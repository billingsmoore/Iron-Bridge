{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset('billingsmoore/Aggregated-bo-en', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Tokenizer for Tibetan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the tokenizer already contains some Tibetan tokens but not enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tokenizer.encode('ཡུན་རིང་དུས་ནས་ཆོས་ཀྱིས་བསྐྱངས་བའི་བུ། ')\n",
    "tokenizer.decode(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "new_tokenizer = BertWordPieceTokenizer(lowercase=False, strip_accents=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokenizer.train_from_iterator(\n",
    "    ds['bo'],\n",
    "    vocab_size=len(tokenizer.get_vocab()),\n",
    "    min_frequency=3,\n",
    "    show_progress=True,\n",
    "    limit_alphabet=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert New Tokenizer to AutoTokenizer Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokenizer.save_model('new_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# Load the trained tokenizer\n",
    "fast_tokenizer = BertTokenizerFast(\n",
    "    vocab_file=\"new_tokenizer/vocab.txt\",\n",
    "    do_lower_case=False\n",
    ")\n",
    "\n",
    "# Save in Hugging Face format\n",
    "fast_tokenizer.save_pretrained(\"fast_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load your new tokenizer\n",
    "new_fast_tokenizer = AutoTokenizer.from_pretrained(\"fast_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = new_fast_tokenizer.encode('ཡུན་རིང་དུས་ནས་ཆོས་ཀྱིས་བསྐྱངས་བའི་བུ། ')\n",
    "new_fast_tokenizer.decode(enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/Documents/MLotsawa/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset('billingsmoore/Aggregated-bo-en', split='train')\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device='cuda')\n",
    "\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(\"fast_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3d3e365cf34d61bc4cf5caadf4564f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "teacher_embeddings = model.encode(ds['en'],show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "\n",
    "# Load the pre-trained MiniLM model\n",
    "word_embedding_model = models.Transformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Replace the tokenizer with your custom tokenizer\n",
    "word_embedding_model.tokenizer = student_tokenizer\n",
    "\n",
    "# add a pooling layer\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "# Create the SentenceTransformer model\n",
    "student_model = SentenceTransformer(modules=[word_embedding_model, pooling_model], device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = losses.MSELoss(model=student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbillingsmoore\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/j/Documents/MLotsawa/Notebooks/Models/EmbeddingModel/wandb/run-20250210_164157-dtv9mwz3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/billingsmoore/sentence-transformers/runs/dtv9mwz3' target=\"_blank\">checkpoints/model</a></strong> to <a href='https://wandb.ai/billingsmoore/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/billingsmoore/sentence-transformers' target=\"_blank\">https://wandb.ai/billingsmoore/sentence-transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/billingsmoore/sentence-transformers/runs/dtv9mwz3' target=\"_blank\">https://wandb.ai/billingsmoore/sentence-transformers/runs/dtv9mwz3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d82357aff04e55b75a97c41851b82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164628 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0237, 'grad_norm': 0.03572463244199753, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.01}\n",
      "{'loss': 0.0034, 'grad_norm': 0.00758838327601552, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.02}\n",
      "{'loss': 0.0028, 'grad_norm': 0.006931068375706673, 'learning_rate': 3e-06, 'epoch': 0.03}\n",
      "{'loss': 0.0026, 'grad_norm': 0.004626153502613306, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.04}\n",
      "{'loss': 0.0025, 'grad_norm': 0.004049560055136681, 'learning_rate': 5e-06, 'epoch': 0.05}\n",
      "{'loss': 0.0025, 'grad_norm': 0.003877197625115514, 'learning_rate': 6e-06, 'epoch': 0.05}\n",
      "{'loss': 0.0024, 'grad_norm': 0.003397856606170535, 'learning_rate': 7e-06, 'epoch': 0.06}\n",
      "{'loss': 0.0024, 'grad_norm': 0.0036154408007860184, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.07}\n",
      "{'loss': 0.0024, 'grad_norm': 0.003426718059927225, 'learning_rate': 9e-06, 'epoch': 0.08}\n",
      "{'loss': 0.0024, 'grad_norm': 0.003442424815148115, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0024, 'grad_norm': 0.004002387169748545, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.1}\n",
      "{'loss': 0.0024, 'grad_norm': 0.0034711044281721115, 'learning_rate': 1.2e-05, 'epoch': 0.11}\n",
      "{'loss': 0.0024, 'grad_norm': 0.0032720090821385384, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0024, 'grad_norm': 0.003559400560334325, 'learning_rate': 1.4e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0024, 'grad_norm': 0.0032395499292761087, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0024, 'grad_norm': 0.003992687910795212, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0024, 'grad_norm': 0.005341940093785524, 'learning_rate': 1.7e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0023, 'grad_norm': 0.003685429459437728, 'learning_rate': 1.8e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0023, 'grad_norm': 0.0035541458055377007, 'learning_rate': 1.9e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0023, 'grad_norm': 0.006041957065463066, 'learning_rate': 2e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0023, 'grad_norm': 0.004553564824163914, 'learning_rate': 1.9935327405012127e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0023, 'grad_norm': 0.0046197716146707535, 'learning_rate': 1.9870654810024255e-05, 'epoch': 0.2}\n",
      "{'loss': 0.0023, 'grad_norm': 0.005365997087210417, 'learning_rate': 1.980598221503638e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0023, 'grad_norm': 0.004624184686690569, 'learning_rate': 1.9741309620048505e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0022, 'grad_norm': 0.004504671320319176, 'learning_rate': 1.967663702506063e-05, 'epoch': 0.23}\n",
      "{'loss': 0.0022, 'grad_norm': 0.0037826320622116327, 'learning_rate': 1.961196443007276e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0022, 'grad_norm': 0.004225562326610088, 'learning_rate': 1.9547291835084884e-05, 'epoch': 0.25}\n",
      "{'loss': 0.0022, 'grad_norm': 0.004321492742747068, 'learning_rate': 1.9482619240097012e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0022, 'grad_norm': 0.004028627183288336, 'learning_rate': 1.9417946645109137e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0022, 'grad_norm': 0.00560023495927453, 'learning_rate': 1.9353274050121262e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0022, 'grad_norm': 0.0055802930146455765, 'learning_rate': 1.9288601455133388e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0022, 'grad_norm': 0.005749587435275316, 'learning_rate': 1.9223928860145516e-05, 'epoch': 0.29}\n",
      "{'loss': 0.0021, 'grad_norm': 0.004011508543044329, 'learning_rate': 1.915925626515764e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0021, 'grad_norm': 0.0054999287240207195, 'learning_rate': 1.9094583670169766e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0021, 'grad_norm': 0.004821645561605692, 'learning_rate': 1.902991107518189e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0021, 'grad_norm': 0.004886826034635305, 'learning_rate': 1.896523848019402e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0021, 'grad_norm': 0.005930319428443909, 'learning_rate': 1.8900565885206145e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0021, 'grad_norm': 0.0049025435000658035, 'learning_rate': 1.8835893290218273e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0021, 'grad_norm': 0.004387243650853634, 'learning_rate': 1.8771220695230398e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0021, 'grad_norm': 0.003853141563013196, 'learning_rate': 1.8706548100242523e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0021, 'grad_norm': 0.004223228897899389, 'learning_rate': 1.864187550525465e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0021, 'grad_norm': 0.0038212763611227274, 'learning_rate': 1.8577202910266777e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0021, 'grad_norm': 0.005492823198437691, 'learning_rate': 1.8512530315278902e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0021, 'grad_norm': 0.005624213721603155, 'learning_rate': 1.844785772029103e-05, 'epoch': 0.4}\n",
      "{'loss': 0.002, 'grad_norm': 0.0037057988811284304, 'learning_rate': 1.8383185125303152e-05, 'epoch': 0.41}\n",
      "{'loss': 0.002, 'grad_norm': 0.005607511382550001, 'learning_rate': 1.831851253031528e-05, 'epoch': 0.42}\n",
      "{'loss': 0.002, 'grad_norm': 0.0044580306857824326, 'learning_rate': 1.8253839935327406e-05, 'epoch': 0.43}\n",
      "{'loss': 0.002, 'grad_norm': 0.006251651793718338, 'learning_rate': 1.8189167340339534e-05, 'epoch': 0.44}\n",
      "{'loss': 0.002, 'grad_norm': 0.0048571424558758736, 'learning_rate': 1.812449474535166e-05, 'epoch': 0.45}\n",
      "{'loss': 0.002, 'grad_norm': 0.00478333979845047, 'learning_rate': 1.8059822150363784e-05, 'epoch': 0.46}\n",
      "{'loss': 0.002, 'grad_norm': 0.003878421150147915, 'learning_rate': 1.799514955537591e-05, 'epoch': 0.46}\n",
      "{'loss': 0.002, 'grad_norm': 0.0040608556009829044, 'learning_rate': 1.7930476960388038e-05, 'epoch': 0.47}\n",
      "{'loss': 0.002, 'grad_norm': 0.004885762929916382, 'learning_rate': 1.7865804365400163e-05, 'epoch': 0.48}\n",
      "{'loss': 0.002, 'grad_norm': 0.004683897364884615, 'learning_rate': 1.780113177041229e-05, 'epoch': 0.49}\n",
      "{'loss': 0.002, 'grad_norm': 0.004591498523950577, 'learning_rate': 1.7736459175424416e-05, 'epoch': 0.5}\n",
      "{'loss': 0.002, 'grad_norm': 0.003858153708279133, 'learning_rate': 1.767178658043654e-05, 'epoch': 0.51}\n",
      "{'loss': 0.002, 'grad_norm': 0.004109884146600962, 'learning_rate': 1.7607113985448666e-05, 'epoch': 0.52}\n",
      "{'loss': 0.002, 'grad_norm': 0.004254267085343599, 'learning_rate': 1.7542441390460795e-05, 'epoch': 0.53}\n",
      "{'loss': 0.002, 'grad_norm': 0.0048791998997330666, 'learning_rate': 1.747776879547292e-05, 'epoch': 0.54}\n",
      "{'loss': 0.002, 'grad_norm': 0.004636416677385569, 'learning_rate': 1.7413096200485048e-05, 'epoch': 0.55}\n",
      "{'loss': 0.002, 'grad_norm': 0.005014329217374325, 'learning_rate': 1.734842360549717e-05, 'epoch': 0.56}\n",
      "{'loss': 0.002, 'grad_norm': 0.005153988022357225, 'learning_rate': 1.72837510105093e-05, 'epoch': 0.56}\n",
      "{'loss': 0.002, 'grad_norm': 0.004508650861680508, 'learning_rate': 1.7219078415521423e-05, 'epoch': 0.57}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004572890233248472, 'learning_rate': 1.7154405820533552e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004467667080461979, 'learning_rate': 1.7089733225545677e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004182510077953339, 'learning_rate': 1.7025060630557802e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004190105013549328, 'learning_rate': 1.6960388035569927e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004813721869140863, 'learning_rate': 1.6895715440582056e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004354255273938179, 'learning_rate': 1.683104284559418e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0019, 'grad_norm': 0.0049231830053031445, 'learning_rate': 1.676637025060631e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004314196761697531, 'learning_rate': 1.6701697655618434e-05, 'epoch': 0.65}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004922980442643166, 'learning_rate': 1.663702506063056e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0019, 'grad_norm': 0.0041049327701330185, 'learning_rate': 1.6572352465642684e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004807513207197189, 'learning_rate': 1.6507679870654813e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0019, 'grad_norm': 0.0037851424422115088, 'learning_rate': 1.6443007275666938e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0019, 'grad_norm': 0.00492603937163949, 'learning_rate': 1.6378334680679063e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004252627957612276, 'learning_rate': 1.6313662085691188e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0019, 'grad_norm': 0.0044121891260147095, 'learning_rate': 1.6248989490703316e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0019, 'grad_norm': 0.00452375179156661, 'learning_rate': 1.618431689571544e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004082563798874617, 'learning_rate': 1.611964430072757e-05, 'epoch': 0.73}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004201873205602169, 'learning_rate': 1.6054971705739695e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004841056186705828, 'learning_rate': 1.599029911075182e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0019, 'grad_norm': 0.0047347997315227985, 'learning_rate': 1.5925626515763945e-05, 'epoch': 0.76}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004394101444631815, 'learning_rate': 1.5860953920776074e-05, 'epoch': 0.77}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004218611400574446, 'learning_rate': 1.57962813257882e-05, 'epoch': 0.77}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004730748012661934, 'learning_rate': 1.5731608730800324e-05, 'epoch': 0.78}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004640213679522276, 'learning_rate': 1.5666936135812452e-05, 'epoch': 0.79}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004926745779812336, 'learning_rate': 1.5602263540824577e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004959911573678255, 'learning_rate': 1.5537590945836702e-05, 'epoch': 0.81}\n",
      "{'loss': 0.0019, 'grad_norm': 0.006020466797053814, 'learning_rate': 1.5472918350848827e-05, 'epoch': 0.82}\n",
      "{'loss': 0.0019, 'grad_norm': 0.0043992833234369755, 'learning_rate': 1.5408245755860956e-05, 'epoch': 0.83}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004262281581759453, 'learning_rate': 1.534357316087308e-05, 'epoch': 0.84}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004572876263409853, 'learning_rate': 1.5278900565885206e-05, 'epoch': 0.85}\n",
      "{'loss': 0.0019, 'grad_norm': 0.0050190528854727745, 'learning_rate': 1.5214227970897333e-05, 'epoch': 0.86}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004240159410983324, 'learning_rate': 1.514955537590946e-05, 'epoch': 0.87}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004328517708927393, 'learning_rate': 1.5084882780921586e-05, 'epoch': 0.87}\n",
      "{'loss': 0.0019, 'grad_norm': 0.00422115670517087, 'learning_rate': 1.5020210185933713e-05, 'epoch': 0.88}\n",
      "{'loss': 0.0019, 'grad_norm': 0.0042139687575399876, 'learning_rate': 1.4955537590945838e-05, 'epoch': 0.89}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004880975466221571, 'learning_rate': 1.4890864995957963e-05, 'epoch': 0.9}\n",
      "{'loss': 0.0019, 'grad_norm': 0.0045518409460783005, 'learning_rate': 1.482619240097009e-05, 'epoch': 0.91}\n",
      "{'loss': 0.0018, 'grad_norm': 0.003760901978239417, 'learning_rate': 1.4761519805982217e-05, 'epoch': 0.92}\n",
      "{'loss': 0.0019, 'grad_norm': 0.003708992153406143, 'learning_rate': 1.4696847210994343e-05, 'epoch': 0.93}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004008852876722813, 'learning_rate': 1.4632174616006468e-05, 'epoch': 0.94}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004447731655091047, 'learning_rate': 1.4567502021018594e-05, 'epoch': 0.95}\n",
      "{'loss': 0.0018, 'grad_norm': 0.0041098217479884624, 'learning_rate': 1.450282942603072e-05, 'epoch': 0.96}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004528071265667677, 'learning_rate': 1.4438156831042847e-05, 'epoch': 0.97}\n",
      "{'loss': 0.0019, 'grad_norm': 0.004587535746395588, 'learning_rate': 1.4373484236054974e-05, 'epoch': 0.97}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004899317864328623, 'learning_rate': 1.4308811641067099e-05, 'epoch': 0.98}\n",
      "{'loss': 0.0018, 'grad_norm': 0.005035154055804014, 'learning_rate': 1.4244139046079226e-05, 'epoch': 0.99}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004222606308758259, 'learning_rate': 1.417946645109135e-05, 'epoch': 1.0}\n",
      "{'loss': 0.0018, 'grad_norm': 0.003984786104410887, 'learning_rate': 1.4114793856103477e-05, 'epoch': 1.01}\n",
      "{'loss': 0.0018, 'grad_norm': 0.005323973949998617, 'learning_rate': 1.4050121261115604e-05, 'epoch': 1.02}\n",
      "{'loss': 0.0018, 'grad_norm': 0.0043068998493254185, 'learning_rate': 1.398544866612773e-05, 'epoch': 1.03}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004540220834314823, 'learning_rate': 1.3920776071139856e-05, 'epoch': 1.04}\n",
      "{'loss': 0.0018, 'grad_norm': 0.003818497294560075, 'learning_rate': 1.3856103476151981e-05, 'epoch': 1.05}\n",
      "{'loss': 0.0018, 'grad_norm': 0.00419628107920289, 'learning_rate': 1.3791430881164108e-05, 'epoch': 1.06}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004234929569065571, 'learning_rate': 1.3726758286176235e-05, 'epoch': 1.07}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004854782950133085, 'learning_rate': 1.366208569118836e-05, 'epoch': 1.08}\n",
      "{'loss': 0.0018, 'grad_norm': 0.0038365477230399847, 'learning_rate': 1.3597413096200486e-05, 'epoch': 1.08}\n",
      "{'loss': 0.0018, 'grad_norm': 0.0040919166058301926, 'learning_rate': 1.3532740501212612e-05, 'epoch': 1.09}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004708948079496622, 'learning_rate': 1.3468067906224738e-05, 'epoch': 1.1}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004154973663389683, 'learning_rate': 1.3403395311236865e-05, 'epoch': 1.11}\n",
      "{'loss': 0.0018, 'grad_norm': 0.0044146268628537655, 'learning_rate': 1.333872271624899e-05, 'epoch': 1.12}\n",
      "{'loss': 0.0018, 'grad_norm': 0.0042925928719341755, 'learning_rate': 1.3274050121261117e-05, 'epoch': 1.13}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004139957018196583, 'learning_rate': 1.3209377526273244e-05, 'epoch': 1.14}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004733039066195488, 'learning_rate': 1.3144704931285369e-05, 'epoch': 1.15}\n",
      "{'loss': 0.0018, 'grad_norm': 0.00451649772003293, 'learning_rate': 1.3080032336297494e-05, 'epoch': 1.16}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004686869215220213, 'learning_rate': 1.301535974130962e-05, 'epoch': 1.17}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004533123690634966, 'learning_rate': 1.2950687146321747e-05, 'epoch': 1.18}\n",
      "{'loss': 0.0018, 'grad_norm': 0.00500213960185647, 'learning_rate': 1.2886014551333874e-05, 'epoch': 1.18}\n",
      "{'loss': 0.0018, 'grad_norm': 0.00414767162874341, 'learning_rate': 1.2821341956345999e-05, 'epoch': 1.19}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004705344792455435, 'learning_rate': 1.2756669361358124e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004797416739165783, 'learning_rate': 1.2691996766370251e-05, 'epoch': 1.21}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004441649187356234, 'learning_rate': 1.2627324171382378e-05, 'epoch': 1.22}\n",
      "{'loss': 0.0018, 'grad_norm': 0.005717472638934851, 'learning_rate': 1.2562651576394504e-05, 'epoch': 1.23}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004824050702154636, 'learning_rate': 1.2497978981406631e-05, 'epoch': 1.24}\n",
      "{'loss': 0.0018, 'grad_norm': 0.0046538617461919785, 'learning_rate': 1.2433306386418755e-05, 'epoch': 1.25}\n",
      "{'loss': 0.0018, 'grad_norm': 0.0043500144965946674, 'learning_rate': 1.2368633791430881e-05, 'epoch': 1.26}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004936478100717068, 'learning_rate': 1.2303961196443008e-05, 'epoch': 1.27}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004689517896622419, 'learning_rate': 1.2239288601455135e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004922233987599611, 'learning_rate': 1.2174616006467262e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004282652400434017, 'learning_rate': 1.2109943411479385e-05, 'epoch': 1.29}\n",
      "{'loss': 0.0018, 'grad_norm': 0.005489856004714966, 'learning_rate': 1.2045270816491512e-05, 'epoch': 1.3}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004327974282205105, 'learning_rate': 1.1980598221503639e-05, 'epoch': 1.31}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004379661288112402, 'learning_rate': 1.1915925626515765e-05, 'epoch': 1.32}\n",
      "{'loss': 0.0018, 'grad_norm': 0.00510860700160265, 'learning_rate': 1.1851253031527892e-05, 'epoch': 1.33}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004329914692789316, 'learning_rate': 1.1786580436540015e-05, 'epoch': 1.34}\n",
      "{'loss': 0.0018, 'grad_norm': 0.005033869296312332, 'learning_rate': 1.1721907841552142e-05, 'epoch': 1.35}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004970792215317488, 'learning_rate': 1.1657235246564269e-05, 'epoch': 1.36}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004632563330233097, 'learning_rate': 1.1592562651576396e-05, 'epoch': 1.37}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004635355435311794, 'learning_rate': 1.1527890056588522e-05, 'epoch': 1.38}\n",
      "{'loss': 0.0018, 'grad_norm': 0.003979330416768789, 'learning_rate': 1.146321746160065e-05, 'epoch': 1.38}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004724201280623674, 'learning_rate': 1.1398544866612773e-05, 'epoch': 1.39}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004920128267258406, 'learning_rate': 1.13338722716249e-05, 'epoch': 1.4}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004134783521294594, 'learning_rate': 1.1269199676637026e-05, 'epoch': 1.41}\n",
      "{'loss': 0.0018, 'grad_norm': 0.0042116972617805, 'learning_rate': 1.1204527081649153e-05, 'epoch': 1.42}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004064539447426796, 'learning_rate': 1.113985448666128e-05, 'epoch': 1.43}\n",
      "{'loss': 0.0018, 'grad_norm': 0.005212835967540741, 'learning_rate': 1.1075181891673403e-05, 'epoch': 1.44}\n",
      "{'loss': 0.0018, 'grad_norm': 0.005100542679429054, 'learning_rate': 1.101050929668553e-05, 'epoch': 1.45}\n",
      "{'loss': 0.0018, 'grad_norm': 0.0050626350566744804, 'learning_rate': 1.0945836701697656e-05, 'epoch': 1.46}\n",
      "{'loss': 0.0018, 'grad_norm': 0.006096897646784782, 'learning_rate': 1.0881164106709783e-05, 'epoch': 1.47}\n",
      "{'loss': 0.0018, 'grad_norm': 0.005048701073974371, 'learning_rate': 1.081649151172191e-05, 'epoch': 1.48}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004427211359143257, 'learning_rate': 1.0751818916734035e-05, 'epoch': 1.49}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004302238114178181, 'learning_rate': 1.068714632174616e-05, 'epoch': 1.49}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004220985807478428, 'learning_rate': 1.0622473726758287e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004666593391448259, 'learning_rate': 1.0557801131770414e-05, 'epoch': 1.51}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004785662982612848, 'learning_rate': 1.049312853678254e-05, 'epoch': 1.52}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004730578046292067, 'learning_rate': 1.0428455941794665e-05, 'epoch': 1.53}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004852501675486565, 'learning_rate': 1.036378334680679e-05, 'epoch': 1.54}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004059925209730864, 'learning_rate': 1.0299110751818917e-05, 'epoch': 1.55}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004189673811197281, 'learning_rate': 1.0234438156831044e-05, 'epoch': 1.56}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004840672481805086, 'learning_rate': 1.016976556184317e-05, 'epoch': 1.57}\n",
      "{'loss': 0.0018, 'grad_norm': 0.003842960810288787, 'learning_rate': 1.0105092966855296e-05, 'epoch': 1.58}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004377387464046478, 'learning_rate': 1.0040420371867421e-05, 'epoch': 1.59}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004024568945169449, 'learning_rate': 9.975747776879548e-06, 'epoch': 1.59}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004118124023079872, 'learning_rate': 9.911075181891674e-06, 'epoch': 1.6}\n",
      "{'loss': 0.0018, 'grad_norm': 0.003920555580407381, 'learning_rate': 9.846402586903801e-06, 'epoch': 1.61}\n",
      "{'loss': 0.0018, 'grad_norm': 0.0045527019537985325, 'learning_rate': 9.781729991915926e-06, 'epoch': 1.62}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004177772905677557, 'learning_rate': 9.717057396928053e-06, 'epoch': 1.63}\n",
      "{'loss': 0.0018, 'grad_norm': 0.0045975130051374435, 'learning_rate': 9.652384801940178e-06, 'epoch': 1.64}\n",
      "{'loss': 0.0018, 'grad_norm': 0.005375725217163563, 'learning_rate': 9.587712206952305e-06, 'epoch': 1.65}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004497659392654896, 'learning_rate': 9.523039611964432e-06, 'epoch': 1.66}\n",
      "{'loss': 0.0018, 'grad_norm': 0.0046208384446799755, 'learning_rate': 9.458367016976557e-06, 'epoch': 1.67}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004858765751123428, 'learning_rate': 9.393694421988683e-06, 'epoch': 1.68}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004343061707913876, 'learning_rate': 9.329021827000809e-06, 'epoch': 1.69}\n",
      "{'loss': 0.0018, 'grad_norm': 0.0037631895393133163, 'learning_rate': 9.264349232012935e-06, 'epoch': 1.69}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004131928086280823, 'learning_rate': 9.19967663702506e-06, 'epoch': 1.7}\n",
      "{'loss': 0.0018, 'grad_norm': 0.00509557593613863, 'learning_rate': 9.135004042037187e-06, 'epoch': 1.71}\n",
      "{'loss': 0.0018, 'grad_norm': 0.00576668418943882, 'learning_rate': 9.070331447049314e-06, 'epoch': 1.72}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004536876454949379, 'learning_rate': 9.005658852061439e-06, 'epoch': 1.73}\n",
      "{'loss': 0.0018, 'grad_norm': 0.005179497878998518, 'learning_rate': 8.940986257073566e-06, 'epoch': 1.74}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004039488732814789, 'learning_rate': 8.87631366208569e-06, 'epoch': 1.75}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004811170045286417, 'learning_rate': 8.811641067097818e-06, 'epoch': 1.76}\n",
      "{'loss': 0.0018, 'grad_norm': 0.005178059916943312, 'learning_rate': 8.746968472109944e-06, 'epoch': 1.77}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004877591505646706, 'learning_rate': 8.68229587712207e-06, 'epoch': 1.78}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004724706988781691, 'learning_rate': 8.617623282134196e-06, 'epoch': 1.79}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004379470832645893, 'learning_rate': 8.552950687146321e-06, 'epoch': 1.79}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004542122595012188, 'learning_rate': 8.488278092158448e-06, 'epoch': 1.8}\n",
      "{'loss': 0.0018, 'grad_norm': 0.005000137258321047, 'learning_rate': 8.423605497170575e-06, 'epoch': 1.81}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004673635121434927, 'learning_rate': 8.3589329021827e-06, 'epoch': 1.82}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004811183549463749, 'learning_rate': 8.294260307194827e-06, 'epoch': 1.83}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004431992769241333, 'learning_rate': 8.229587712206953e-06, 'epoch': 1.84}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004858722910284996, 'learning_rate': 8.164915117219078e-06, 'epoch': 1.85}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004842155147343874, 'learning_rate': 8.100242522231205e-06, 'epoch': 1.86}\n",
      "{'loss': 0.0018, 'grad_norm': 0.00406670430675149, 'learning_rate': 8.035569927243332e-06, 'epoch': 1.87}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004468528553843498, 'learning_rate': 7.970897332255457e-06, 'epoch': 1.88}\n",
      "{'loss': 0.0017, 'grad_norm': 0.005673838779330254, 'learning_rate': 7.906224737267584e-06, 'epoch': 1.89}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004931698553264141, 'learning_rate': 7.841552142279709e-06, 'epoch': 1.9}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0038628852926194668, 'learning_rate': 7.776879547291836e-06, 'epoch': 1.9}\n",
      "{'loss': 0.0018, 'grad_norm': 0.00450615119189024, 'learning_rate': 7.712206952303962e-06, 'epoch': 1.91}\n",
      "{'loss': 0.0018, 'grad_norm': 0.00495624914765358, 'learning_rate': 7.647534357316087e-06, 'epoch': 1.92}\n",
      "{'loss': 0.0017, 'grad_norm': 0.00437737675383687, 'learning_rate': 7.582861762328214e-06, 'epoch': 1.93}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0050126975402235985, 'learning_rate': 7.518189167340341e-06, 'epoch': 1.94}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004940033424645662, 'learning_rate': 7.453516572352466e-06, 'epoch': 1.95}\n",
      "{'loss': 0.0017, 'grad_norm': 0.005303061101585627, 'learning_rate': 7.388843977364593e-06, 'epoch': 1.96}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004002268426120281, 'learning_rate': 7.324171382376718e-06, 'epoch': 1.97}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004331599455326796, 'learning_rate': 7.2594987873888445e-06, 'epoch': 1.98}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004272130783647299, 'learning_rate': 7.194826192400971e-06, 'epoch': 1.99}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0046624052338302135, 'learning_rate': 7.130153597413096e-06, 'epoch': 2.0}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004583094269037247, 'learning_rate': 7.065481002425223e-06, 'epoch': 2.0}\n",
      "{'loss': 0.0017, 'grad_norm': 0.003954737447202206, 'learning_rate': 7.00080840743735e-06, 'epoch': 2.01}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004230531398206949, 'learning_rate': 6.936135812449475e-06, 'epoch': 2.02}\n",
      "{'loss': 0.0017, 'grad_norm': 0.005113633349537849, 'learning_rate': 6.871463217461602e-06, 'epoch': 2.03}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004232668783515692, 'learning_rate': 6.806790622473727e-06, 'epoch': 2.04}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004681923892349005, 'learning_rate': 6.7421180274858535e-06, 'epoch': 2.05}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0037808255292475224, 'learning_rate': 6.677445432497979e-06, 'epoch': 2.06}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004634759854525328, 'learning_rate': 6.612772837510105e-06, 'epoch': 2.07}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004366023000329733, 'learning_rate': 6.548100242522232e-06, 'epoch': 2.08}\n",
      "{'loss': 0.0018, 'grad_norm': 0.0045606293715536594, 'learning_rate': 6.483427647534358e-06, 'epoch': 2.09}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004934887867420912, 'learning_rate': 6.418755052546484e-06, 'epoch': 2.1}\n",
      "{'loss': 0.0018, 'grad_norm': 0.004406768828630447, 'learning_rate': 6.35408245755861e-06, 'epoch': 2.1}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0052424343302845955, 'learning_rate': 6.289409862570737e-06, 'epoch': 2.11}\n",
      "{'loss': 0.0018, 'grad_norm': 0.005156494211405516, 'learning_rate': 6.2247372675828625e-06, 'epoch': 2.12}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004972788039594889, 'learning_rate': 6.160064672594988e-06, 'epoch': 2.13}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004670510999858379, 'learning_rate': 6.095392077607114e-06, 'epoch': 2.14}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004773417487740517, 'learning_rate': 6.03071948261924e-06, 'epoch': 2.15}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004235527012497187, 'learning_rate': 5.966046887631367e-06, 'epoch': 2.16}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0049339886754751205, 'learning_rate': 5.901374292643492e-06, 'epoch': 2.17}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004614288918673992, 'learning_rate': 5.836701697655619e-06, 'epoch': 2.18}\n",
      "{'loss': 0.0017, 'grad_norm': 0.005723915062844753, 'learning_rate': 5.772029102667746e-06, 'epoch': 2.19}\n",
      "{'loss': 0.0017, 'grad_norm': 0.005101105198264122, 'learning_rate': 5.707356507679871e-06, 'epoch': 2.2}\n",
      "{'loss': 0.0017, 'grad_norm': 0.005260756239295006, 'learning_rate': 5.642683912691997e-06, 'epoch': 2.2}\n",
      "{'loss': 0.0017, 'grad_norm': 0.005264197010546923, 'learning_rate': 5.5780113177041225e-06, 'epoch': 2.21}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0038936955388635397, 'learning_rate': 5.513338722716249e-06, 'epoch': 2.22}\n",
      "{'loss': 0.0017, 'grad_norm': 0.005842347629368305, 'learning_rate': 5.448666127728376e-06, 'epoch': 2.23}\n",
      "{'loss': 0.0017, 'grad_norm': 0.00474012503400445, 'learning_rate': 5.383993532740501e-06, 'epoch': 2.24}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004178683273494244, 'learning_rate': 5.319320937752628e-06, 'epoch': 2.25}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0048818341456353664, 'learning_rate': 5.2546483427647546e-06, 'epoch': 2.26}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004632194060832262, 'learning_rate': 5.18997574777688e-06, 'epoch': 2.27}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004145761951804161, 'learning_rate': 5.125303152789006e-06, 'epoch': 2.28}\n",
      "{'loss': 0.0017, 'grad_norm': 0.005150640849024057, 'learning_rate': 5.0606305578011315e-06, 'epoch': 2.29}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004147711209952831, 'learning_rate': 4.995957962813258e-06, 'epoch': 2.3}\n",
      "{'loss': 0.0017, 'grad_norm': 0.003747920971363783, 'learning_rate': 4.931285367825384e-06, 'epoch': 2.31}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004678282421082258, 'learning_rate': 4.866612772837511e-06, 'epoch': 2.31}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004927503876388073, 'learning_rate': 4.801940177849637e-06, 'epoch': 2.32}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004254193510860205, 'learning_rate': 4.737267582861763e-06, 'epoch': 2.33}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0046247448772192, 'learning_rate': 4.6725949878738895e-06, 'epoch': 2.34}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004897919949144125, 'learning_rate': 4.607922392886015e-06, 'epoch': 2.35}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0046400404535233974, 'learning_rate': 4.543249797898141e-06, 'epoch': 2.36}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004291309975087643, 'learning_rate': 4.478577202910267e-06, 'epoch': 2.37}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004908187314867973, 'learning_rate': 4.413904607922393e-06, 'epoch': 2.38}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004710385575890541, 'learning_rate': 4.349232012934519e-06, 'epoch': 2.39}\n",
      "{'loss': 0.0017, 'grad_norm': 0.00465089688077569, 'learning_rate': 4.284559417946646e-06, 'epoch': 2.4}\n",
      "{'loss': 0.0017, 'grad_norm': 0.005037956405431032, 'learning_rate': 4.219886822958772e-06, 'epoch': 2.41}\n",
      "{'loss': 0.0017, 'grad_norm': 0.00449999887496233, 'learning_rate': 4.155214227970898e-06, 'epoch': 2.41}\n",
      "{'loss': 0.0017, 'grad_norm': 0.00381908705458045, 'learning_rate': 4.0905416329830235e-06, 'epoch': 2.42}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004896378610283136, 'learning_rate': 4.0258690379951495e-06, 'epoch': 2.43}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004766890313476324, 'learning_rate': 3.961196443007276e-06, 'epoch': 2.44}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004750833380967379, 'learning_rate': 3.896523848019402e-06, 'epoch': 2.45}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004470743238925934, 'learning_rate': 3.831851253031528e-06, 'epoch': 2.46}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0039869616739451885, 'learning_rate': 3.7671786580436544e-06, 'epoch': 2.47}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004500401671975851, 'learning_rate': 3.7025060630557803e-06, 'epoch': 2.48}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0048835426568984985, 'learning_rate': 3.6378334680679066e-06, 'epoch': 2.49}\n",
      "{'loss': 0.0017, 'grad_norm': 0.00419263169169426, 'learning_rate': 3.5731608730800325e-06, 'epoch': 2.5}\n",
      "{'loss': 0.0017, 'grad_norm': 0.005313284695148468, 'learning_rate': 3.5084882780921584e-06, 'epoch': 2.51}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004454689100384712, 'learning_rate': 3.4438156831042848e-06, 'epoch': 2.51}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004567123483866453, 'learning_rate': 3.379143088116411e-06, 'epoch': 2.52}\n",
      "{'loss': 0.0017, 'grad_norm': 0.005659653339534998, 'learning_rate': 3.314470493128537e-06, 'epoch': 2.53}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004238318186253309, 'learning_rate': 3.249797898140663e-06, 'epoch': 2.54}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004162485711276531, 'learning_rate': 3.185125303152789e-06, 'epoch': 2.55}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004788361489772797, 'learning_rate': 3.1204527081649156e-06, 'epoch': 2.56}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004056908655911684, 'learning_rate': 3.0557801131770415e-06, 'epoch': 2.57}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004746335092931986, 'learning_rate': 2.9911075181891674e-06, 'epoch': 2.58}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004398765973746777, 'learning_rate': 2.9264349232012938e-06, 'epoch': 2.59}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004616971127688885, 'learning_rate': 2.86176232821342e-06, 'epoch': 2.6}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004404154140502214, 'learning_rate': 2.797089733225546e-06, 'epoch': 2.61}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004366844426840544, 'learning_rate': 2.732417138237672e-06, 'epoch': 2.61}\n",
      "{'loss': 0.0017, 'grad_norm': 0.005054830107837915, 'learning_rate': 2.6677445432497983e-06, 'epoch': 2.62}\n",
      "{'loss': 0.0017, 'grad_norm': 0.005004648119211197, 'learning_rate': 2.603071948261924e-06, 'epoch': 2.63}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004695236682891846, 'learning_rate': 2.53839935327405e-06, 'epoch': 2.64}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004380404949188232, 'learning_rate': 2.4737267582861764e-06, 'epoch': 2.65}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004758274648338556, 'learning_rate': 2.4090541632983023e-06, 'epoch': 2.66}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004762541968375444, 'learning_rate': 2.3443815683104287e-06, 'epoch': 2.67}\n",
      "{'loss': 0.0017, 'grad_norm': 0.005632475949823856, 'learning_rate': 2.2797089733225546e-06, 'epoch': 2.68}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004397851414978504, 'learning_rate': 2.215036378334681e-06, 'epoch': 2.69}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0046293470077216625, 'learning_rate': 2.150363783346807e-06, 'epoch': 2.7}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004283777438104153, 'learning_rate': 2.085691188358933e-06, 'epoch': 2.71}\n",
      "{'loss': 0.0017, 'grad_norm': 0.005434234626591206, 'learning_rate': 2.021018593371059e-06, 'epoch': 2.72}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004931531380861998, 'learning_rate': 1.9563459983831854e-06, 'epoch': 2.72}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0050184051506221294, 'learning_rate': 1.8916734033953113e-06, 'epoch': 2.73}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004403071943670511, 'learning_rate': 1.8270008084074375e-06, 'epoch': 2.74}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004442386329174042, 'learning_rate': 1.7623282134195636e-06, 'epoch': 2.75}\n",
      "{'loss': 0.0017, 'grad_norm': 0.00486953416839242, 'learning_rate': 1.6976556184316897e-06, 'epoch': 2.76}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0051779793575406075, 'learning_rate': 1.6329830234438156e-06, 'epoch': 2.77}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004714752081781626, 'learning_rate': 1.568310428455942e-06, 'epoch': 2.78}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004238543566316366, 'learning_rate': 1.5036378334680679e-06, 'epoch': 2.79}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004373008850961924, 'learning_rate': 1.4389652384801942e-06, 'epoch': 2.8}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004657969810068607, 'learning_rate': 1.3742926434923201e-06, 'epoch': 2.81}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004304233938455582, 'learning_rate': 1.3096200485044462e-06, 'epoch': 2.82}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004323207773268223, 'learning_rate': 1.2449474535165724e-06, 'epoch': 2.82}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0038369805552065372, 'learning_rate': 1.1802748585286985e-06, 'epoch': 2.83}\n",
      "{'loss': 0.0017, 'grad_norm': 0.00467398576438427, 'learning_rate': 1.1156022635408246e-06, 'epoch': 2.84}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004602770321071148, 'learning_rate': 1.0509296685529507e-06, 'epoch': 2.85}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004207408055663109, 'learning_rate': 9.862570735650769e-07, 'epoch': 2.86}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004945188295096159, 'learning_rate': 9.21584478577203e-07, 'epoch': 2.87}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004873627796769142, 'learning_rate': 8.56911883589329e-07, 'epoch': 2.88}\n",
      "{'loss': 0.0017, 'grad_norm': 0.003969072829931974, 'learning_rate': 7.922392886014551e-07, 'epoch': 2.89}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004830211400985718, 'learning_rate': 7.275666936135813e-07, 'epoch': 2.9}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0040981350466609, 'learning_rate': 6.628940986257074e-07, 'epoch': 2.91}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004488299135118723, 'learning_rate': 5.982215036378335e-07, 'epoch': 2.92}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0044352519325912, 'learning_rate': 5.335489086499596e-07, 'epoch': 2.92}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004167057573795319, 'learning_rate': 4.6887631366208576e-07, 'epoch': 2.93}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004198706243187189, 'learning_rate': 4.0420371867421183e-07, 'epoch': 2.94}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004860792774707079, 'learning_rate': 3.3953112368633795e-07, 'epoch': 2.95}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004560357891023159, 'learning_rate': 2.74858528698464e-07, 'epoch': 2.96}\n",
      "{'loss': 0.0017, 'grad_norm': 0.00430466141551733, 'learning_rate': 2.1018593371059018e-07, 'epoch': 2.97}\n",
      "{'loss': 0.0017, 'grad_norm': 0.0042765140533447266, 'learning_rate': 1.4551333872271625e-07, 'epoch': 2.98}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004095014184713364, 'learning_rate': 8.084074373484237e-08, 'epoch': 2.99}\n",
      "{'loss': 0.0017, 'grad_norm': 0.004742179065942764, 'learning_rate': 1.6168148746968472e-08, 'epoch': 3.0}\n",
      "{'train_runtime': 9072.1672, 'train_samples_per_second': 290.34, 'train_steps_per_second': 18.146, 'train_loss': 0.0019264478252457847, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6e0fa6fab64d149f3990f1eaf09d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, datasets, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "# Create InputExample objects for training\n",
    "train_examples = [\n",
    "    InputExample(texts=[sentence], label=teacher_embedding)\n",
    "    for sentence, teacher_embedding in zip(ds['bo'], teacher_embeddings)\n",
    "]\n",
    "\n",
    "# Create a DataLoader for training\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "\n",
    "# Fine-tune the student model\n",
    "student_model.fit(\n",
    "    train_objectives=[(train_dataloader, loss_fn)],\n",
    "    epochs=20,  # Adjust the number of epochs as needed\n",
    "    output_path='./fine-tuned-minilm'  # Save the fine-tuned model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./fine-tuned-minilm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset('billingsmoore/Aggregated-bo-en', split='train')\n",
    "\n",
    "teacher_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device='cuda')\n",
    "student_model = SentenceTransformer('./fine-tuned-minilm', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between Teacher and Student Embeddings:\n",
      "0.10575532\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate embeddings using the fine-tuned model\n",
    "teacher_embeddings = teacher_model.encode(ds['en'][:100])\n",
    "student_embeddings = student_model.encode(ds['bo'][:100])\n",
    "\n",
    "# Compare the embeddings (e.g., using cosine similarity)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity = cosine_similarity(teacher_embeddings[:100], student_embeddings[:100])\n",
    "print(\"Cosine Similarity between Teacher and Student Embeddings:\")\n",
    "print(np.mean(similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train More"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72852cb75a6647d0ac2fa8f9fd717943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "teacher_embeddings = teacher_model.encode(ds['en'],show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbillingsmoore\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db49bd3a23da44369170218329224bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112291999999495, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/j/Documents/MLotsawa/Notebooks/Models/EmbeddingModel/wandb/run-20250211_131531-cypyfbk5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/billingsmoore/sentence-transformers/runs/cypyfbk5' target=\"_blank\">checkpoints/model</a></strong> to <a href='https://wandb.ai/billingsmoore/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/billingsmoore/sentence-transformers' target=\"_blank\">https://wandb.ai/billingsmoore/sentence-transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/billingsmoore/sentence-transformers/runs/cypyfbk5' target=\"_blank\">https://wandb.ai/billingsmoore/sentence-transformers/runs/cypyfbk5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2767a15af6cc4f588fd197c84f39169a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1097520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0042, 'grad_norm': 0.01006426103413105, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.01}\n",
      "{'loss': 0.0036, 'grad_norm': 0.007295185700058937, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.02}\n",
      "{'loss': 0.0035, 'grad_norm': 0.006422760896384716, 'learning_rate': 3e-06, 'epoch': 0.03}\n",
      "{'loss': 0.0034, 'grad_norm': 0.005309778731316328, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.04}\n",
      "{'loss': 0.0034, 'grad_norm': 0.005954865366220474, 'learning_rate': 5e-06, 'epoch': 0.05}\n",
      "{'loss': 0.0033, 'grad_norm': 0.005869138985872269, 'learning_rate': 6e-06, 'epoch': 0.05}\n",
      "{'loss': 0.0033, 'grad_norm': 0.0063346978276968, 'learning_rate': 7e-06, 'epoch': 0.06}\n",
      "{'loss': 0.0033, 'grad_norm': 0.005792014766484499, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.07}\n",
      "{'loss': 0.0033, 'grad_norm': 0.006025457289069891, 'learning_rate': 9e-06, 'epoch': 0.08}\n",
      "{'loss': 0.0032, 'grad_norm': 0.006847941782325506, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0032, 'grad_norm': 0.0069137574173510075, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.1}\n",
      "{'loss': 0.0032, 'grad_norm': 0.009031458757817745, 'learning_rate': 1.2e-05, 'epoch': 0.11}\n",
      "{'loss': 0.0032, 'grad_norm': 0.0077234492637217045, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0032, 'grad_norm': 0.007179166190326214, 'learning_rate': 1.4e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0032, 'grad_norm': 0.0068649123422801495, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0031, 'grad_norm': 0.006924763321876526, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0031, 'grad_norm': 0.004854216240346432, 'learning_rate': 1.7e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0031, 'grad_norm': 0.006269530858844519, 'learning_rate': 1.8e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0031, 'grad_norm': 0.004866007249802351, 'learning_rate': 1.9e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0031, 'grad_norm': 0.004962493199855089, 'learning_rate': 2e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0031, 'grad_norm': 0.006774004548788071, 'learning_rate': 1.999080459770115e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0031, 'grad_norm': 0.006212218664586544, 'learning_rate': 1.99816091954023e-05, 'epoch': 0.2}\n",
      "{'loss': 0.0031, 'grad_norm': 0.006403504405170679, 'learning_rate': 1.9972413793103448e-05, 'epoch': 0.21}\n",
      "{'loss': 0.003, 'grad_norm': 0.00482612568885088, 'learning_rate': 1.9963218390804598e-05, 'epoch': 0.22}\n",
      "{'loss': 0.003, 'grad_norm': 0.00613514706492424, 'learning_rate': 1.9954022988505748e-05, 'epoch': 0.23}\n",
      "{'loss': 0.003, 'grad_norm': 0.00668787956237793, 'learning_rate': 1.9944827586206898e-05, 'epoch': 0.24}\n",
      "{'loss': 0.003, 'grad_norm': 0.0055687385611236095, 'learning_rate': 1.9935632183908048e-05, 'epoch': 0.25}\n",
      "{'loss': 0.003, 'grad_norm': 0.005634949076920748, 'learning_rate': 1.9926436781609198e-05, 'epoch': 0.26}\n",
      "{'loss': 0.003, 'grad_norm': 0.005391853395849466, 'learning_rate': 1.9917241379310344e-05, 'epoch': 0.26}\n",
      "{'loss': 0.003, 'grad_norm': 0.006601778790354729, 'learning_rate': 1.9908045977011498e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0029, 'grad_norm': 0.005993652623146772, 'learning_rate': 1.9898850574712644e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0029, 'grad_norm': 0.005295639857649803, 'learning_rate': 1.9889655172413794e-05, 'epoch': 0.29}\n",
      "{'loss': 0.0029, 'grad_norm': 0.005830582231283188, 'learning_rate': 1.9880459770114944e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0029, 'grad_norm': 0.004428736865520477, 'learning_rate': 1.9871264367816094e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0029, 'grad_norm': 0.005794888827949762, 'learning_rate': 1.9862068965517244e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0029, 'grad_norm': 0.008029160089790821, 'learning_rate': 1.9852873563218394e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0029, 'grad_norm': 0.006629328243434429, 'learning_rate': 1.984367816091954e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0029, 'grad_norm': 0.004511604551225901, 'learning_rate': 1.9834482758620694e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0029, 'grad_norm': 0.0052012186497449875, 'learning_rate': 1.982528735632184e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0029, 'grad_norm': 0.0055152918212115765, 'learning_rate': 1.981609195402299e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0029, 'grad_norm': 0.0051816487684845924, 'learning_rate': 1.980689655172414e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0029, 'grad_norm': 0.004463569261133671, 'learning_rate': 1.9797701149425287e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0029, 'grad_norm': 0.0055784983560442924, 'learning_rate': 1.978850574712644e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0028, 'grad_norm': 0.005403850227594376, 'learning_rate': 1.9779310344827587e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0028, 'grad_norm': 0.004927926696836948, 'learning_rate': 1.9770114942528737e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0028, 'grad_norm': 0.0076485867612063885, 'learning_rate': 1.9760919540229887e-05, 'epoch': 0.42}\n",
      "{'loss': 0.0028, 'grad_norm': 0.005490829702466726, 'learning_rate': 1.9751724137931037e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0028, 'grad_norm': 0.005553482566028833, 'learning_rate': 1.9742528735632186e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0028, 'grad_norm': 0.004946964792907238, 'learning_rate': 1.9733333333333336e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0028, 'grad_norm': 0.004466763231903315, 'learning_rate': 1.9724137931034483e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0028, 'grad_norm': 0.00566966412588954, 'learning_rate': 1.9714942528735633e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0028, 'grad_norm': 0.006149770226329565, 'learning_rate': 1.9705747126436783e-05, 'epoch': 0.47}\n",
      "{'loss': 0.0028, 'grad_norm': 0.006878988351672888, 'learning_rate': 1.9696551724137933e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0028, 'grad_norm': 0.005508590489625931, 'learning_rate': 1.9687356321839083e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0028, 'grad_norm': 0.005211702547967434, 'learning_rate': 1.9678160919540233e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0028, 'grad_norm': 0.005625874735414982, 'learning_rate': 1.966896551724138e-05, 'epoch': 0.51}\n",
      "{'loss': 0.0028, 'grad_norm': 0.005335975904017687, 'learning_rate': 1.9659770114942533e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0027, 'grad_norm': 0.004981022793799639, 'learning_rate': 1.965057471264368e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0027, 'grad_norm': 0.00492478720843792, 'learning_rate': 1.964137931034483e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0027, 'grad_norm': 0.004596634302288294, 'learning_rate': 1.963218390804598e-05, 'epoch': 0.55}\n",
      "{'loss': 0.0027, 'grad_norm': 0.004636380821466446, 'learning_rate': 1.9622988505747126e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0027, 'grad_norm': 0.005056212190538645, 'learning_rate': 1.961379310344828e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0028, 'grad_norm': 0.004541180096566677, 'learning_rate': 1.9604597701149425e-05, 'epoch': 0.57}\n",
      "{'loss': 0.0027, 'grad_norm': 0.00486676674336195, 'learning_rate': 1.9595402298850575e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0027, 'grad_norm': 0.0056725675240159035, 'learning_rate': 1.9586206896551725e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0027, 'grad_norm': 0.0065322802402079105, 'learning_rate': 1.9577011494252875e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0027, 'grad_norm': 0.005678699817508459, 'learning_rate': 1.9567816091954025e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0027, 'grad_norm': 0.004545630421489477, 'learning_rate': 1.9558620689655175e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0027, 'grad_norm': 0.0071410927921533585, 'learning_rate': 1.954942528735632e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0027, 'grad_norm': 0.0041346317157149315, 'learning_rate': 1.9540229885057475e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0027, 'grad_norm': 0.0072777061723172665, 'learning_rate': 1.953103448275862e-05, 'epoch': 0.65}\n",
      "{'loss': 0.0027, 'grad_norm': 0.004658079240471125, 'learning_rate': 1.952183908045977e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0027, 'grad_norm': 0.004159781616181135, 'learning_rate': 1.951264367816092e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0027, 'grad_norm': 0.004418263677507639, 'learning_rate': 1.950344827586207e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0027, 'grad_norm': 0.0057098460383713245, 'learning_rate': 1.949425287356322e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0027, 'grad_norm': 0.0045017157681286335, 'learning_rate': 1.948505747126437e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0027, 'grad_norm': 0.004800816532224417, 'learning_rate': 1.9475862068965518e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0027, 'grad_norm': 0.006742081139236689, 'learning_rate': 1.9466666666666668e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0027, 'grad_norm': 0.00448486115783453, 'learning_rate': 1.9457471264367818e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0027, 'grad_norm': 0.005035164766013622, 'learning_rate': 1.9448275862068968e-05, 'epoch': 0.73}\n",
      "{'loss': 0.0026, 'grad_norm': 0.005899858195334673, 'learning_rate': 1.9439080459770118e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0026, 'grad_norm': 0.006450220011174679, 'learning_rate': 1.9429885057471264e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0026, 'grad_norm': 0.004536379594355822, 'learning_rate': 1.9420689655172414e-05, 'epoch': 0.76}\n",
      "{'loss': 0.0027, 'grad_norm': 0.004987017717212439, 'learning_rate': 1.9411494252873564e-05, 'epoch': 0.77}\n",
      "{'loss': 0.0027, 'grad_norm': 0.004358744714409113, 'learning_rate': 1.9402298850574714e-05, 'epoch': 0.77}\n",
      "{'loss': 0.0026, 'grad_norm': 0.005016690585762262, 'learning_rate': 1.9393103448275864e-05, 'epoch': 0.78}\n",
      "{'loss': 0.0026, 'grad_norm': 0.005220101214945316, 'learning_rate': 1.9383908045977014e-05, 'epoch': 0.79}\n",
      "{'loss': 0.0026, 'grad_norm': 0.0048066116869449615, 'learning_rate': 1.937471264367816e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0026, 'grad_norm': 0.005884787067770958, 'learning_rate': 1.9365517241379314e-05, 'epoch': 0.81}\n",
      "{'loss': 0.0026, 'grad_norm': 0.00519798556342721, 'learning_rate': 1.935632183908046e-05, 'epoch': 0.82}\n",
      "{'loss': 0.0026, 'grad_norm': 0.006326110567897558, 'learning_rate': 1.934712643678161e-05, 'epoch': 0.83}\n",
      "{'loss': 0.0026, 'grad_norm': 0.005099150352180004, 'learning_rate': 1.933793103448276e-05, 'epoch': 0.84}\n",
      "{'loss': 0.0026, 'grad_norm': 0.0053649600595235825, 'learning_rate': 1.932873563218391e-05, 'epoch': 0.85}\n",
      "{'loss': 0.0026, 'grad_norm': 0.005796873942017555, 'learning_rate': 1.931954022988506e-05, 'epoch': 0.86}\n",
      "{'loss': 0.0026, 'grad_norm': 0.004944742191582918, 'learning_rate': 1.931034482758621e-05, 'epoch': 0.87}\n",
      "{'loss': 0.0026, 'grad_norm': 0.006084936670958996, 'learning_rate': 1.9301149425287357e-05, 'epoch': 0.87}\n",
      "{'loss': 0.0026, 'grad_norm': 0.005665348377078772, 'learning_rate': 1.929195402298851e-05, 'epoch': 0.88}\n",
      "{'loss': 0.0026, 'grad_norm': 0.006994425784796476, 'learning_rate': 1.9282758620689656e-05, 'epoch': 0.89}\n",
      "{'loss': 0.0026, 'grad_norm': 0.00456691300496459, 'learning_rate': 1.9273563218390806e-05, 'epoch': 0.9}\n",
      "{'loss': 0.0026, 'grad_norm': 0.005536369979381561, 'learning_rate': 1.9264367816091956e-05, 'epoch': 0.91}\n",
      "{'loss': 0.0026, 'grad_norm': 0.00455201230943203, 'learning_rate': 1.9255172413793103e-05, 'epoch': 0.92}\n",
      "{'loss': 0.0026, 'grad_norm': 0.004634058102965355, 'learning_rate': 1.9245977011494256e-05, 'epoch': 0.93}\n",
      "{'loss': 0.0026, 'grad_norm': 0.0047326041385531425, 'learning_rate': 1.9236781609195403e-05, 'epoch': 0.94}\n",
      "{'loss': 0.0026, 'grad_norm': 0.0038222805596888065, 'learning_rate': 1.9227586206896553e-05, 'epoch': 0.95}\n",
      "{'loss': 0.0026, 'grad_norm': 0.004858752712607384, 'learning_rate': 1.9218390804597703e-05, 'epoch': 0.96}\n",
      "{'loss': 0.0026, 'grad_norm': 0.005749817471951246, 'learning_rate': 1.9209195402298853e-05, 'epoch': 0.97}\n",
      "{'loss': 0.0026, 'grad_norm': 0.0053835418075323105, 'learning_rate': 1.9200000000000003e-05, 'epoch': 0.97}\n",
      "{'loss': 0.0026, 'grad_norm': 0.005418349988758564, 'learning_rate': 1.9190804597701152e-05, 'epoch': 0.98}\n",
      "{'loss': 0.0026, 'grad_norm': 0.004797665402293205, 'learning_rate': 1.91816091954023e-05, 'epoch': 0.99}\n",
      "{'loss': 0.0026, 'grad_norm': 0.005433431826531887, 'learning_rate': 1.917241379310345e-05, 'epoch': 1.0}\n",
      "{'loss': 0.0026, 'grad_norm': 0.004733308218419552, 'learning_rate': 1.91632183908046e-05, 'epoch': 1.01}\n",
      "{'loss': 0.0026, 'grad_norm': 0.0051813870668411255, 'learning_rate': 1.915402298850575e-05, 'epoch': 1.02}\n",
      "{'loss': 0.0026, 'grad_norm': 0.005268956068903208, 'learning_rate': 1.91448275862069e-05, 'epoch': 1.03}\n",
      "{'loss': 0.0026, 'grad_norm': 0.0054204282350838184, 'learning_rate': 1.913563218390805e-05, 'epoch': 1.04}\n",
      "{'loss': 0.0026, 'grad_norm': 0.005304356571286917, 'learning_rate': 1.9126436781609195e-05, 'epoch': 1.05}\n",
      "{'loss': 0.0026, 'grad_norm': 0.006548629142343998, 'learning_rate': 1.911724137931035e-05, 'epoch': 1.06}\n",
      "{'loss': 0.0026, 'grad_norm': 0.006994953844696283, 'learning_rate': 1.9108045977011495e-05, 'epoch': 1.07}\n",
      "{'loss': 0.0026, 'grad_norm': 0.006212073378264904, 'learning_rate': 1.9098850574712645e-05, 'epoch': 1.08}\n",
      "{'loss': 0.0026, 'grad_norm': 0.0058051105588674545, 'learning_rate': 1.9089655172413795e-05, 'epoch': 1.08}\n",
      "{'loss': 0.0026, 'grad_norm': 0.004641062114387751, 'learning_rate': 1.908045977011494e-05, 'epoch': 1.09}\n",
      "{'loss': 0.0026, 'grad_norm': 0.0043419827707111835, 'learning_rate': 1.9071264367816095e-05, 'epoch': 1.1}\n",
      "{'loss': 0.0026, 'grad_norm': 0.004215532448142767, 'learning_rate': 1.906206896551724e-05, 'epoch': 1.11}\n",
      "{'loss': 0.0025, 'grad_norm': 0.005790396127849817, 'learning_rate': 1.905287356321839e-05, 'epoch': 1.12}\n",
      "{'loss': 0.0026, 'grad_norm': 0.004430759698152542, 'learning_rate': 1.904367816091954e-05, 'epoch': 1.13}\n",
      "{'loss': 0.0025, 'grad_norm': 0.005440205335617065, 'learning_rate': 1.903448275862069e-05, 'epoch': 1.14}\n",
      "{'loss': 0.0026, 'grad_norm': 0.00540613429620862, 'learning_rate': 1.902528735632184e-05, 'epoch': 1.15}\n",
      "{'loss': 0.0026, 'grad_norm': 0.006851464509963989, 'learning_rate': 1.901609195402299e-05, 'epoch': 1.16}\n",
      "{'loss': 0.0025, 'grad_norm': 0.008805079385638237, 'learning_rate': 1.9006896551724138e-05, 'epoch': 1.17}\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, datasets, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sentence_transformers import losses\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = losses.MSELoss(model=student_model)\n",
    "\n",
    "\n",
    "# Create InputExample objects for training\n",
    "train_examples = [\n",
    "    InputExample(texts=[sentence], label=teacher_embedding)\n",
    "    for sentence, teacher_embedding in zip(ds['bo'], teacher_embeddings)\n",
    "]\n",
    "\n",
    "# Create a DataLoader for training\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "\n",
    "# Fine-tune the student model\n",
    "student_model.fit(\n",
    "    train_objectives=[(train_dataloader, loss_fn)],\n",
    "    epochs=20,  # Adjust the number of epochs as needed\n",
    "    output_path='./fine-tuned-minilm'  # Save the fine-tuned model\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
