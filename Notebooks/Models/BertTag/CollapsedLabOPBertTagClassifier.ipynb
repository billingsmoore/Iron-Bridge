{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Source': 'ཐུབ་པས་རྟག་ཏུ་དེ་བཞིན་སྤྱད།།',\n",
       " 'Target': 'The aspirant should move in such a way at all times.',\n",
       " 'File_Name': 'TM2382',\n",
       " 'Machine Aligned': True,\n",
       " '__index_level_0__': 0,\n",
       " 'Tag': 'Prophecies, Rituals'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset('openpecha/tagged_cleaned_MT_v1.0.3')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Blank Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition(example):\n",
    "    return example['Tag'] != ''\n",
    "\n",
    "ds = ds.filter(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Source', 'Target', 'File_Name', 'Machine Aligned', '__index_level_0__', 'Tag'],\n",
       "        num_rows: 1163105\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Source', 'Target', 'File_Name', 'Machine Aligned', '__index_level_0__', 'Tag'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Source': 'ཐུབ་པས་རྟག་ཏུ་དེ་བཞིན་སྤྱད།།',\n",
       " 'Target': 'The aspirant should move in such a way at all times.',\n",
       " 'File_Name': 'TM2382',\n",
       " 'Machine Aligned': True,\n",
       " '__index_level_0__': 0,\n",
       " 'Tag': 'Prophecies, Rituals'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapse Buddhist Lables into One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "buddhist_labels = ['Mantras',\n",
    "                    'Dzogchen',\n",
    "                    'Astrology',\n",
    "                    'Monastery',\n",
    "                    'Mahamudra',\n",
    "                    'Mind',\n",
    "                    'Meditation',\n",
    "                    'Self, Logic, Aggregates',\n",
    "                    'Tantra',\n",
    "                    'Emptiness',\n",
    "                    'Dreams',\n",
    "                    'Education, Teaching',\n",
    "                    'Ethics, Enlightenment, Wisdom',\n",
    "                    'Prophecies, Rituals',\n",
    "                    'Lama',\n",
    "                    'Samsara, Nirvana',\n",
    "                    'Milarepa, Realization, Biography',\n",
    "                    'Kayas',\n",
    "                    'Intrinsic Existence, Conventional Existence',\n",
    "                    'Time, Causality, Perception',\n",
    "                    'Natural State',\n",
    "                    'Karma, Consequences',\n",
    "                    'Dharma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_labels(example):\n",
    "    if example['Tag'] in buddhist_labels:\n",
    "        example['Tag'] = 'Buddhist'\n",
    "    return example\n",
    "\n",
    "# Apply the function to the dataset\n",
    "ds = ds.map(collapse_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Source', 'Target', 'File_Name', 'Machine Aligned', '__index_level_0__', 'Tag'],\n",
       "        num_rows: 1163105\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Source', 'Target', 'File_Name', 'Machine Aligned', '__index_level_0__', 'Tag'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Labels to Id Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = list(set(ds['train']['Tag']))\n",
    "\n",
    "# Create a label-to-index mapping\n",
    "label2id = {label: idx for idx, label in enumerate(all_tags)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "# Save label mappings for future use\n",
    "import json\n",
    "with open(\"simple_op_label_mapping.json\", \"w\") as f:\n",
    "    json.dump(label2id, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Journalism',\n",
       " 'History, Politics, Law',\n",
       " 'Business',\n",
       " 'Fiction',\n",
       " 'Science & Medicine',\n",
       " 'Buddhist',\n",
       " 'Language & Culture']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab10b05406704e6ea27d7981f518bfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1163105 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(examples):\n",
    "    tokens = tokenizer(examples[\"Target\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    tokens[\"labels\"] = [label2id[label] for label in examples[\"Tag\"]]    \n",
    "    return tokens\n",
    "\n",
    "encoded_dataset = ds.map(preprocess, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = encoded_dataset.remove_columns(['Source', 'Target', 'File_Name', 'Machine Aligned', '__index_level_0__', 'Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = encoded_dataset['train'].train_test_split(.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c606795ab87245a29f28f99b2bad86eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Load tokenizer and model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=len(label2id))\n",
    "\n",
    "# Resize embeddings to match the new tokenizer\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, references = eval_pred\n",
    "    \n",
    "    # Get predicted class indices\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(references, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(references, predictions, average=\"weighted\")\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4480/68811231.py:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbillingsmoore\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/j/Desktop/MLotsawa/Notebooks/Models/BertTag/wandb/run-20250103_224047-dfgxd16k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/billingsmoore/huggingface/runs/dfgxd16k' target=\"_blank\">en-col-op-bert-classifier</a></strong> to <a href='https://wandb.ai/billingsmoore/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/billingsmoore/huggingface' target=\"_blank\">https://wandb.ai/billingsmoore/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/billingsmoore/huggingface/runs/dfgxd16k' target=\"_blank\">https://wandb.ai/billingsmoore/huggingface/runs/dfgxd16k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f82d502fd984eb5804b9b3f7422a81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6179000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6483, 'grad_norm': 6.397555828094482, 'learning_rate': 1.9998381615148082e-05, 'epoch': 0.01}\n",
      "{'loss': 0.5102, 'grad_norm': 11.611562728881836, 'learning_rate': 1.9996763230296166e-05, 'epoch': 0.02}\n",
      "{'loss': 0.5057, 'grad_norm': 5.505033016204834, 'learning_rate': 1.9995144845444247e-05, 'epoch': 0.02}\n",
      "{'loss': 0.4955, 'grad_norm': 5.837775707244873, 'learning_rate': 1.999352646059233e-05, 'epoch': 0.03}\n",
      "{'loss': 0.481, 'grad_norm': 6.1027750968933105, 'learning_rate': 1.9991908075740415e-05, 'epoch': 0.04}\n",
      "{'loss': 0.4827, 'grad_norm': 3.4290521144866943, 'learning_rate': 1.9990289690888496e-05, 'epoch': 0.05}\n",
      "{'loss': 0.477, 'grad_norm': 6.998585224151611, 'learning_rate': 1.9988671306036576e-05, 'epoch': 0.06}\n",
      "{'loss': 0.4776, 'grad_norm': 4.99961519241333, 'learning_rate': 1.998705292118466e-05, 'epoch': 0.06}\n",
      "{'loss': 0.4714, 'grad_norm': 8.222979545593262, 'learning_rate': 1.998543453633274e-05, 'epoch': 0.07}\n",
      "{'loss': 0.4774, 'grad_norm': 1.7104167938232422, 'learning_rate': 1.9983816151480825e-05, 'epoch': 0.08}\n",
      "{'loss': 0.4591, 'grad_norm': 2.647585868835449, 'learning_rate': 1.9982197766628905e-05, 'epoch': 0.09}\n",
      "{'loss': 0.4569, 'grad_norm': 9.147218704223633, 'learning_rate': 1.9980579381776986e-05, 'epoch': 0.1}\n",
      "{'loss': 0.4525, 'grad_norm': 3.367514133453369, 'learning_rate': 1.997896099692507e-05, 'epoch': 0.11}\n",
      "{'loss': 0.4709, 'grad_norm': 3.033576726913452, 'learning_rate': 1.997734261207315e-05, 'epoch': 0.11}\n",
      "{'loss': 0.4513, 'grad_norm': 6.15392541885376, 'learning_rate': 1.9975724227221235e-05, 'epoch': 0.12}\n",
      "{'loss': 0.4593, 'grad_norm': 5.21504020690918, 'learning_rate': 1.997410584236932e-05, 'epoch': 0.13}\n",
      "{'loss': 0.4529, 'grad_norm': 8.115962028503418, 'learning_rate': 1.99724874575174e-05, 'epoch': 0.14}\n",
      "{'loss': 0.4553, 'grad_norm': 4.764174938201904, 'learning_rate': 1.9970869072665483e-05, 'epoch': 0.15}\n",
      "{'loss': 0.454, 'grad_norm': 7.3205108642578125, 'learning_rate': 1.9969250687813564e-05, 'epoch': 0.15}\n",
      "{'loss': 0.4436, 'grad_norm': 5.344163417816162, 'learning_rate': 1.9967632302961645e-05, 'epoch': 0.16}\n",
      "{'loss': 0.4404, 'grad_norm': 5.562300205230713, 'learning_rate': 1.996601391810973e-05, 'epoch': 0.17}\n",
      "{'loss': 0.4576, 'grad_norm': 3.587736129760742, 'learning_rate': 1.996439553325781e-05, 'epoch': 0.18}\n",
      "{'loss': 0.4499, 'grad_norm': 3.234518527984619, 'learning_rate': 1.9962777148405893e-05, 'epoch': 0.19}\n",
      "{'loss': 0.4731, 'grad_norm': 7.4619855880737305, 'learning_rate': 1.9961158763553974e-05, 'epoch': 0.19}\n",
      "{'loss': 0.4532, 'grad_norm': 3.8958938121795654, 'learning_rate': 1.9959540378702058e-05, 'epoch': 0.2}\n",
      "{'loss': 0.4501, 'grad_norm': 7.693896293640137, 'learning_rate': 1.995792199385014e-05, 'epoch': 0.21}\n",
      "{'loss': 0.453, 'grad_norm': 6.723462104797363, 'learning_rate': 1.9956303608998223e-05, 'epoch': 0.22}\n",
      "{'loss': 0.4498, 'grad_norm': 2.0429751873016357, 'learning_rate': 1.9954685224146303e-05, 'epoch': 0.23}\n",
      "{'loss': 0.4605, 'grad_norm': 1.73858642578125, 'learning_rate': 1.9953066839294387e-05, 'epoch': 0.23}\n",
      "{'loss': 0.4359, 'grad_norm': 4.236610412597656, 'learning_rate': 1.9951448454442468e-05, 'epoch': 0.24}\n",
      "{'loss': 0.4537, 'grad_norm': 5.709194660186768, 'learning_rate': 1.994983006959055e-05, 'epoch': 0.25}\n",
      "{'loss': 0.4522, 'grad_norm': 3.234851837158203, 'learning_rate': 1.9948211684738633e-05, 'epoch': 0.26}\n",
      "{'loss': 0.4409, 'grad_norm': 4.221322059631348, 'learning_rate': 1.9946593299886713e-05, 'epoch': 0.27}\n",
      "{'loss': 0.4423, 'grad_norm': 5.862962245941162, 'learning_rate': 1.9944974915034797e-05, 'epoch': 0.28}\n",
      "{'loss': 0.4378, 'grad_norm': 4.428182601928711, 'learning_rate': 1.994335653018288e-05, 'epoch': 0.28}\n",
      "{'loss': 0.4409, 'grad_norm': 8.447690963745117, 'learning_rate': 1.9941738145330962e-05, 'epoch': 0.29}\n",
      "{'loss': 0.4237, 'grad_norm': 4.203089237213135, 'learning_rate': 1.9940119760479046e-05, 'epoch': 0.3}\n",
      "{'loss': 0.4419, 'grad_norm': 5.818411827087402, 'learning_rate': 1.9938501375627126e-05, 'epoch': 0.31}\n",
      "{'loss': 0.4508, 'grad_norm': 3.9677956104278564, 'learning_rate': 1.9936882990775207e-05, 'epoch': 0.32}\n",
      "{'loss': 0.4399, 'grad_norm': 3.64365553855896, 'learning_rate': 1.993526460592329e-05, 'epoch': 0.32}\n",
      "{'loss': 0.438, 'grad_norm': 1.0751628875732422, 'learning_rate': 1.9933646221071372e-05, 'epoch': 0.33}\n",
      "{'loss': 0.4294, 'grad_norm': 4.478941917419434, 'learning_rate': 1.9932027836219456e-05, 'epoch': 0.34}\n",
      "{'loss': 0.445, 'grad_norm': 10.759862899780273, 'learning_rate': 1.9930409451367536e-05, 'epoch': 0.35}\n",
      "{'loss': 0.4622, 'grad_norm': 2.8118808269500732, 'learning_rate': 1.9928791066515617e-05, 'epoch': 0.36}\n",
      "{'loss': 0.4399, 'grad_norm': 4.435519695281982, 'learning_rate': 1.99271726816637e-05, 'epoch': 0.36}\n",
      "{'loss': 0.4272, 'grad_norm': 3.8325724601745605, 'learning_rate': 1.9925554296811785e-05, 'epoch': 0.37}\n",
      "{'loss': 0.4488, 'grad_norm': 3.7869980335235596, 'learning_rate': 1.9923935911959866e-05, 'epoch': 0.38}\n",
      "{'loss': 0.4201, 'grad_norm': 4.288438320159912, 'learning_rate': 1.992231752710795e-05, 'epoch': 0.39}\n",
      "{'loss': 0.4401, 'grad_norm': 5.403167247772217, 'learning_rate': 1.992069914225603e-05, 'epoch': 0.4}\n",
      "{'loss': 0.4084, 'grad_norm': 8.11252212524414, 'learning_rate': 1.991908075740411e-05, 'epoch': 0.4}\n",
      "{'loss': 0.4388, 'grad_norm': 4.625543117523193, 'learning_rate': 1.9917462372552195e-05, 'epoch': 0.41}\n",
      "{'loss': 0.4425, 'grad_norm': 4.80236291885376, 'learning_rate': 1.9915843987700276e-05, 'epoch': 0.42}\n",
      "{'loss': 0.425, 'grad_norm': 5.180977821350098, 'learning_rate': 1.991422560284836e-05, 'epoch': 0.43}\n",
      "{'loss': 0.4493, 'grad_norm': 3.1429388523101807, 'learning_rate': 1.991260721799644e-05, 'epoch': 0.44}\n",
      "{'loss': 0.43, 'grad_norm': 3.628403425216675, 'learning_rate': 1.9910988833144524e-05, 'epoch': 0.45}\n",
      "{'loss': 0.429, 'grad_norm': 4.130038261413574, 'learning_rate': 1.9909370448292605e-05, 'epoch': 0.45}\n",
      "{'loss': 0.4337, 'grad_norm': 2.6139533519744873, 'learning_rate': 1.990775206344069e-05, 'epoch': 0.46}\n",
      "{'loss': 0.4403, 'grad_norm': 1.878374695777893, 'learning_rate': 1.990613367858877e-05, 'epoch': 0.47}\n",
      "{'loss': 0.4222, 'grad_norm': 4.093039512634277, 'learning_rate': 1.9904515293736854e-05, 'epoch': 0.48}\n",
      "{'loss': 0.4389, 'grad_norm': 2.500859022140503, 'learning_rate': 1.9902896908884934e-05, 'epoch': 0.49}\n",
      "{'loss': 0.4468, 'grad_norm': 2.913548707962036, 'learning_rate': 1.9901278524033015e-05, 'epoch': 0.49}\n",
      "{'loss': 0.4228, 'grad_norm': 8.432771682739258, 'learning_rate': 1.98996601391811e-05, 'epoch': 0.5}\n",
      "{'loss': 0.4327, 'grad_norm': 4.541947364807129, 'learning_rate': 1.989804175432918e-05, 'epoch': 0.51}\n",
      "{'loss': 0.4389, 'grad_norm': 2.5536227226257324, 'learning_rate': 1.9896423369477263e-05, 'epoch': 0.52}\n",
      "{'loss': 0.4359, 'grad_norm': 3.0884456634521484, 'learning_rate': 1.9894804984625347e-05, 'epoch': 0.53}\n",
      "{'loss': 0.4444, 'grad_norm': 4.688943386077881, 'learning_rate': 1.9893186599773428e-05, 'epoch': 0.53}\n",
      "{'loss': 0.4235, 'grad_norm': 2.305968999862671, 'learning_rate': 1.9891568214921512e-05, 'epoch': 0.54}\n",
      "{'loss': 0.4326, 'grad_norm': 3.454153537750244, 'learning_rate': 1.9889949830069593e-05, 'epoch': 0.55}\n",
      "{'loss': 0.411, 'grad_norm': 8.281373977661133, 'learning_rate': 1.9888331445217673e-05, 'epoch': 0.56}\n",
      "{'loss': 0.4329, 'grad_norm': 3.710242509841919, 'learning_rate': 1.9886713060365757e-05, 'epoch': 0.57}\n",
      "{'loss': 0.4338, 'grad_norm': 4.746860504150391, 'learning_rate': 1.9885094675513838e-05, 'epoch': 0.57}\n",
      "{'loss': 0.4226, 'grad_norm': 6.580936908721924, 'learning_rate': 1.9883476290661922e-05, 'epoch': 0.58}\n",
      "{'loss': 0.4213, 'grad_norm': 7.110084533691406, 'learning_rate': 1.9881857905810003e-05, 'epoch': 0.59}\n",
      "{'loss': 0.4137, 'grad_norm': 6.635749340057373, 'learning_rate': 1.9880239520958083e-05, 'epoch': 0.6}\n",
      "{'loss': 0.4226, 'grad_norm': 2.0631017684936523, 'learning_rate': 1.9878621136106167e-05, 'epoch': 0.61}\n",
      "{'loss': 0.4404, 'grad_norm': 5.18855094909668, 'learning_rate': 1.987700275125425e-05, 'epoch': 0.61}\n",
      "{'loss': 0.4292, 'grad_norm': 8.429258346557617, 'learning_rate': 1.9875384366402332e-05, 'epoch': 0.62}\n",
      "{'loss': 0.4302, 'grad_norm': 2.622551918029785, 'learning_rate': 1.9873765981550416e-05, 'epoch': 0.63}\n",
      "{'loss': 0.4344, 'grad_norm': 4.613176345825195, 'learning_rate': 1.9872147596698497e-05, 'epoch': 0.64}\n",
      "{'loss': 0.4318, 'grad_norm': 5.214266300201416, 'learning_rate': 1.9870529211846577e-05, 'epoch': 0.65}\n",
      "{'loss': 0.4093, 'grad_norm': 3.380419969558716, 'learning_rate': 1.986891082699466e-05, 'epoch': 0.66}\n",
      "{'loss': 0.4442, 'grad_norm': 4.9024505615234375, 'learning_rate': 1.9867292442142742e-05, 'epoch': 0.66}\n",
      "{'loss': 0.4402, 'grad_norm': 3.170677423477173, 'learning_rate': 1.9865674057290826e-05, 'epoch': 0.67}\n",
      "{'loss': 0.4284, 'grad_norm': 2.2395973205566406, 'learning_rate': 1.9864055672438906e-05, 'epoch': 0.68}\n",
      "{'loss': 0.4185, 'grad_norm': 5.707152366638184, 'learning_rate': 1.986243728758699e-05, 'epoch': 0.69}\n",
      "{'loss': 0.4267, 'grad_norm': 2.1670992374420166, 'learning_rate': 1.9860818902735074e-05, 'epoch': 0.7}\n",
      "{'loss': 0.4344, 'grad_norm': 4.048093795776367, 'learning_rate': 1.9859200517883155e-05, 'epoch': 0.7}\n",
      "{'loss': 0.4216, 'grad_norm': 4.384010314941406, 'learning_rate': 1.9857582133031236e-05, 'epoch': 0.71}\n",
      "{'loss': 0.4097, 'grad_norm': 3.9292943477630615, 'learning_rate': 1.985596374817932e-05, 'epoch': 0.72}\n",
      "{'loss': 0.431, 'grad_norm': 5.33888578414917, 'learning_rate': 1.98543453633274e-05, 'epoch': 0.73}\n",
      "{'loss': 0.4364, 'grad_norm': 1.2877918481826782, 'learning_rate': 1.9852726978475484e-05, 'epoch': 0.74}\n",
      "{'loss': 0.4402, 'grad_norm': 3.3858933448791504, 'learning_rate': 1.9851108593623565e-05, 'epoch': 0.74}\n",
      "{'loss': 0.4161, 'grad_norm': 3.207390069961548, 'learning_rate': 1.9849490208771646e-05, 'epoch': 0.75}\n",
      "{'loss': 0.411, 'grad_norm': 4.796050071716309, 'learning_rate': 1.984787182391973e-05, 'epoch': 0.76}\n",
      "{'loss': 0.4098, 'grad_norm': 5.118721961975098, 'learning_rate': 1.9846253439067814e-05, 'epoch': 0.77}\n",
      "{'loss': 0.4109, 'grad_norm': 3.5356271266937256, 'learning_rate': 1.9844635054215894e-05, 'epoch': 0.78}\n",
      "{'loss': 0.4333, 'grad_norm': 3.937894821166992, 'learning_rate': 1.984301666936398e-05, 'epoch': 0.78}\n",
      "{'loss': 0.4258, 'grad_norm': 1.7274478673934937, 'learning_rate': 1.984139828451206e-05, 'epoch': 0.79}\n",
      "{'loss': 0.4187, 'grad_norm': 5.181070804595947, 'learning_rate': 1.983977989966014e-05, 'epoch': 0.8}\n",
      "{'loss': 0.4254, 'grad_norm': 6.218809604644775, 'learning_rate': 1.9838161514808224e-05, 'epoch': 0.81}\n",
      "{'loss': 0.4268, 'grad_norm': 4.151180267333984, 'learning_rate': 1.9836543129956304e-05, 'epoch': 0.82}\n",
      "{'loss': 0.4334, 'grad_norm': 3.4531753063201904, 'learning_rate': 1.9834924745104388e-05, 'epoch': 0.83}\n",
      "{'loss': 0.4422, 'grad_norm': 5.89646053314209, 'learning_rate': 1.983330636025247e-05, 'epoch': 0.83}\n",
      "{'loss': 0.4323, 'grad_norm': 2.9823620319366455, 'learning_rate': 1.983168797540055e-05, 'epoch': 0.84}\n",
      "{'loss': 0.4198, 'grad_norm': 3.742058277130127, 'learning_rate': 1.9830069590548634e-05, 'epoch': 0.85}\n",
      "{'loss': 0.4191, 'grad_norm': 5.721800327301025, 'learning_rate': 1.9828451205696718e-05, 'epoch': 0.86}\n",
      "{'loss': 0.4219, 'grad_norm': 5.152989387512207, 'learning_rate': 1.9826832820844798e-05, 'epoch': 0.87}\n",
      "{'loss': 0.4278, 'grad_norm': 3.0196709632873535, 'learning_rate': 1.9825214435992882e-05, 'epoch': 0.87}\n",
      "{'loss': 0.4266, 'grad_norm': 3.7831804752349854, 'learning_rate': 1.9823596051140963e-05, 'epoch': 0.88}\n",
      "{'loss': 0.4159, 'grad_norm': 3.7915923595428467, 'learning_rate': 1.9821977666289043e-05, 'epoch': 0.89}\n",
      "{'loss': 0.4109, 'grad_norm': 6.503130912780762, 'learning_rate': 1.9820359281437127e-05, 'epoch': 0.9}\n",
      "{'loss': 0.4135, 'grad_norm': 6.060164451599121, 'learning_rate': 1.9818740896585208e-05, 'epoch': 0.91}\n",
      "{'loss': 0.4247, 'grad_norm': 2.7887744903564453, 'learning_rate': 1.9817122511733292e-05, 'epoch': 0.91}\n",
      "{'loss': 0.423, 'grad_norm': 6.200654983520508, 'learning_rate': 1.9815504126881373e-05, 'epoch': 0.92}\n",
      "{'loss': 0.4175, 'grad_norm': 6.000941276550293, 'learning_rate': 1.9813885742029457e-05, 'epoch': 0.93}\n",
      "{'loss': 0.4323, 'grad_norm': 4.677355766296387, 'learning_rate': 1.981226735717754e-05, 'epoch': 0.94}\n",
      "{'loss': 0.4138, 'grad_norm': 4.230481147766113, 'learning_rate': 1.981064897232562e-05, 'epoch': 0.95}\n",
      "{'loss': 0.4157, 'grad_norm': 6.337557315826416, 'learning_rate': 1.9809030587473702e-05, 'epoch': 0.95}\n",
      "{'loss': 0.4373, 'grad_norm': 5.236532688140869, 'learning_rate': 1.9807412202621786e-05, 'epoch': 0.96}\n",
      "{'loss': 0.4235, 'grad_norm': 7.8983941078186035, 'learning_rate': 1.9805793817769867e-05, 'epoch': 0.97}\n",
      "{'loss': 0.4096, 'grad_norm': 2.8586277961730957, 'learning_rate': 1.980417543291795e-05, 'epoch': 0.98}\n",
      "{'loss': 0.403, 'grad_norm': 10.670340538024902, 'learning_rate': 1.980255704806603e-05, 'epoch': 0.99}\n",
      "{'loss': 0.4226, 'grad_norm': 3.7038166522979736, 'learning_rate': 1.9800938663214112e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b321338009485ea18a7eb1870dbe4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/Desktop/MLotsawa/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4207659065723419, 'eval_accuracy': 0.850268820285901, 'eval_f1': 0.8411203626221172, 'eval_precision': 0.844679736197194, 'eval_recall': 0.850268820285901, 'eval_runtime': 405.7856, 'eval_samples_per_second': 429.946, 'eval_steps_per_second': 26.874, 'epoch': 1.0}\n",
      "{'loss': 0.4095, 'grad_norm': 5.7561354637146, 'learning_rate': 1.9799320278362196e-05, 'epoch': 1.0}\n",
      "{'loss': 0.3882, 'grad_norm': 3.9415371417999268, 'learning_rate': 1.979770189351028e-05, 'epoch': 1.01}\n",
      "{'loss': 0.3695, 'grad_norm': 2.2126357555389404, 'learning_rate': 1.979608350865836e-05, 'epoch': 1.02}\n",
      "{'loss': 0.3921, 'grad_norm': 7.058658599853516, 'learning_rate': 1.9794465123806445e-05, 'epoch': 1.03}\n",
      "{'loss': 0.39, 'grad_norm': 3.2204318046569824, 'learning_rate': 1.9792846738954525e-05, 'epoch': 1.04}\n",
      "{'loss': 0.3899, 'grad_norm': 5.074982643127441, 'learning_rate': 1.9791228354102606e-05, 'epoch': 1.04}\n",
      "{'loss': 0.3672, 'grad_norm': 6.697738170623779, 'learning_rate': 1.978960996925069e-05, 'epoch': 1.05}\n",
      "{'loss': 0.3772, 'grad_norm': 3.5309019088745117, 'learning_rate': 1.978799158439877e-05, 'epoch': 1.06}\n",
      "{'loss': 0.4063, 'grad_norm': 6.145796775817871, 'learning_rate': 1.9786373199546854e-05, 'epoch': 1.07}\n",
      "{'loss': 0.3906, 'grad_norm': 14.336867332458496, 'learning_rate': 1.9784754814694935e-05, 'epoch': 1.08}\n",
      "{'loss': 0.3637, 'grad_norm': 6.303582191467285, 'learning_rate': 1.9783136429843016e-05, 'epoch': 1.08}\n",
      "{'loss': 0.3869, 'grad_norm': 5.508619785308838, 'learning_rate': 1.9781518044991103e-05, 'epoch': 1.09}\n",
      "{'loss': 0.3972, 'grad_norm': 1.6555036306381226, 'learning_rate': 1.9779899660139184e-05, 'epoch': 1.1}\n",
      "{'loss': 0.377, 'grad_norm': 2.9434072971343994, 'learning_rate': 1.9778281275287264e-05, 'epoch': 1.11}\n",
      "{'loss': 0.3876, 'grad_norm': 8.273883819580078, 'learning_rate': 1.977666289043535e-05, 'epoch': 1.12}\n",
      "{'loss': 0.3786, 'grad_norm': 3.304702043533325, 'learning_rate': 1.977504450558343e-05, 'epoch': 1.12}\n",
      "{'loss': 0.3801, 'grad_norm': 10.051471710205078, 'learning_rate': 1.9773426120731513e-05, 'epoch': 1.13}\n",
      "{'loss': 0.3687, 'grad_norm': 7.601110458374023, 'learning_rate': 1.9771807735879594e-05, 'epoch': 1.14}\n",
      "{'loss': 0.3692, 'grad_norm': 6.442054271697998, 'learning_rate': 1.9770189351027674e-05, 'epoch': 1.15}\n",
      "{'loss': 0.3703, 'grad_norm': 4.803277492523193, 'learning_rate': 1.976857096617576e-05, 'epoch': 1.16}\n",
      "{'loss': 0.3804, 'grad_norm': 6.0839409828186035, 'learning_rate': 1.976695258132384e-05, 'epoch': 1.17}\n",
      "{'loss': 0.389, 'grad_norm': 1.4884661436080933, 'learning_rate': 1.9765334196471923e-05, 'epoch': 1.17}\n",
      "{'loss': 0.3756, 'grad_norm': 6.474752902984619, 'learning_rate': 1.9763715811620007e-05, 'epoch': 1.18}\n",
      "{'loss': 0.3855, 'grad_norm': 4.999300003051758, 'learning_rate': 1.9762097426768088e-05, 'epoch': 1.19}\n",
      "{'loss': 0.399, 'grad_norm': 4.24007511138916, 'learning_rate': 1.9760479041916168e-05, 'epoch': 1.2}\n",
      "{'loss': 0.3859, 'grad_norm': 6.401206970214844, 'learning_rate': 1.9758860657064252e-05, 'epoch': 1.21}\n",
      "{'loss': 0.3701, 'grad_norm': 5.29141092300415, 'learning_rate': 1.9757242272212333e-05, 'epoch': 1.21}\n",
      "{'loss': 0.3803, 'grad_norm': 4.749730587005615, 'learning_rate': 1.9755623887360417e-05, 'epoch': 1.22}\n",
      "{'loss': 0.3745, 'grad_norm': 3.381169557571411, 'learning_rate': 1.9754005502508498e-05, 'epoch': 1.23}\n",
      "{'loss': 0.4044, 'grad_norm': 2.6697189807891846, 'learning_rate': 1.9752387117656578e-05, 'epoch': 1.24}\n",
      "{'loss': 0.382, 'grad_norm': 6.0044050216674805, 'learning_rate': 1.9750768732804662e-05, 'epoch': 1.25}\n",
      "{'loss': 0.3657, 'grad_norm': 6.555266380310059, 'learning_rate': 1.9749150347952746e-05, 'epoch': 1.25}\n",
      "{'loss': 0.3894, 'grad_norm': 4.334022521972656, 'learning_rate': 1.9747531963100827e-05, 'epoch': 1.26}\n",
      "{'loss': 0.3841, 'grad_norm': 10.964839935302734, 'learning_rate': 1.974591357824891e-05, 'epoch': 1.27}\n",
      "{'loss': 0.3887, 'grad_norm': 2.7996251583099365, 'learning_rate': 1.974429519339699e-05, 'epoch': 1.28}\n",
      "{'loss': 0.3857, 'grad_norm': 5.059066295623779, 'learning_rate': 1.9742676808545072e-05, 'epoch': 1.29}\n",
      "{'loss': 0.3951, 'grad_norm': 3.4029006958007812, 'learning_rate': 1.9741058423693156e-05, 'epoch': 1.29}\n",
      "{'loss': 0.3782, 'grad_norm': 12.318277359008789, 'learning_rate': 1.9739440038841237e-05, 'epoch': 1.3}\n",
      "{'loss': 0.3877, 'grad_norm': 0.5347973108291626, 'learning_rate': 1.973782165398932e-05, 'epoch': 1.31}\n",
      "{'loss': 0.374, 'grad_norm': 3.0646755695343018, 'learning_rate': 1.97362032691374e-05, 'epoch': 1.32}\n",
      "{'loss': 0.381, 'grad_norm': 6.1161651611328125, 'learning_rate': 1.9734584884285482e-05, 'epoch': 1.33}\n",
      "{'loss': 0.3792, 'grad_norm': 7.647335529327393, 'learning_rate': 1.973296649943357e-05, 'epoch': 1.34}\n",
      "{'loss': 0.3882, 'grad_norm': 3.9609453678131104, 'learning_rate': 1.973134811458165e-05, 'epoch': 1.34}\n",
      "{'loss': 0.3857, 'grad_norm': 2.6867713928222656, 'learning_rate': 1.972972972972973e-05, 'epoch': 1.35}\n",
      "{'loss': 0.3927, 'grad_norm': 1.903730869293213, 'learning_rate': 1.9728111344877815e-05, 'epoch': 1.36}\n",
      "{'loss': 0.3818, 'grad_norm': 2.9240849018096924, 'learning_rate': 1.9726492960025895e-05, 'epoch': 1.37}\n",
      "{'loss': 0.3747, 'grad_norm': 2.5571694374084473, 'learning_rate': 1.972487457517398e-05, 'epoch': 1.38}\n",
      "{'loss': 0.377, 'grad_norm': 1.51309072971344, 'learning_rate': 1.972325619032206e-05, 'epoch': 1.38}\n",
      "{'loss': 0.3963, 'grad_norm': 4.6566481590271, 'learning_rate': 1.972163780547014e-05, 'epoch': 1.39}\n",
      "{'loss': 0.3852, 'grad_norm': 6.655205726623535, 'learning_rate': 1.9720019420618225e-05, 'epoch': 1.4}\n",
      "{'loss': 0.3914, 'grad_norm': 8.015519142150879, 'learning_rate': 1.9718401035766305e-05, 'epoch': 1.41}\n",
      "{'loss': 0.3797, 'grad_norm': 4.611347198486328, 'learning_rate': 1.971678265091439e-05, 'epoch': 1.42}\n",
      "{'loss': 0.3751, 'grad_norm': 13.166491508483887, 'learning_rate': 1.9715164266062473e-05, 'epoch': 1.42}\n",
      "{'loss': 0.3906, 'grad_norm': 4.969786167144775, 'learning_rate': 1.9713545881210554e-05, 'epoch': 1.43}\n",
      "{'loss': 0.3882, 'grad_norm': 3.697606325149536, 'learning_rate': 1.9711927496358634e-05, 'epoch': 1.44}\n",
      "{'loss': 0.3891, 'grad_norm': 5.470523357391357, 'learning_rate': 1.971030911150672e-05, 'epoch': 1.45}\n",
      "{'loss': 0.3662, 'grad_norm': 10.898530006408691, 'learning_rate': 1.97086907266548e-05, 'epoch': 1.46}\n",
      "{'loss': 0.3789, 'grad_norm': 3.2942657470703125, 'learning_rate': 1.9707072341802883e-05, 'epoch': 1.46}\n",
      "{'loss': 0.3922, 'grad_norm': 2.5990488529205322, 'learning_rate': 1.9705453956950964e-05, 'epoch': 1.47}\n",
      "{'loss': 0.3769, 'grad_norm': 26.848995208740234, 'learning_rate': 1.9703835572099044e-05, 'epoch': 1.48}\n",
      "{'loss': 0.3719, 'grad_norm': 3.5758681297302246, 'learning_rate': 1.970221718724713e-05, 'epoch': 1.49}\n",
      "{'loss': 0.3728, 'grad_norm': 5.16801118850708, 'learning_rate': 1.9700598802395212e-05, 'epoch': 1.5}\n",
      "{'loss': 0.378, 'grad_norm': 4.476804256439209, 'learning_rate': 1.9698980417543293e-05, 'epoch': 1.51}\n",
      "{'loss': 0.3925, 'grad_norm': 1.7904709577560425, 'learning_rate': 1.9697362032691377e-05, 'epoch': 1.51}\n",
      "{'loss': 0.3951, 'grad_norm': 2.6201133728027344, 'learning_rate': 1.9695743647839458e-05, 'epoch': 1.52}\n",
      "{'loss': 0.3722, 'grad_norm': 7.375740051269531, 'learning_rate': 1.9694125262987542e-05, 'epoch': 1.53}\n",
      "{'loss': 0.4088, 'grad_norm': 9.044299125671387, 'learning_rate': 1.9692506878135622e-05, 'epoch': 1.54}\n",
      "{'loss': 0.3631, 'grad_norm': 2.6592650413513184, 'learning_rate': 1.9690888493283703e-05, 'epoch': 1.55}\n",
      "{'loss': 0.3886, 'grad_norm': 3.3277337551116943, 'learning_rate': 1.9689270108431787e-05, 'epoch': 1.55}\n",
      "{'loss': 0.37, 'grad_norm': 4.184875965118408, 'learning_rate': 1.9687651723579868e-05, 'epoch': 1.56}\n",
      "{'loss': 0.3913, 'grad_norm': 4.327247619628906, 'learning_rate': 1.968603333872795e-05, 'epoch': 1.57}\n",
      "{'loss': 0.3787, 'grad_norm': 8.229113578796387, 'learning_rate': 1.9684414953876036e-05, 'epoch': 1.58}\n",
      "{'loss': 0.4027, 'grad_norm': 3.6290323734283447, 'learning_rate': 1.9682796569024116e-05, 'epoch': 1.59}\n",
      "{'loss': 0.3714, 'grad_norm': 5.876583576202393, 'learning_rate': 1.9681178184172197e-05, 'epoch': 1.59}\n",
      "{'loss': 0.3862, 'grad_norm': 4.982997417449951, 'learning_rate': 1.967955979932028e-05, 'epoch': 1.6}\n",
      "{'loss': 0.3746, 'grad_norm': 2.4255459308624268, 'learning_rate': 1.967794141446836e-05, 'epoch': 1.61}\n",
      "{'loss': 0.3911, 'grad_norm': 2.0275652408599854, 'learning_rate': 1.9676323029616446e-05, 'epoch': 1.62}\n",
      "{'loss': 0.3789, 'grad_norm': 9.725762367248535, 'learning_rate': 1.9674704644764526e-05, 'epoch': 1.63}\n",
      "{'loss': 0.3834, 'grad_norm': 7.731186389923096, 'learning_rate': 1.9673086259912607e-05, 'epoch': 1.63}\n",
      "{'loss': 0.3775, 'grad_norm': 4.9183549880981445, 'learning_rate': 1.967146787506069e-05, 'epoch': 1.64}\n",
      "{'loss': 0.3858, 'grad_norm': 7.126104831695557, 'learning_rate': 1.966984949020877e-05, 'epoch': 1.65}\n",
      "{'loss': 0.3759, 'grad_norm': 1.905492901802063, 'learning_rate': 1.9668231105356855e-05, 'epoch': 1.66}\n",
      "{'loss': 0.3847, 'grad_norm': 9.550838470458984, 'learning_rate': 1.966661272050494e-05, 'epoch': 1.67}\n",
      "{'loss': 0.3894, 'grad_norm': 3.3003430366516113, 'learning_rate': 1.966499433565302e-05, 'epoch': 1.68}\n",
      "{'loss': 0.3966, 'grad_norm': 3.079019069671631, 'learning_rate': 1.96633759508011e-05, 'epoch': 1.68}\n",
      "{'loss': 0.3901, 'grad_norm': 2.685725212097168, 'learning_rate': 1.9661757565949185e-05, 'epoch': 1.69}\n",
      "{'loss': 0.3928, 'grad_norm': 8.434582710266113, 'learning_rate': 1.9660139181097265e-05, 'epoch': 1.7}\n",
      "{'loss': 0.3935, 'grad_norm': 2.0416860580444336, 'learning_rate': 1.965852079624535e-05, 'epoch': 1.71}\n",
      "{'loss': 0.3868, 'grad_norm': 16.5532283782959, 'learning_rate': 1.965690241139343e-05, 'epoch': 1.72}\n",
      "{'loss': 0.3749, 'grad_norm': 3.128431558609009, 'learning_rate': 1.965528402654151e-05, 'epoch': 1.72}\n",
      "{'loss': 0.3852, 'grad_norm': 5.659575462341309, 'learning_rate': 1.9653665641689595e-05, 'epoch': 1.73}\n",
      "{'loss': 0.3873, 'grad_norm': 9.73188591003418, 'learning_rate': 1.965204725683768e-05, 'epoch': 1.74}\n",
      "{'loss': 0.3887, 'grad_norm': 10.698649406433105, 'learning_rate': 1.965042887198576e-05, 'epoch': 1.75}\n",
      "{'loss': 0.3915, 'grad_norm': 2.7155816555023193, 'learning_rate': 1.9648810487133843e-05, 'epoch': 1.76}\n",
      "{'loss': 0.3909, 'grad_norm': 4.556356906890869, 'learning_rate': 1.9647192102281924e-05, 'epoch': 1.76}\n",
      "{'loss': 0.3912, 'grad_norm': 2.859666585922241, 'learning_rate': 1.9645573717430008e-05, 'epoch': 1.77}\n",
      "{'loss': 0.3873, 'grad_norm': 8.503257751464844, 'learning_rate': 1.964395533257809e-05, 'epoch': 1.78}\n",
      "{'loss': 0.3719, 'grad_norm': 6.020317554473877, 'learning_rate': 1.964233694772617e-05, 'epoch': 1.79}\n",
      "{'loss': 0.3875, 'grad_norm': 2.9119246006011963, 'learning_rate': 1.9640718562874253e-05, 'epoch': 1.8}\n",
      "{'loss': 0.3965, 'grad_norm': 4.960289001464844, 'learning_rate': 1.9639100178022334e-05, 'epoch': 1.8}\n",
      "{'loss': 0.3873, 'grad_norm': 3.589538812637329, 'learning_rate': 1.9637481793170418e-05, 'epoch': 1.81}\n",
      "{'loss': 0.3888, 'grad_norm': 3.8008875846862793, 'learning_rate': 1.9635863408318502e-05, 'epoch': 1.82}\n",
      "{'loss': 0.3734, 'grad_norm': 2.9902212619781494, 'learning_rate': 1.9634245023466583e-05, 'epoch': 1.83}\n",
      "{'loss': 0.3687, 'grad_norm': 5.07757043838501, 'learning_rate': 1.9632626638614663e-05, 'epoch': 1.84}\n",
      "{'loss': 0.3876, 'grad_norm': 4.917626857757568, 'learning_rate': 1.9631008253762747e-05, 'epoch': 1.84}\n",
      "{'loss': 0.3949, 'grad_norm': 5.266748428344727, 'learning_rate': 1.9629389868910828e-05, 'epoch': 1.85}\n",
      "{'loss': 0.3875, 'grad_norm': 6.806153774261475, 'learning_rate': 1.9627771484058912e-05, 'epoch': 1.86}\n",
      "{'loss': 0.3932, 'grad_norm': 1.2895246744155884, 'learning_rate': 1.9626153099206992e-05, 'epoch': 1.87}\n",
      "{'loss': 0.3826, 'grad_norm': 5.411766529083252, 'learning_rate': 1.9624534714355073e-05, 'epoch': 1.88}\n",
      "{'loss': 0.3834, 'grad_norm': 5.249417781829834, 'learning_rate': 1.9622916329503157e-05, 'epoch': 1.89}\n",
      "{'loss': 0.3806, 'grad_norm': 4.83758544921875, 'learning_rate': 1.9621297944651238e-05, 'epoch': 1.89}\n",
      "{'loss': 0.3864, 'grad_norm': 4.56509256362915, 'learning_rate': 1.9619679559799322e-05, 'epoch': 1.9}\n",
      "{'loss': 0.3951, 'grad_norm': 7.59940767288208, 'learning_rate': 1.9618061174947406e-05, 'epoch': 1.91}\n",
      "{'loss': 0.3884, 'grad_norm': 7.320795059204102, 'learning_rate': 1.9616442790095486e-05, 'epoch': 1.92}\n",
      "{'loss': 0.4081, 'grad_norm': 3.8929061889648438, 'learning_rate': 1.961482440524357e-05, 'epoch': 1.93}\n",
      "{'loss': 0.3962, 'grad_norm': 6.169473648071289, 'learning_rate': 1.961320602039165e-05, 'epoch': 1.93}\n",
      "{'loss': 0.3833, 'grad_norm': 9.86396598815918, 'learning_rate': 1.961158763553973e-05, 'epoch': 1.94}\n",
      "{'loss': 0.3915, 'grad_norm': 7.037533283233643, 'learning_rate': 1.9609969250687816e-05, 'epoch': 1.95}\n",
      "{'loss': 0.3842, 'grad_norm': 2.946046829223633, 'learning_rate': 1.9608350865835896e-05, 'epoch': 1.96}\n",
      "{'loss': 0.3861, 'grad_norm': 2.0628180503845215, 'learning_rate': 1.960673248098398e-05, 'epoch': 1.97}\n",
      "{'loss': 0.3841, 'grad_norm': 3.434830904006958, 'learning_rate': 1.960511409613206e-05, 'epoch': 1.97}\n",
      "{'loss': 0.3836, 'grad_norm': 8.352632522583008, 'learning_rate': 1.9603495711280145e-05, 'epoch': 1.98}\n",
      "{'loss': 0.3947, 'grad_norm': 5.824683666229248, 'learning_rate': 1.9601877326428226e-05, 'epoch': 1.99}\n",
      "{'loss': 0.3883, 'grad_norm': 5.267368793487549, 'learning_rate': 1.960025894157631e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f043d7582294b78abd74b41da65468d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4310838282108307, 'eval_accuracy': 0.8525615306134147, 'eval_f1': 0.8450336886101782, 'eval_precision': 0.8480871413328013, 'eval_recall': 0.8525615306134147, 'eval_runtime': 406.4293, 'eval_samples_per_second': 429.265, 'eval_steps_per_second': 26.831, 'epoch': 2.0}\n",
      "{'loss': 0.341, 'grad_norm': 4.577843189239502, 'learning_rate': 1.959864055672439e-05, 'epoch': 2.01}\n",
      "{'loss': 0.3302, 'grad_norm': 3.8836381435394287, 'learning_rate': 1.9597022171872474e-05, 'epoch': 2.01}\n",
      "{'loss': 0.3301, 'grad_norm': 5.883388996124268, 'learning_rate': 1.9595403787020555e-05, 'epoch': 2.02}\n",
      "{'loss': 0.3353, 'grad_norm': 2.8376076221466064, 'learning_rate': 1.9593785402168635e-05, 'epoch': 2.03}\n",
      "{'loss': 0.3227, 'grad_norm': 4.838154315948486, 'learning_rate': 1.959216701731672e-05, 'epoch': 2.04}\n",
      "{'loss': 0.328, 'grad_norm': 8.006811141967773, 'learning_rate': 1.95905486324648e-05, 'epoch': 2.05}\n",
      "{'loss': 0.3237, 'grad_norm': 2.5016961097717285, 'learning_rate': 1.9588930247612884e-05, 'epoch': 2.06}\n",
      "{'loss': 0.3289, 'grad_norm': 12.661128044128418, 'learning_rate': 1.9587311862760968e-05, 'epoch': 2.06}\n",
      "{'loss': 0.3192, 'grad_norm': 3.8976621627807617, 'learning_rate': 1.958569347790905e-05, 'epoch': 2.07}\n",
      "{'loss': 0.3124, 'grad_norm': 5.26003885269165, 'learning_rate': 1.958407509305713e-05, 'epoch': 2.08}\n",
      "{'loss': 0.3151, 'grad_norm': 1.2159231901168823, 'learning_rate': 1.9582456708205213e-05, 'epoch': 2.09}\n",
      "{'loss': 0.3311, 'grad_norm': 1.0685315132141113, 'learning_rate': 1.9580838323353294e-05, 'epoch': 2.1}\n",
      "{'loss': 0.3365, 'grad_norm': 8.729470252990723, 'learning_rate': 1.9579219938501378e-05, 'epoch': 2.1}\n",
      "{'loss': 0.3237, 'grad_norm': 2.881078004837036, 'learning_rate': 1.957760155364946e-05, 'epoch': 2.11}\n",
      "{'loss': 0.3272, 'grad_norm': 13.25275707244873, 'learning_rate': 1.957598316879754e-05, 'epoch': 2.12}\n",
      "{'loss': 0.3046, 'grad_norm': 5.68534517288208, 'learning_rate': 1.9574364783945623e-05, 'epoch': 2.13}\n",
      "{'loss': 0.3438, 'grad_norm': 13.116397857666016, 'learning_rate': 1.9572746399093704e-05, 'epoch': 2.14}\n",
      "{'loss': 0.3425, 'grad_norm': 5.029816627502441, 'learning_rate': 1.9571128014241788e-05, 'epoch': 2.14}\n",
      "{'loss': 0.3333, 'grad_norm': 13.244330406188965, 'learning_rate': 1.9569509629389872e-05, 'epoch': 2.15}\n",
      "{'loss': 0.3404, 'grad_norm': 6.083303928375244, 'learning_rate': 1.9567891244537953e-05, 'epoch': 2.16}\n",
      "{'loss': 0.3303, 'grad_norm': 4.202506065368652, 'learning_rate': 1.9566272859686037e-05, 'epoch': 2.17}\n",
      "{'loss': 0.3376, 'grad_norm': 7.619997024536133, 'learning_rate': 1.9564654474834117e-05, 'epoch': 2.18}\n",
      "{'loss': 0.3284, 'grad_norm': 8.605474472045898, 'learning_rate': 1.9563036089982198e-05, 'epoch': 2.18}\n",
      "{'loss': 0.3532, 'grad_norm': 19.71392250061035, 'learning_rate': 1.9561417705130282e-05, 'epoch': 2.19}\n",
      "{'loss': 0.3219, 'grad_norm': 6.431569576263428, 'learning_rate': 1.9559799320278363e-05, 'epoch': 2.2}\n",
      "{'loss': 0.3204, 'grad_norm': 7.613591194152832, 'learning_rate': 1.9558180935426447e-05, 'epoch': 2.21}\n",
      "{'loss': 0.3439, 'grad_norm': 10.477804183959961, 'learning_rate': 1.9556562550574527e-05, 'epoch': 2.22}\n",
      "{'loss': 0.3414, 'grad_norm': 4.51594877243042, 'learning_rate': 1.955494416572261e-05, 'epoch': 2.23}\n",
      "{'loss': 0.3408, 'grad_norm': 14.25355339050293, 'learning_rate': 1.9553325780870692e-05, 'epoch': 2.23}\n",
      "{'loss': 0.3475, 'grad_norm': 5.039206027984619, 'learning_rate': 1.9551707396018776e-05, 'epoch': 2.24}\n",
      "{'loss': 0.3245, 'grad_norm': 3.201517343521118, 'learning_rate': 1.9550089011166856e-05, 'epoch': 2.25}\n",
      "{'loss': 0.3316, 'grad_norm': 8.964094161987305, 'learning_rate': 1.954847062631494e-05, 'epoch': 2.26}\n",
      "{'loss': 0.3315, 'grad_norm': 6.779498100280762, 'learning_rate': 1.954685224146302e-05, 'epoch': 2.27}\n",
      "{'loss': 0.3244, 'grad_norm': 7.134448051452637, 'learning_rate': 1.9545233856611102e-05, 'epoch': 2.27}\n",
      "{'loss': 0.3491, 'grad_norm': 7.765393257141113, 'learning_rate': 1.9543615471759186e-05, 'epoch': 2.28}\n",
      "{'loss': 0.3425, 'grad_norm': 10.254922866821289, 'learning_rate': 1.9541997086907266e-05, 'epoch': 2.29}\n",
      "{'loss': 0.3416, 'grad_norm': 11.71365737915039, 'learning_rate': 1.954037870205535e-05, 'epoch': 2.3}\n",
      "{'loss': 0.3297, 'grad_norm': 8.628997802734375, 'learning_rate': 1.9538760317203434e-05, 'epoch': 2.31}\n",
      "{'loss': 0.3329, 'grad_norm': 7.42291784286499, 'learning_rate': 1.9537141932351515e-05, 'epoch': 2.31}\n",
      "{'loss': 0.35, 'grad_norm': 1.7553731203079224, 'learning_rate': 1.95355235474996e-05, 'epoch': 2.32}\n",
      "{'loss': 0.3314, 'grad_norm': 5.8523664474487305, 'learning_rate': 1.953390516264768e-05, 'epoch': 2.33}\n",
      "{'loss': 0.3292, 'grad_norm': 2.025146961212158, 'learning_rate': 1.953228677779576e-05, 'epoch': 2.34}\n",
      "{'loss': 0.3294, 'grad_norm': 11.586417198181152, 'learning_rate': 1.9530668392943844e-05, 'epoch': 2.35}\n",
      "{'loss': 0.3418, 'grad_norm': 5.105679512023926, 'learning_rate': 1.9529050008091925e-05, 'epoch': 2.35}\n",
      "{'loss': 0.337, 'grad_norm': 11.264216423034668, 'learning_rate': 1.952743162324001e-05, 'epoch': 2.36}\n",
      "{'loss': 0.359, 'grad_norm': 8.026334762573242, 'learning_rate': 1.952581323838809e-05, 'epoch': 2.37}\n",
      "{'loss': 0.3445, 'grad_norm': 3.4531373977661133, 'learning_rate': 1.952419485353617e-05, 'epoch': 2.38}\n",
      "{'loss': 0.3472, 'grad_norm': 5.5076117515563965, 'learning_rate': 1.9522576468684254e-05, 'epoch': 2.39}\n",
      "{'loss': 0.329, 'grad_norm': 5.983109951019287, 'learning_rate': 1.9520958083832338e-05, 'epoch': 2.4}\n",
      "{'loss': 0.3456, 'grad_norm': 11.679645538330078, 'learning_rate': 1.951933969898042e-05, 'epoch': 2.4}\n",
      "{'loss': 0.3351, 'grad_norm': 5.9161577224731445, 'learning_rate': 1.9517721314128503e-05, 'epoch': 2.41}\n",
      "{'loss': 0.3449, 'grad_norm': 1.4821438789367676, 'learning_rate': 1.9516102929276584e-05, 'epoch': 2.42}\n",
      "{'loss': 0.3332, 'grad_norm': 4.475252151489258, 'learning_rate': 1.9514484544424664e-05, 'epoch': 2.43}\n",
      "{'loss': 0.341, 'grad_norm': 4.4212541580200195, 'learning_rate': 1.9512866159572748e-05, 'epoch': 2.44}\n",
      "{'loss': 0.3376, 'grad_norm': 7.137694358825684, 'learning_rate': 1.951124777472083e-05, 'epoch': 2.44}\n",
      "{'loss': 0.3331, 'grad_norm': 4.423847198486328, 'learning_rate': 1.9509629389868913e-05, 'epoch': 2.45}\n",
      "{'loss': 0.351, 'grad_norm': 5.348424911499023, 'learning_rate': 1.9508011005016997e-05, 'epoch': 2.46}\n",
      "{'loss': 0.3277, 'grad_norm': 5.183553218841553, 'learning_rate': 1.9506392620165077e-05, 'epoch': 2.47}\n",
      "{'loss': 0.3427, 'grad_norm': 5.904998302459717, 'learning_rate': 1.9504774235313158e-05, 'epoch': 2.48}\n",
      "{'loss': 0.3508, 'grad_norm': 4.575468063354492, 'learning_rate': 1.9503155850461242e-05, 'epoch': 2.48}\n",
      "{'loss': 0.3353, 'grad_norm': 7.587416648864746, 'learning_rate': 1.9501537465609323e-05, 'epoch': 2.49}\n",
      "{'loss': 0.3194, 'grad_norm': 8.969244003295898, 'learning_rate': 1.9499919080757407e-05, 'epoch': 2.5}\n",
      "{'loss': 0.3541, 'grad_norm': 5.970902919769287, 'learning_rate': 1.9498300695905487e-05, 'epoch': 2.51}\n",
      "{'loss': 0.3544, 'grad_norm': 4.288913726806641, 'learning_rate': 1.949668231105357e-05, 'epoch': 2.52}\n",
      "{'loss': 0.3309, 'grad_norm': 0.9453678131103516, 'learning_rate': 1.9495063926201652e-05, 'epoch': 2.52}\n",
      "{'loss': 0.3363, 'grad_norm': 8.2301025390625, 'learning_rate': 1.9493445541349733e-05, 'epoch': 2.53}\n",
      "{'loss': 0.3536, 'grad_norm': 7.6589484214782715, 'learning_rate': 1.9491827156497817e-05, 'epoch': 2.54}\n",
      "{'loss': 0.3304, 'grad_norm': 8.44205379486084, 'learning_rate': 1.94902087716459e-05, 'epoch': 2.55}\n",
      "{'loss': 0.3316, 'grad_norm': 13.06281566619873, 'learning_rate': 1.948859038679398e-05, 'epoch': 2.56}\n",
      "{'loss': 0.3469, 'grad_norm': 4.247103214263916, 'learning_rate': 1.9486972001942065e-05, 'epoch': 2.57}\n",
      "{'loss': 0.3438, 'grad_norm': 19.50005531311035, 'learning_rate': 1.9485353617090146e-05, 'epoch': 2.57}\n",
      "{'loss': 0.339, 'grad_norm': 3.106111526489258, 'learning_rate': 1.9483735232238227e-05, 'epoch': 2.58}\n",
      "{'loss': 0.3458, 'grad_norm': 9.843362808227539, 'learning_rate': 1.948211684738631e-05, 'epoch': 2.59}\n",
      "{'loss': 0.3389, 'grad_norm': 4.284264087677002, 'learning_rate': 1.948049846253439e-05, 'epoch': 2.6}\n",
      "{'loss': 0.3389, 'grad_norm': 9.853842735290527, 'learning_rate': 1.9478880077682475e-05, 'epoch': 2.61}\n",
      "{'loss': 0.3489, 'grad_norm': 6.752362251281738, 'learning_rate': 1.9477261692830556e-05, 'epoch': 2.61}\n",
      "{'loss': 0.3318, 'grad_norm': 5.636856555938721, 'learning_rate': 1.947564330797864e-05, 'epoch': 2.62}\n",
      "{'loss': 0.346, 'grad_norm': 7.661250591278076, 'learning_rate': 1.947402492312672e-05, 'epoch': 2.63}\n",
      "{'loss': 0.3442, 'grad_norm': 4.302987575531006, 'learning_rate': 1.9472406538274804e-05, 'epoch': 2.64}\n",
      "{'loss': 0.3367, 'grad_norm': 15.78766918182373, 'learning_rate': 1.9470788153422885e-05, 'epoch': 2.65}\n",
      "{'loss': 0.3427, 'grad_norm': 11.378196716308594, 'learning_rate': 1.946916976857097e-05, 'epoch': 2.65}\n",
      "{'loss': 0.3549, 'grad_norm': 2.674769163131714, 'learning_rate': 1.946755138371905e-05, 'epoch': 2.66}\n",
      "{'loss': 0.354, 'grad_norm': 4.345941066741943, 'learning_rate': 1.946593299886713e-05, 'epoch': 2.67}\n",
      "{'loss': 0.3478, 'grad_norm': 3.118136405944824, 'learning_rate': 1.9464314614015214e-05, 'epoch': 2.68}\n",
      "{'loss': 0.3497, 'grad_norm': 7.062602519989014, 'learning_rate': 1.9462696229163295e-05, 'epoch': 2.69}\n",
      "{'loss': 0.3526, 'grad_norm': 5.38215446472168, 'learning_rate': 1.946107784431138e-05, 'epoch': 2.69}\n",
      "{'loss': 0.3536, 'grad_norm': 2.994473934173584, 'learning_rate': 1.9459459459459463e-05, 'epoch': 2.7}\n",
      "{'loss': 0.3502, 'grad_norm': 11.020488739013672, 'learning_rate': 1.9457841074607544e-05, 'epoch': 2.71}\n",
      "{'loss': 0.3488, 'grad_norm': 7.761448383331299, 'learning_rate': 1.9456222689755628e-05, 'epoch': 2.72}\n",
      "{'loss': 0.3426, 'grad_norm': 5.4775543212890625, 'learning_rate': 1.945460430490371e-05, 'epoch': 2.73}\n",
      "{'loss': 0.3565, 'grad_norm': 9.282849311828613, 'learning_rate': 1.945298592005179e-05, 'epoch': 2.74}\n",
      "{'loss': 0.3432, 'grad_norm': 7.613106727600098, 'learning_rate': 1.9451367535199873e-05, 'epoch': 2.74}\n",
      "{'loss': 0.346, 'grad_norm': 9.493396759033203, 'learning_rate': 1.9449749150347954e-05, 'epoch': 2.75}\n",
      "{'loss': 0.3478, 'grad_norm': 9.16850471496582, 'learning_rate': 1.9448130765496038e-05, 'epoch': 2.76}\n",
      "{'loss': 0.3247, 'grad_norm': 3.8684744834899902, 'learning_rate': 1.9446512380644118e-05, 'epoch': 2.77}\n",
      "{'loss': 0.344, 'grad_norm': 1.9471827745437622, 'learning_rate': 1.94448939957922e-05, 'epoch': 2.78}\n",
      "{'loss': 0.352, 'grad_norm': 11.18764591217041, 'learning_rate': 1.9443275610940283e-05, 'epoch': 2.78}\n",
      "{'loss': 0.3353, 'grad_norm': 7.453202724456787, 'learning_rate': 1.9441657226088367e-05, 'epoch': 2.79}\n",
      "{'loss': 0.3513, 'grad_norm': 14.259703636169434, 'learning_rate': 1.9440038841236448e-05, 'epoch': 2.8}\n",
      "{'loss': 0.3565, 'grad_norm': 7.084933280944824, 'learning_rate': 1.943842045638453e-05, 'epoch': 2.81}\n",
      "{'loss': 0.3623, 'grad_norm': 6.9887237548828125, 'learning_rate': 1.9436802071532612e-05, 'epoch': 2.82}\n",
      "{'loss': 0.3462, 'grad_norm': 4.2319746017456055, 'learning_rate': 1.9435183686680693e-05, 'epoch': 2.82}\n",
      "{'loss': 0.337, 'grad_norm': 5.825637340545654, 'learning_rate': 1.9433565301828777e-05, 'epoch': 2.83}\n",
      "{'loss': 0.3396, 'grad_norm': 2.7914578914642334, 'learning_rate': 1.9431946916976857e-05, 'epoch': 2.84}\n",
      "{'loss': 0.3559, 'grad_norm': 6.069055557250977, 'learning_rate': 1.943032853212494e-05, 'epoch': 2.85}\n",
      "{'loss': 0.3602, 'grad_norm': 13.240017890930176, 'learning_rate': 1.9428710147273022e-05, 'epoch': 2.86}\n",
      "{'loss': 0.3387, 'grad_norm': 3.697275161743164, 'learning_rate': 1.9427091762421106e-05, 'epoch': 2.86}\n",
      "{'loss': 0.3405, 'grad_norm': 2.574172019958496, 'learning_rate': 1.9425473377569187e-05, 'epoch': 2.87}\n",
      "{'loss': 0.356, 'grad_norm': 6.089875221252441, 'learning_rate': 1.942385499271727e-05, 'epoch': 2.88}\n",
      "{'loss': 0.354, 'grad_norm': 5.191273212432861, 'learning_rate': 1.942223660786535e-05, 'epoch': 2.89}\n",
      "{'loss': 0.3528, 'grad_norm': 7.522876262664795, 'learning_rate': 1.9420618223013435e-05, 'epoch': 2.9}\n",
      "{'loss': 0.3557, 'grad_norm': 5.787431240081787, 'learning_rate': 1.9418999838161516e-05, 'epoch': 2.91}\n",
      "{'loss': 0.3534, 'grad_norm': 13.298937797546387, 'learning_rate': 1.94173814533096e-05, 'epoch': 2.91}\n",
      "{'loss': 0.3422, 'grad_norm': 9.366703033447266, 'learning_rate': 1.941576306845768e-05, 'epoch': 2.92}\n",
      "{'loss': 0.3383, 'grad_norm': 14.715930938720703, 'learning_rate': 1.941414468360576e-05, 'epoch': 2.93}\n",
      "{'loss': 0.3604, 'grad_norm': 4.721395969390869, 'learning_rate': 1.9412526298753845e-05, 'epoch': 2.94}\n",
      "{'loss': 0.3629, 'grad_norm': 7.679386138916016, 'learning_rate': 1.941090791390193e-05, 'epoch': 2.95}\n",
      "{'loss': 0.3408, 'grad_norm': 8.622222900390625, 'learning_rate': 1.940928952905001e-05, 'epoch': 2.95}\n",
      "{'loss': 0.3533, 'grad_norm': 8.74281120300293, 'learning_rate': 1.9407671144198094e-05, 'epoch': 2.96}\n",
      "{'loss': 0.3687, 'grad_norm': 11.00576114654541, 'learning_rate': 1.9406052759346175e-05, 'epoch': 2.97}\n",
      "{'loss': 0.3506, 'grad_norm': 5.857142448425293, 'learning_rate': 1.9404434374494255e-05, 'epoch': 2.98}\n",
      "{'loss': 0.3532, 'grad_norm': 4.827281475067139, 'learning_rate': 1.940281598964234e-05, 'epoch': 2.99}\n",
      "{'loss': 0.3344, 'grad_norm': 8.717556953430176, 'learning_rate': 1.940119760479042e-05, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ccb2e8b5d64372ad35243ca930b5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/Desktop/MLotsawa/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44673487544059753, 'eval_accuracy': 0.8526417754748776, 'eval_f1': 0.8443285599436753, 'eval_precision': 0.848795194497865, 'eval_recall': 0.8526417754748776, 'eval_runtime': 406.4284, 'eval_samples_per_second': 429.266, 'eval_steps_per_second': 26.831, 'epoch': 3.0}\n",
      "{'loss': 0.3487, 'grad_norm': 5.341777801513672, 'learning_rate': 1.9399579219938504e-05, 'epoch': 3.0}\n",
      "{'loss': 0.2825, 'grad_norm': 13.408658027648926, 'learning_rate': 1.9397960835086584e-05, 'epoch': 3.01}\n",
      "{'loss': 0.2755, 'grad_norm': 3.749850273132324, 'learning_rate': 1.9396342450234665e-05, 'epoch': 3.02}\n",
      "{'loss': 0.2808, 'grad_norm': 6.097711086273193, 'learning_rate': 1.939472406538275e-05, 'epoch': 3.03}\n",
      "{'loss': 0.28, 'grad_norm': 3.202685594558716, 'learning_rate': 1.9393105680530833e-05, 'epoch': 3.03}\n",
      "{'loss': 0.2649, 'grad_norm': 16.06536293029785, 'learning_rate': 1.9391487295678914e-05, 'epoch': 3.04}\n",
      "{'loss': 0.2975, 'grad_norm': 8.506192207336426, 'learning_rate': 1.9389868910826998e-05, 'epoch': 3.05}\n",
      "{'loss': 0.293, 'grad_norm': 1.6656525135040283, 'learning_rate': 1.938825052597508e-05, 'epoch': 3.06}\n",
      "{'loss': 0.2895, 'grad_norm': 7.043324947357178, 'learning_rate': 1.938663214112316e-05, 'epoch': 3.07}\n",
      "{'loss': 0.289, 'grad_norm': 5.305056095123291, 'learning_rate': 1.9385013756271243e-05, 'epoch': 3.07}\n",
      "{'loss': 0.2974, 'grad_norm': 9.489282608032227, 'learning_rate': 1.9383395371419324e-05, 'epoch': 3.08}\n",
      "{'loss': 0.2893, 'grad_norm': 5.819775104522705, 'learning_rate': 1.9381776986567408e-05, 'epoch': 3.09}\n",
      "{'loss': 0.283, 'grad_norm': 2.498687982559204, 'learning_rate': 1.938015860171549e-05, 'epoch': 3.1}\n",
      "{'loss': 0.296, 'grad_norm': 3.727182149887085, 'learning_rate': 1.9378540216863572e-05, 'epoch': 3.11}\n",
      "{'loss': 0.2755, 'grad_norm': 14.453316688537598, 'learning_rate': 1.9376921832011656e-05, 'epoch': 3.12}\n",
      "{'loss': 0.2764, 'grad_norm': 16.9514102935791, 'learning_rate': 1.9375303447159737e-05, 'epoch': 3.12}\n",
      "{'loss': 0.2702, 'grad_norm': 4.509516716003418, 'learning_rate': 1.9373685062307818e-05, 'epoch': 3.13}\n",
      "{'loss': 0.2822, 'grad_norm': 12.531787872314453, 'learning_rate': 1.93720666774559e-05, 'epoch': 3.14}\n",
      "{'loss': 0.2818, 'grad_norm': 19.291797637939453, 'learning_rate': 1.9370448292603982e-05, 'epoch': 3.15}\n",
      "{'loss': 0.2817, 'grad_norm': 7.832123756408691, 'learning_rate': 1.9368829907752066e-05, 'epoch': 3.16}\n",
      "{'loss': 0.2741, 'grad_norm': 7.194359302520752, 'learning_rate': 1.9367211522900147e-05, 'epoch': 3.16}\n",
      "{'loss': 0.2798, 'grad_norm': 7.874062538146973, 'learning_rate': 1.9365593138048228e-05, 'epoch': 3.17}\n",
      "{'loss': 0.2765, 'grad_norm': 15.495036125183105, 'learning_rate': 1.936397475319631e-05, 'epoch': 3.18}\n",
      "{'loss': 0.2768, 'grad_norm': 7.434772968292236, 'learning_rate': 1.9362356368344396e-05, 'epoch': 3.19}\n",
      "{'loss': 0.282, 'grad_norm': 5.866437911987305, 'learning_rate': 1.9360737983492476e-05, 'epoch': 3.2}\n",
      "{'loss': 0.2982, 'grad_norm': 11.015695571899414, 'learning_rate': 1.935911959864056e-05, 'epoch': 3.2}\n",
      "{'loss': 0.2994, 'grad_norm': 10.589229583740234, 'learning_rate': 1.935750121378864e-05, 'epoch': 3.21}\n",
      "{'loss': 0.2877, 'grad_norm': 3.865056276321411, 'learning_rate': 1.935588282893672e-05, 'epoch': 3.22}\n",
      "{'loss': 0.2917, 'grad_norm': 4.158374309539795, 'learning_rate': 1.9354264444084805e-05, 'epoch': 3.23}\n",
      "{'loss': 0.2928, 'grad_norm': 10.046929359436035, 'learning_rate': 1.9352646059232886e-05, 'epoch': 3.24}\n",
      "{'loss': 0.2893, 'grad_norm': 17.534160614013672, 'learning_rate': 1.935102767438097e-05, 'epoch': 3.24}\n",
      "{'loss': 0.2829, 'grad_norm': 4.86996603012085, 'learning_rate': 1.934940928952905e-05, 'epoch': 3.25}\n",
      "{'loss': 0.2814, 'grad_norm': 9.49618911743164, 'learning_rate': 1.934779090467713e-05, 'epoch': 3.26}\n",
      "{'loss': 0.2937, 'grad_norm': 21.12230110168457, 'learning_rate': 1.9346172519825215e-05, 'epoch': 3.27}\n",
      "{'loss': 0.2877, 'grad_norm': 13.246155738830566, 'learning_rate': 1.93445541349733e-05, 'epoch': 3.28}\n",
      "{'loss': 0.301, 'grad_norm': 32.2148323059082, 'learning_rate': 1.934293575012138e-05, 'epoch': 3.29}\n",
      "{'loss': 0.2873, 'grad_norm': 8.87434196472168, 'learning_rate': 1.9341317365269464e-05, 'epoch': 3.29}\n",
      "{'loss': 0.2885, 'grad_norm': 6.631331443786621, 'learning_rate': 1.9339698980417545e-05, 'epoch': 3.3}\n",
      "{'loss': 0.3048, 'grad_norm': 6.585457801818848, 'learning_rate': 1.933808059556563e-05, 'epoch': 3.31}\n",
      "{'loss': 0.2946, 'grad_norm': 5.190262317657471, 'learning_rate': 1.933646221071371e-05, 'epoch': 3.32}\n",
      "{'loss': 0.3123, 'grad_norm': 13.212198257446289, 'learning_rate': 1.933484382586179e-05, 'epoch': 3.33}\n",
      "{'loss': 0.2861, 'grad_norm': 2.637044906616211, 'learning_rate': 1.9333225441009874e-05, 'epoch': 3.33}\n",
      "{'loss': 0.2957, 'grad_norm': 21.270004272460938, 'learning_rate': 1.9331607056157955e-05, 'epoch': 3.34}\n",
      "{'loss': 0.3015, 'grad_norm': 10.956518173217773, 'learning_rate': 1.932998867130604e-05, 'epoch': 3.35}\n",
      "{'loss': 0.2866, 'grad_norm': 7.868044853210449, 'learning_rate': 1.9328370286454123e-05, 'epoch': 3.36}\n",
      "{'loss': 0.2882, 'grad_norm': 2.9180383682250977, 'learning_rate': 1.9326751901602203e-05, 'epoch': 3.37}\n",
      "{'loss': 0.3011, 'grad_norm': 6.909212112426758, 'learning_rate': 1.9325133516750284e-05, 'epoch': 3.37}\n",
      "{'loss': 0.3151, 'grad_norm': 16.400850296020508, 'learning_rate': 1.9323515131898368e-05, 'epoch': 3.38}\n",
      "{'loss': 0.31, 'grad_norm': 5.311521053314209, 'learning_rate': 1.932189674704645e-05, 'epoch': 3.39}\n",
      "{'loss': 0.3073, 'grad_norm': 14.892334938049316, 'learning_rate': 1.9320278362194533e-05, 'epoch': 3.4}\n",
      "{'loss': 0.2745, 'grad_norm': 22.673524856567383, 'learning_rate': 1.9318659977342613e-05, 'epoch': 3.41}\n",
      "{'loss': 0.3074, 'grad_norm': 2.330352306365967, 'learning_rate': 1.9317041592490694e-05, 'epoch': 3.41}\n",
      "{'loss': 0.294, 'grad_norm': 17.351787567138672, 'learning_rate': 1.9315423207638778e-05, 'epoch': 3.42}\n",
      "{'loss': 0.2983, 'grad_norm': 15.887782096862793, 'learning_rate': 1.9313804822786862e-05, 'epoch': 3.43}\n",
      "{'loss': 0.3063, 'grad_norm': 6.937140464782715, 'learning_rate': 1.9312186437934942e-05, 'epoch': 3.44}\n",
      "{'loss': 0.3111, 'grad_norm': 27.367429733276367, 'learning_rate': 1.9310568053083026e-05, 'epoch': 3.45}\n",
      "{'loss': 0.2965, 'grad_norm': 13.14948558807373, 'learning_rate': 1.9308949668231107e-05, 'epoch': 3.46}\n",
      "{'loss': 0.3016, 'grad_norm': 11.876130104064941, 'learning_rate': 1.9307331283379188e-05, 'epoch': 3.46}\n",
      "{'loss': 0.2907, 'grad_norm': 25.254329681396484, 'learning_rate': 1.9305712898527272e-05, 'epoch': 3.47}\n",
      "{'loss': 0.3123, 'grad_norm': 8.195780754089355, 'learning_rate': 1.9304094513675352e-05, 'epoch': 3.48}\n",
      "{'loss': 0.2969, 'grad_norm': 16.578819274902344, 'learning_rate': 1.9302476128823436e-05, 'epoch': 3.49}\n",
      "{'loss': 0.2949, 'grad_norm': 4.289210319519043, 'learning_rate': 1.9300857743971517e-05, 'epoch': 3.5}\n",
      "{'loss': 0.302, 'grad_norm': 7.897071838378906, 'learning_rate': 1.9299239359119598e-05, 'epoch': 3.5}\n",
      "{'loss': 0.2941, 'grad_norm': 6.62778902053833, 'learning_rate': 1.9297620974267685e-05, 'epoch': 3.51}\n",
      "{'loss': 0.3053, 'grad_norm': 4.027868747711182, 'learning_rate': 1.9296002589415766e-05, 'epoch': 3.52}\n",
      "{'loss': 0.3127, 'grad_norm': 12.472199440002441, 'learning_rate': 1.9294384204563846e-05, 'epoch': 3.53}\n",
      "{'loss': 0.3031, 'grad_norm': 14.521364212036133, 'learning_rate': 1.929276581971193e-05, 'epoch': 3.54}\n",
      "{'loss': 0.3057, 'grad_norm': 3.5964879989624023, 'learning_rate': 1.929114743486001e-05, 'epoch': 3.54}\n",
      "{'loss': 0.2921, 'grad_norm': 11.69213581085205, 'learning_rate': 1.9289529050008095e-05, 'epoch': 3.55}\n",
      "{'loss': 0.2974, 'grad_norm': 10.721427917480469, 'learning_rate': 1.9287910665156176e-05, 'epoch': 3.56}\n",
      "{'loss': 0.3114, 'grad_norm': 8.17868423461914, 'learning_rate': 1.9286292280304256e-05, 'epoch': 3.57}\n",
      "{'loss': 0.3005, 'grad_norm': 8.65353012084961, 'learning_rate': 1.928467389545234e-05, 'epoch': 3.58}\n",
      "{'loss': 0.2965, 'grad_norm': 13.283724784851074, 'learning_rate': 1.928305551060042e-05, 'epoch': 3.58}\n",
      "{'loss': 0.2945, 'grad_norm': 37.75597381591797, 'learning_rate': 1.9281437125748505e-05, 'epoch': 3.59}\n",
      "{'loss': 0.3056, 'grad_norm': 3.614126205444336, 'learning_rate': 1.927981874089659e-05, 'epoch': 3.6}\n",
      "{'loss': 0.2975, 'grad_norm': 6.569686412811279, 'learning_rate': 1.927820035604467e-05, 'epoch': 3.61}\n",
      "{'loss': 0.3147, 'grad_norm': 15.462384223937988, 'learning_rate': 1.927658197119275e-05, 'epoch': 3.62}\n",
      "{'loss': 0.3029, 'grad_norm': 19.066946029663086, 'learning_rate': 1.9274963586340834e-05, 'epoch': 3.63}\n",
      "{'loss': 0.3073, 'grad_norm': 7.114408016204834, 'learning_rate': 1.9273345201488915e-05, 'epoch': 3.63}\n",
      "{'loss': 0.2942, 'grad_norm': 13.262608528137207, 'learning_rate': 1.9271726816637e-05, 'epoch': 3.64}\n",
      "{'loss': 0.2948, 'grad_norm': 26.924564361572266, 'learning_rate': 1.927010843178508e-05, 'epoch': 3.65}\n",
      "{'loss': 0.3001, 'grad_norm': 9.81361198425293, 'learning_rate': 1.926849004693316e-05, 'epoch': 3.66}\n",
      "{'loss': 0.3082, 'grad_norm': 1.4685628414154053, 'learning_rate': 1.9266871662081244e-05, 'epoch': 3.67}\n",
      "{'loss': 0.3065, 'grad_norm': 6.287742614746094, 'learning_rate': 1.9265253277229328e-05, 'epoch': 3.67}\n",
      "{'loss': 0.3105, 'grad_norm': 4.896083354949951, 'learning_rate': 1.926363489237741e-05, 'epoch': 3.68}\n",
      "{'loss': 0.2971, 'grad_norm': 4.670142650604248, 'learning_rate': 1.9262016507525493e-05, 'epoch': 3.69}\n",
      "{'loss': 0.2978, 'grad_norm': 6.001871109008789, 'learning_rate': 1.9260398122673573e-05, 'epoch': 3.7}\n",
      "{'loss': 0.297, 'grad_norm': 7.794744491577148, 'learning_rate': 1.9258779737821657e-05, 'epoch': 3.71}\n",
      "{'loss': 0.3087, 'grad_norm': 14.013960838317871, 'learning_rate': 1.9257161352969738e-05, 'epoch': 3.71}\n",
      "{'loss': 0.3023, 'grad_norm': 11.88891315460205, 'learning_rate': 1.925554296811782e-05, 'epoch': 3.72}\n",
      "{'loss': 0.3146, 'grad_norm': 12.489876747131348, 'learning_rate': 1.9253924583265903e-05, 'epoch': 3.73}\n",
      "{'loss': 0.3193, 'grad_norm': 14.491360664367676, 'learning_rate': 1.9252306198413983e-05, 'epoch': 3.74}\n",
      "{'loss': 0.3135, 'grad_norm': 7.7147932052612305, 'learning_rate': 1.9250687813562067e-05, 'epoch': 3.75}\n",
      "{'loss': 0.3013, 'grad_norm': 23.799514770507812, 'learning_rate': 1.924906942871015e-05, 'epoch': 3.75}\n",
      "{'loss': 0.3064, 'grad_norm': 9.541877746582031, 'learning_rate': 1.9247451043858232e-05, 'epoch': 3.76}\n",
      "{'loss': 0.3009, 'grad_norm': 2.3724615573883057, 'learning_rate': 1.9245832659006313e-05, 'epoch': 3.77}\n",
      "{'loss': 0.3229, 'grad_norm': 9.264320373535156, 'learning_rate': 1.9244214274154397e-05, 'epoch': 3.78}\n",
      "{'loss': 0.318, 'grad_norm': 12.356308937072754, 'learning_rate': 1.9242595889302477e-05, 'epoch': 3.79}\n",
      "{'loss': 0.3253, 'grad_norm': 7.747425556182861, 'learning_rate': 1.924097750445056e-05, 'epoch': 3.8}\n",
      "{'loss': 0.3081, 'grad_norm': 5.55134916305542, 'learning_rate': 1.9239359119598642e-05, 'epoch': 3.8}\n",
      "{'loss': 0.3085, 'grad_norm': 9.632818222045898, 'learning_rate': 1.9237740734746722e-05, 'epoch': 3.81}\n",
      "{'loss': 0.3124, 'grad_norm': 9.355378150939941, 'learning_rate': 1.9236122349894806e-05, 'epoch': 3.82}\n",
      "{'loss': 0.3125, 'grad_norm': 11.70755386352539, 'learning_rate': 1.9234503965042887e-05, 'epoch': 3.83}\n",
      "{'loss': 0.3048, 'grad_norm': 17.110292434692383, 'learning_rate': 1.923288558019097e-05, 'epoch': 3.84}\n",
      "{'loss': 0.312, 'grad_norm': 8.371246337890625, 'learning_rate': 1.9231267195339055e-05, 'epoch': 3.84}\n",
      "{'loss': 0.3134, 'grad_norm': 5.820160388946533, 'learning_rate': 1.9229648810487136e-05, 'epoch': 3.85}\n",
      "{'loss': 0.3124, 'grad_norm': 19.911287307739258, 'learning_rate': 1.9228030425635216e-05, 'epoch': 3.86}\n",
      "{'loss': 0.3061, 'grad_norm': 20.814050674438477, 'learning_rate': 1.92264120407833e-05, 'epoch': 3.87}\n",
      "{'loss': 0.322, 'grad_norm': 10.303447723388672, 'learning_rate': 1.922479365593138e-05, 'epoch': 3.88}\n",
      "{'loss': 0.3033, 'grad_norm': 13.035364151000977, 'learning_rate': 1.9223175271079465e-05, 'epoch': 3.88}\n",
      "{'loss': 0.3103, 'grad_norm': 1.6785922050476074, 'learning_rate': 1.9221556886227546e-05, 'epoch': 3.89}\n",
      "{'loss': 0.2942, 'grad_norm': 21.926311492919922, 'learning_rate': 1.9219938501375626e-05, 'epoch': 3.9}\n",
      "{'loss': 0.3124, 'grad_norm': 3.0858047008514404, 'learning_rate': 1.921832011652371e-05, 'epoch': 3.91}\n",
      "{'loss': 0.3163, 'grad_norm': 2.989931106567383, 'learning_rate': 1.9216701731671794e-05, 'epoch': 3.92}\n",
      "{'loss': 0.3115, 'grad_norm': 10.938603401184082, 'learning_rate': 1.9215083346819875e-05, 'epoch': 3.92}\n",
      "{'loss': 0.3091, 'grad_norm': 6.743674278259277, 'learning_rate': 1.921346496196796e-05, 'epoch': 3.93}\n",
      "{'loss': 0.3047, 'grad_norm': 8.069616317749023, 'learning_rate': 1.921184657711604e-05, 'epoch': 3.94}\n",
      "{'loss': 0.3162, 'grad_norm': 12.659321784973145, 'learning_rate': 1.9210228192264124e-05, 'epoch': 3.95}\n",
      "{'loss': 0.3268, 'grad_norm': 7.632519245147705, 'learning_rate': 1.9208609807412204e-05, 'epoch': 3.96}\n",
      "{'loss': 0.3188, 'grad_norm': 10.407464981079102, 'learning_rate': 1.9206991422560285e-05, 'epoch': 3.97}\n",
      "{'loss': 0.3057, 'grad_norm': 9.698629379272461, 'learning_rate': 1.920537303770837e-05, 'epoch': 3.97}\n",
      "{'loss': 0.3219, 'grad_norm': 11.504997253417969, 'learning_rate': 1.920375465285645e-05, 'epoch': 3.98}\n",
      "{'loss': 0.3184, 'grad_norm': 4.574094772338867, 'learning_rate': 1.9202136268004534e-05, 'epoch': 3.99}\n",
      "{'loss': 0.3122, 'grad_norm': 10.042645454406738, 'learning_rate': 1.9200517883152618e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af4df1745c041388fded302a8ff1ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4988257586956024, 'eval_accuracy': 0.8475232996687033, 'eval_f1': 0.8407941748243749, 'eval_precision': 0.8400164388835006, 'eval_recall': 0.8475232996687033, 'eval_runtime': 406.5037, 'eval_samples_per_second': 429.187, 'eval_steps_per_second': 26.826, 'epoch': 4.0}\n",
      "{'loss': 0.2566, 'grad_norm': 5.924985408782959, 'learning_rate': 1.9198899498300698e-05, 'epoch': 4.01}\n",
      "{'loss': 0.2516, 'grad_norm': 0.8387424349784851, 'learning_rate': 1.919728111344878e-05, 'epoch': 4.01}\n",
      "{'loss': 0.2337, 'grad_norm': 1.2511589527130127, 'learning_rate': 1.9195662728596863e-05, 'epoch': 4.02}\n",
      "{'loss': 0.2427, 'grad_norm': 26.29286003112793, 'learning_rate': 1.9194044343744943e-05, 'epoch': 4.03}\n",
      "{'loss': 0.2392, 'grad_norm': 2.1782076358795166, 'learning_rate': 1.9192425958893027e-05, 'epoch': 4.04}\n",
      "{'loss': 0.2484, 'grad_norm': 10.332441329956055, 'learning_rate': 1.9190807574041108e-05, 'epoch': 4.05}\n",
      "{'loss': 0.2576, 'grad_norm': 15.544615745544434, 'learning_rate': 1.918918918918919e-05, 'epoch': 4.05}\n",
      "{'loss': 0.2337, 'grad_norm': 14.112585067749023, 'learning_rate': 1.9187570804337273e-05, 'epoch': 4.06}\n",
      "{'loss': 0.2435, 'grad_norm': 4.312591552734375, 'learning_rate': 1.9185952419485353e-05, 'epoch': 4.07}\n",
      "{'loss': 0.2439, 'grad_norm': 19.12900733947754, 'learning_rate': 1.9184334034633437e-05, 'epoch': 4.08}\n",
      "{'loss': 0.2361, 'grad_norm': 2.1880271434783936, 'learning_rate': 1.918271564978152e-05, 'epoch': 4.09}\n",
      "{'loss': 0.253, 'grad_norm': 10.995927810668945, 'learning_rate': 1.9181097264929602e-05, 'epoch': 4.09}\n",
      "{'loss': 0.2477, 'grad_norm': 17.73387908935547, 'learning_rate': 1.9179478880077686e-05, 'epoch': 4.1}\n",
      "{'loss': 0.2423, 'grad_norm': 16.103044509887695, 'learning_rate': 1.9177860495225767e-05, 'epoch': 4.11}\n",
      "{'loss': 0.2429, 'grad_norm': 8.156494140625, 'learning_rate': 1.9176242110373847e-05, 'epoch': 4.12}\n",
      "{'loss': 0.251, 'grad_norm': 14.545171737670898, 'learning_rate': 1.917462372552193e-05, 'epoch': 4.13}\n",
      "{'loss': 0.2647, 'grad_norm': 4.5583014488220215, 'learning_rate': 1.9173005340670012e-05, 'epoch': 4.13}\n",
      "{'loss': 0.2475, 'grad_norm': 0.5223867893218994, 'learning_rate': 1.9171386955818096e-05, 'epoch': 4.14}\n",
      "{'loss': 0.2504, 'grad_norm': 13.940211296081543, 'learning_rate': 1.9169768570966177e-05, 'epoch': 4.15}\n",
      "{'loss': 0.2561, 'grad_norm': 13.873023986816406, 'learning_rate': 1.916815018611426e-05, 'epoch': 4.16}\n",
      "{'loss': 0.2594, 'grad_norm': 3.119089365005493, 'learning_rate': 1.916653180126234e-05, 'epoch': 4.17}\n",
      "{'loss': 0.2413, 'grad_norm': 0.7771140933036804, 'learning_rate': 1.9164913416410425e-05, 'epoch': 4.18}\n",
      "{'loss': 0.2612, 'grad_norm': 14.81144905090332, 'learning_rate': 1.9163295031558506e-05, 'epoch': 4.18}\n",
      "{'loss': 0.2669, 'grad_norm': 18.87118148803711, 'learning_rate': 1.916167664670659e-05, 'epoch': 4.19}\n",
      "{'loss': 0.2533, 'grad_norm': 11.19605541229248, 'learning_rate': 1.916005826185467e-05, 'epoch': 4.2}\n",
      "{'loss': 0.2442, 'grad_norm': 3.4664602279663086, 'learning_rate': 1.915843987700275e-05, 'epoch': 4.21}\n",
      "{'loss': 0.2619, 'grad_norm': 1.491452932357788, 'learning_rate': 1.9156821492150835e-05, 'epoch': 4.22}\n",
      "{'loss': 0.2484, 'grad_norm': 10.451617240905762, 'learning_rate': 1.9155203107298916e-05, 'epoch': 4.22}\n",
      "{'loss': 0.2643, 'grad_norm': 6.629254341125488, 'learning_rate': 1.9153584722447e-05, 'epoch': 4.23}\n",
      "{'loss': 0.2586, 'grad_norm': 8.352996826171875, 'learning_rate': 1.9151966337595084e-05, 'epoch': 4.24}\n",
      "{'loss': 0.2666, 'grad_norm': 3.840853452682495, 'learning_rate': 1.9150347952743164e-05, 'epoch': 4.25}\n",
      "{'loss': 0.25, 'grad_norm': 23.12213897705078, 'learning_rate': 1.9148729567891245e-05, 'epoch': 4.26}\n",
      "{'loss': 0.2682, 'grad_norm': 5.669721603393555, 'learning_rate': 1.914711118303933e-05, 'epoch': 4.26}\n",
      "{'loss': 0.2529, 'grad_norm': 3.2691760063171387, 'learning_rate': 1.914549279818741e-05, 'epoch': 4.27}\n",
      "{'loss': 0.2618, 'grad_norm': 24.558330535888672, 'learning_rate': 1.9143874413335494e-05, 'epoch': 4.28}\n",
      "{'loss': 0.2642, 'grad_norm': 17.14532470703125, 'learning_rate': 1.9142256028483574e-05, 'epoch': 4.29}\n",
      "{'loss': 0.2612, 'grad_norm': 8.897706985473633, 'learning_rate': 1.9140637643631655e-05, 'epoch': 4.3}\n",
      "{'loss': 0.2507, 'grad_norm': 10.574031829833984, 'learning_rate': 1.913901925877974e-05, 'epoch': 4.3}\n",
      "{'loss': 0.2465, 'grad_norm': 28.88322639465332, 'learning_rate': 1.913740087392782e-05, 'epoch': 4.31}\n",
      "{'loss': 0.2713, 'grad_norm': 9.998377799987793, 'learning_rate': 1.9135782489075904e-05, 'epoch': 4.32}\n",
      "{'loss': 0.2494, 'grad_norm': 6.822101593017578, 'learning_rate': 1.9134164104223988e-05, 'epoch': 4.33}\n",
      "{'loss': 0.2605, 'grad_norm': 7.737832069396973, 'learning_rate': 1.9132545719372068e-05, 'epoch': 4.34}\n",
      "{'loss': 0.2623, 'grad_norm': 9.305707931518555, 'learning_rate': 1.9130927334520152e-05, 'epoch': 4.35}\n",
      "{'loss': 0.2595, 'grad_norm': 11.212947845458984, 'learning_rate': 1.9129308949668233e-05, 'epoch': 4.35}\n",
      "{'loss': 0.2563, 'grad_norm': 3.3844382762908936, 'learning_rate': 1.9127690564816314e-05, 'epoch': 4.36}\n",
      "{'loss': 0.2752, 'grad_norm': 4.244833469390869, 'learning_rate': 1.9126072179964398e-05, 'epoch': 4.37}\n",
      "{'loss': 0.253, 'grad_norm': 2.310396194458008, 'learning_rate': 1.9124453795112478e-05, 'epoch': 4.38}\n",
      "{'loss': 0.2717, 'grad_norm': 1.6999919414520264, 'learning_rate': 1.9122835410260562e-05, 'epoch': 4.39}\n",
      "{'loss': 0.2706, 'grad_norm': 8.46584415435791, 'learning_rate': 1.9121217025408643e-05, 'epoch': 4.39}\n",
      "{'loss': 0.2628, 'grad_norm': 6.677984714508057, 'learning_rate': 1.9119598640556727e-05, 'epoch': 4.4}\n",
      "{'loss': 0.2573, 'grad_norm': 0.47268882393836975, 'learning_rate': 1.9117980255704807e-05, 'epoch': 4.41}\n",
      "{'loss': 0.2572, 'grad_norm': 14.070276260375977, 'learning_rate': 1.911636187085289e-05, 'epoch': 4.42}\n",
      "{'loss': 0.2689, 'grad_norm': 0.6178228259086609, 'learning_rate': 1.9114743486000972e-05, 'epoch': 4.43}\n",
      "{'loss': 0.2756, 'grad_norm': 3.987518548965454, 'learning_rate': 1.9113125101149056e-05, 'epoch': 4.43}\n",
      "{'loss': 0.251, 'grad_norm': 0.9082459807395935, 'learning_rate': 1.9111506716297137e-05, 'epoch': 4.44}\n",
      "{'loss': 0.2616, 'grad_norm': 22.672475814819336, 'learning_rate': 1.9109888331445217e-05, 'epoch': 4.45}\n",
      "{'loss': 0.2701, 'grad_norm': 14.403632164001465, 'learning_rate': 1.91082699465933e-05, 'epoch': 4.46}\n",
      "{'loss': 0.2725, 'grad_norm': 11.000373840332031, 'learning_rate': 1.9106651561741382e-05, 'epoch': 4.47}\n",
      "{'loss': 0.2484, 'grad_norm': 11.890777587890625, 'learning_rate': 1.9105033176889466e-05, 'epoch': 4.47}\n",
      "{'loss': 0.2674, 'grad_norm': 6.168781757354736, 'learning_rate': 1.910341479203755e-05, 'epoch': 4.48}\n",
      "{'loss': 0.2766, 'grad_norm': 13.037182807922363, 'learning_rate': 1.910179640718563e-05, 'epoch': 4.49}\n",
      "{'loss': 0.2641, 'grad_norm': 0.6547948718070984, 'learning_rate': 1.9100178022333715e-05, 'epoch': 4.5}\n",
      "{'loss': 0.2706, 'grad_norm': 1.1875263452529907, 'learning_rate': 1.9098559637481795e-05, 'epoch': 4.51}\n",
      "{'loss': 0.2538, 'grad_norm': 11.426102638244629, 'learning_rate': 1.9096941252629876e-05, 'epoch': 4.52}\n",
      "{'loss': 0.2753, 'grad_norm': 21.025789260864258, 'learning_rate': 1.909532286777796e-05, 'epoch': 4.52}\n",
      "{'loss': 0.2616, 'grad_norm': 9.02625560760498, 'learning_rate': 1.909370448292604e-05, 'epoch': 4.53}\n",
      "{'loss': 0.2774, 'grad_norm': 6.622941970825195, 'learning_rate': 1.9092086098074125e-05, 'epoch': 4.54}\n",
      "{'loss': 0.2864, 'grad_norm': 2.3853793144226074, 'learning_rate': 1.9090467713222205e-05, 'epoch': 4.55}\n",
      "{'loss': 0.263, 'grad_norm': 6.856888294219971, 'learning_rate': 1.9088849328370286e-05, 'epoch': 4.56}\n",
      "{'loss': 0.2683, 'grad_norm': 8.965108871459961, 'learning_rate': 1.908723094351837e-05, 'epoch': 4.56}\n",
      "{'loss': 0.2811, 'grad_norm': 7.365342140197754, 'learning_rate': 1.9085612558666454e-05, 'epoch': 4.57}\n",
      "{'loss': 0.2521, 'grad_norm': 15.095829010009766, 'learning_rate': 1.9083994173814535e-05, 'epoch': 4.58}\n",
      "{'loss': 0.2678, 'grad_norm': 1.1227202415466309, 'learning_rate': 1.908237578896262e-05, 'epoch': 4.59}\n",
      "{'loss': 0.2698, 'grad_norm': 10.094447135925293, 'learning_rate': 1.90807574041107e-05, 'epoch': 4.6}\n",
      "{'loss': 0.2743, 'grad_norm': 8.075130462646484, 'learning_rate': 1.907913901925878e-05, 'epoch': 4.6}\n",
      "{'loss': 0.2528, 'grad_norm': 9.849609375, 'learning_rate': 1.9077520634406864e-05, 'epoch': 4.61}\n",
      "{'loss': 0.2547, 'grad_norm': 1.664197564125061, 'learning_rate': 1.9075902249554944e-05, 'epoch': 4.62}\n",
      "{'loss': 0.2725, 'grad_norm': 1.490227222442627, 'learning_rate': 1.907428386470303e-05, 'epoch': 4.63}\n",
      "{'loss': 0.2661, 'grad_norm': 20.99890899658203, 'learning_rate': 1.907266547985111e-05, 'epoch': 4.64}\n",
      "{'loss': 0.2728, 'grad_norm': 2.435063362121582, 'learning_rate': 1.9071047094999193e-05, 'epoch': 4.64}\n",
      "{'loss': 0.2691, 'grad_norm': 8.210158348083496, 'learning_rate': 1.9069428710147274e-05, 'epoch': 4.65}\n",
      "{'loss': 0.2728, 'grad_norm': 27.763755798339844, 'learning_rate': 1.9067810325295358e-05, 'epoch': 4.66}\n",
      "{'loss': 0.2702, 'grad_norm': 29.340272903442383, 'learning_rate': 1.906619194044344e-05, 'epoch': 4.67}\n",
      "{'loss': 0.2728, 'grad_norm': 23.235698699951172, 'learning_rate': 1.9064573555591522e-05, 'epoch': 4.68}\n",
      "{'loss': 0.2814, 'grad_norm': 6.0438923835754395, 'learning_rate': 1.9062955170739603e-05, 'epoch': 4.69}\n",
      "{'loss': 0.2805, 'grad_norm': 2.347637176513672, 'learning_rate': 1.9061336785887684e-05, 'epoch': 4.69}\n",
      "{'loss': 0.2745, 'grad_norm': 14.760852813720703, 'learning_rate': 1.9059718401035768e-05, 'epoch': 4.7}\n",
      "{'loss': 0.2789, 'grad_norm': 12.253169059753418, 'learning_rate': 1.9058100016183848e-05, 'epoch': 4.71}\n",
      "{'loss': 0.2728, 'grad_norm': 27.758502960205078, 'learning_rate': 1.9056481631331932e-05, 'epoch': 4.72}\n",
      "{'loss': 0.2733, 'grad_norm': 12.293350219726562, 'learning_rate': 1.9054863246480016e-05, 'epoch': 4.73}\n",
      "{'loss': 0.2716, 'grad_norm': 6.940597057342529, 'learning_rate': 1.9053244861628097e-05, 'epoch': 4.73}\n",
      "{'loss': 0.2863, 'grad_norm': 4.239115238189697, 'learning_rate': 1.905162647677618e-05, 'epoch': 4.74}\n",
      "{'loss': 0.2839, 'grad_norm': 7.775585651397705, 'learning_rate': 1.905000809192426e-05, 'epoch': 4.75}\n",
      "{'loss': 0.2723, 'grad_norm': 12.258820533752441, 'learning_rate': 1.9048389707072342e-05, 'epoch': 4.76}\n",
      "{'loss': 0.287, 'grad_norm': 5.137076377868652, 'learning_rate': 1.9046771322220426e-05, 'epoch': 4.77}\n",
      "{'loss': 0.2741, 'grad_norm': 0.5693119764328003, 'learning_rate': 1.9045152937368507e-05, 'epoch': 4.77}\n",
      "{'loss': 0.2744, 'grad_norm': 11.590744972229004, 'learning_rate': 1.904353455251659e-05, 'epoch': 4.78}\n",
      "{'loss': 0.2839, 'grad_norm': 12.829861640930176, 'learning_rate': 1.904191616766467e-05, 'epoch': 4.79}\n",
      "{'loss': 0.2691, 'grad_norm': 1.4562411308288574, 'learning_rate': 1.9040297782812755e-05, 'epoch': 4.8}\n",
      "{'loss': 0.2766, 'grad_norm': 9.130354881286621, 'learning_rate': 1.9038679397960836e-05, 'epoch': 4.81}\n",
      "{'loss': 0.2861, 'grad_norm': 2.6832001209259033, 'learning_rate': 1.903706101310892e-05, 'epoch': 4.81}\n",
      "{'loss': 0.2766, 'grad_norm': 10.743667602539062, 'learning_rate': 1.9035442628257e-05, 'epoch': 4.82}\n",
      "{'loss': 0.2816, 'grad_norm': 20.742544174194336, 'learning_rate': 1.9033824243405085e-05, 'epoch': 4.83}\n",
      "{'loss': 0.2769, 'grad_norm': 7.933516979217529, 'learning_rate': 1.9032205858553165e-05, 'epoch': 4.84}\n",
      "{'loss': 0.2616, 'grad_norm': 6.577502250671387, 'learning_rate': 1.9030587473701246e-05, 'epoch': 4.85}\n",
      "{'loss': 0.2831, 'grad_norm': 25.415889739990234, 'learning_rate': 1.902896908884933e-05, 'epoch': 4.86}\n",
      "{'loss': 0.278, 'grad_norm': 8.424934387207031, 'learning_rate': 1.902735070399741e-05, 'epoch': 4.86}\n",
      "{'loss': 0.2832, 'grad_norm': 20.495161056518555, 'learning_rate': 1.9025732319145495e-05, 'epoch': 4.87}\n",
      "{'loss': 0.2746, 'grad_norm': 3.6721885204315186, 'learning_rate': 1.902411393429358e-05, 'epoch': 4.88}\n",
      "{'loss': 0.2853, 'grad_norm': 12.807788848876953, 'learning_rate': 1.902249554944166e-05, 'epoch': 4.89}\n",
      "{'loss': 0.2735, 'grad_norm': 8.599298477172852, 'learning_rate': 1.9020877164589743e-05, 'epoch': 4.9}\n",
      "{'loss': 0.2786, 'grad_norm': 10.168745994567871, 'learning_rate': 1.9019258779737824e-05, 'epoch': 4.9}\n",
      "{'loss': 0.266, 'grad_norm': 11.875066757202148, 'learning_rate': 1.9017640394885905e-05, 'epoch': 4.91}\n",
      "{'loss': 0.2776, 'grad_norm': 18.122127532958984, 'learning_rate': 1.901602201003399e-05, 'epoch': 4.92}\n",
      "{'loss': 0.2911, 'grad_norm': 11.963157653808594, 'learning_rate': 1.901440362518207e-05, 'epoch': 4.93}\n",
      "{'loss': 0.2894, 'grad_norm': 2.1033785343170166, 'learning_rate': 1.9012785240330153e-05, 'epoch': 4.94}\n",
      "{'loss': 0.2694, 'grad_norm': 34.46742248535156, 'learning_rate': 1.9011166855478234e-05, 'epoch': 4.94}\n",
      "{'loss': 0.287, 'grad_norm': 15.172406196594238, 'learning_rate': 1.9009548470626315e-05, 'epoch': 4.95}\n",
      "{'loss': 0.2726, 'grad_norm': 19.388200759887695, 'learning_rate': 1.90079300857744e-05, 'epoch': 4.96}\n",
      "{'loss': 0.2804, 'grad_norm': 7.277557373046875, 'learning_rate': 1.9006311700922483e-05, 'epoch': 4.97}\n",
      "{'loss': 0.2896, 'grad_norm': 14.107157707214355, 'learning_rate': 1.9004693316070563e-05, 'epoch': 4.98}\n",
      "{'loss': 0.2883, 'grad_norm': 10.542649269104004, 'learning_rate': 1.9003074931218647e-05, 'epoch': 4.98}\n",
      "{'loss': 0.2672, 'grad_norm': 19.64804458618164, 'learning_rate': 1.9001456546366728e-05, 'epoch': 4.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a121972f2642e0975fa46fba3e7d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5627232193946838, 'eval_accuracy': 0.8459986473009068, 'eval_f1': 0.8391218228897186, 'eval_precision': 0.8415472118425453, 'eval_recall': 0.8459986473009068, 'eval_runtime': 406.5015, 'eval_samples_per_second': 429.189, 'eval_steps_per_second': 26.826, 'epoch': 5.0}\n",
      "{'loss': 0.2723, 'grad_norm': 19.75212860107422, 'learning_rate': 1.899983816151481e-05, 'epoch': 5.0}\n",
      "{'loss': 0.2115, 'grad_norm': 2.251190423965454, 'learning_rate': 1.8998219776662892e-05, 'epoch': 5.01}\n",
      "{'loss': 0.2325, 'grad_norm': 19.01184844970703, 'learning_rate': 1.8996601391810973e-05, 'epoch': 5.02}\n",
      "{'loss': 0.223, 'grad_norm': 6.405007362365723, 'learning_rate': 1.8994983006959057e-05, 'epoch': 5.03}\n",
      "{'loss': 0.2145, 'grad_norm': 5.565252304077148, 'learning_rate': 1.8993364622107138e-05, 'epoch': 5.03}\n",
      "{'loss': 0.2129, 'grad_norm': 19.0717716217041, 'learning_rate': 1.8991746237255222e-05, 'epoch': 5.04}\n",
      "{'loss': 0.2218, 'grad_norm': 0.9892017245292664, 'learning_rate': 1.8990127852403302e-05, 'epoch': 5.05}\n",
      "{'loss': 0.2133, 'grad_norm': 4.091236591339111, 'learning_rate': 1.8988509467551386e-05, 'epoch': 5.06}\n",
      "{'loss': 0.2105, 'grad_norm': 10.170106887817383, 'learning_rate': 1.8986891082699467e-05, 'epoch': 5.07}\n",
      "{'loss': 0.196, 'grad_norm': 0.2857721149921417, 'learning_rate': 1.898527269784755e-05, 'epoch': 5.07}\n",
      "{'loss': 0.235, 'grad_norm': 27.392831802368164, 'learning_rate': 1.898365431299563e-05, 'epoch': 5.08}\n",
      "{'loss': 0.2153, 'grad_norm': 7.895138263702393, 'learning_rate': 1.8982035928143712e-05, 'epoch': 5.09}\n",
      "{'loss': 0.2353, 'grad_norm': 51.02739715576172, 'learning_rate': 1.8980417543291796e-05, 'epoch': 5.1}\n",
      "{'loss': 0.2312, 'grad_norm': 15.327726364135742, 'learning_rate': 1.8978799158439877e-05, 'epoch': 5.11}\n",
      "{'loss': 0.2175, 'grad_norm': 15.916596412658691, 'learning_rate': 1.897718077358796e-05, 'epoch': 5.11}\n",
      "{'loss': 0.2302, 'grad_norm': 1.734511137008667, 'learning_rate': 1.8975562388736045e-05, 'epoch': 5.12}\n",
      "{'loss': 0.2269, 'grad_norm': 3.404956579208374, 'learning_rate': 1.8973944003884126e-05, 'epoch': 5.13}\n",
      "{'loss': 0.2308, 'grad_norm': 2.2861030101776123, 'learning_rate': 1.897232561903221e-05, 'epoch': 5.14}\n",
      "{'loss': 0.2227, 'grad_norm': 24.68427085876465, 'learning_rate': 1.897070723418029e-05, 'epoch': 5.15}\n",
      "{'loss': 0.2349, 'grad_norm': 11.7965087890625, 'learning_rate': 1.896908884932837e-05, 'epoch': 5.15}\n",
      "{'loss': 0.2266, 'grad_norm': 29.645496368408203, 'learning_rate': 1.8967470464476455e-05, 'epoch': 5.16}\n",
      "{'loss': 0.2282, 'grad_norm': 3.931623935699463, 'learning_rate': 1.8965852079624535e-05, 'epoch': 5.17}\n",
      "{'loss': 0.2273, 'grad_norm': 18.951419830322266, 'learning_rate': 1.896423369477262e-05, 'epoch': 5.18}\n",
      "{'loss': 0.2264, 'grad_norm': 43.27047348022461, 'learning_rate': 1.89626153099207e-05, 'epoch': 5.19}\n",
      "{'loss': 0.2292, 'grad_norm': 4.442671775817871, 'learning_rate': 1.896099692506878e-05, 'epoch': 5.2}\n",
      "{'loss': 0.2183, 'grad_norm': 2.32551908493042, 'learning_rate': 1.8959378540216865e-05, 'epoch': 5.2}\n",
      "{'loss': 0.2329, 'grad_norm': 11.977629661560059, 'learning_rate': 1.895776015536495e-05, 'epoch': 5.21}\n",
      "{'loss': 0.2369, 'grad_norm': 11.302945137023926, 'learning_rate': 1.895614177051303e-05, 'epoch': 5.22}\n",
      "{'loss': 0.2277, 'grad_norm': 1.2446824312210083, 'learning_rate': 1.8954523385661113e-05, 'epoch': 5.23}\n",
      "{'loss': 0.2365, 'grad_norm': 7.568887710571289, 'learning_rate': 1.8952905000809194e-05, 'epoch': 5.24}\n",
      "{'loss': 0.237, 'grad_norm': 6.641763210296631, 'learning_rate': 1.8951286615957275e-05, 'epoch': 5.24}\n",
      "{'loss': 0.2463, 'grad_norm': 1.2188576459884644, 'learning_rate': 1.894966823110536e-05, 'epoch': 5.25}\n",
      "{'loss': 0.2336, 'grad_norm': 45.747276306152344, 'learning_rate': 1.894804984625344e-05, 'epoch': 5.26}\n",
      "{'loss': 0.226, 'grad_norm': 15.43628978729248, 'learning_rate': 1.8946431461401523e-05, 'epoch': 5.27}\n",
      "{'loss': 0.2236, 'grad_norm': 0.8522564768791199, 'learning_rate': 1.8944813076549604e-05, 'epoch': 5.28}\n",
      "{'loss': 0.2417, 'grad_norm': 28.400846481323242, 'learning_rate': 1.8943194691697688e-05, 'epoch': 5.28}\n",
      "{'loss': 0.226, 'grad_norm': 19.97454833984375, 'learning_rate': 1.8941576306845772e-05, 'epoch': 5.29}\n",
      "{'loss': 0.2371, 'grad_norm': 45.6289176940918, 'learning_rate': 1.8939957921993853e-05, 'epoch': 5.3}\n",
      "{'loss': 0.2466, 'grad_norm': 4.894577503204346, 'learning_rate': 1.8938339537141933e-05, 'epoch': 5.31}\n",
      "{'loss': 0.2355, 'grad_norm': 25.843894958496094, 'learning_rate': 1.8936721152290017e-05, 'epoch': 5.32}\n",
      "{'loss': 0.2286, 'grad_norm': 7.025918483734131, 'learning_rate': 1.8935102767438098e-05, 'epoch': 5.32}\n",
      "{'loss': 0.2322, 'grad_norm': 4.188565254211426, 'learning_rate': 1.8933484382586182e-05, 'epoch': 5.33}\n",
      "{'loss': 0.2417, 'grad_norm': 9.468929290771484, 'learning_rate': 1.8931865997734263e-05, 'epoch': 5.34}\n",
      "{'loss': 0.244, 'grad_norm': 18.320125579833984, 'learning_rate': 1.8930247612882343e-05, 'epoch': 5.35}\n",
      "{'loss': 0.2309, 'grad_norm': 10.410425186157227, 'learning_rate': 1.8928629228030427e-05, 'epoch': 5.36}\n",
      "{'loss': 0.2435, 'grad_norm': 17.046127319335938, 'learning_rate': 1.892701084317851e-05, 'epoch': 5.36}\n",
      "{'loss': 0.2321, 'grad_norm': 15.488815307617188, 'learning_rate': 1.8925392458326592e-05, 'epoch': 5.37}\n",
      "{'loss': 0.2524, 'grad_norm': 0.2505079507827759, 'learning_rate': 1.8923774073474676e-05, 'epoch': 5.38}\n",
      "{'loss': 0.2424, 'grad_norm': 19.445791244506836, 'learning_rate': 1.8922155688622756e-05, 'epoch': 5.39}\n",
      "{'loss': 0.2246, 'grad_norm': 24.767995834350586, 'learning_rate': 1.8920537303770837e-05, 'epoch': 5.4}\n",
      "{'loss': 0.2241, 'grad_norm': 3.416520357131958, 'learning_rate': 1.891891891891892e-05, 'epoch': 5.41}\n",
      "{'loss': 0.2405, 'grad_norm': 12.530547142028809, 'learning_rate': 1.8917300534067002e-05, 'epoch': 5.41}\n",
      "{'loss': 0.241, 'grad_norm': 1.7687360048294067, 'learning_rate': 1.8915682149215086e-05, 'epoch': 5.42}\n",
      "{'loss': 0.2411, 'grad_norm': 4.543729305267334, 'learning_rate': 1.8914063764363166e-05, 'epoch': 5.43}\n",
      "{'loss': 0.2379, 'grad_norm': 3.2333791255950928, 'learning_rate': 1.8912445379511247e-05, 'epoch': 5.44}\n",
      "{'loss': 0.2352, 'grad_norm': 1.7459487915039062, 'learning_rate': 1.891082699465933e-05, 'epoch': 5.45}\n",
      "{'loss': 0.2378, 'grad_norm': 5.70441198348999, 'learning_rate': 1.8909208609807415e-05, 'epoch': 5.45}\n",
      "{'loss': 0.2431, 'grad_norm': 2.029448986053467, 'learning_rate': 1.8907590224955496e-05, 'epoch': 5.46}\n",
      "{'loss': 0.2382, 'grad_norm': 0.7005674839019775, 'learning_rate': 1.890597184010358e-05, 'epoch': 5.47}\n",
      "{'loss': 0.2397, 'grad_norm': 0.6409633159637451, 'learning_rate': 1.890435345525166e-05, 'epoch': 5.48}\n",
      "{'loss': 0.2298, 'grad_norm': 6.2125163078308105, 'learning_rate': 1.890273507039974e-05, 'epoch': 5.49}\n",
      "{'loss': 0.2436, 'grad_norm': 12.412572860717773, 'learning_rate': 1.8901116685547825e-05, 'epoch': 5.49}\n",
      "{'loss': 0.235, 'grad_norm': 12.621962547302246, 'learning_rate': 1.8899498300695906e-05, 'epoch': 5.5}\n",
      "{'loss': 0.2421, 'grad_norm': 0.8468334078788757, 'learning_rate': 1.889787991584399e-05, 'epoch': 5.51}\n",
      "{'loss': 0.2379, 'grad_norm': 0.4699370265007019, 'learning_rate': 1.889626153099207e-05, 'epoch': 5.52}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 36\u001b[0m\n\u001b[1;32m     25\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     26\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     27\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stopping]  \u001b[38;5;66;03m# Add the early stopping callback\u001b[39;00m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.12/site-packages/transformers/trainer.py:2164\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2165\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2169\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.12/site-packages/transformers/trainer.py:2522\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2516\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2517\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2519\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2520\u001b[0m )\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2522\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2525\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2526\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2528\u001b[0m ):\n\u001b[1;32m   2529\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2530\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.12/site-packages/transformers/trainer.py:3688\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3686\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3687\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3688\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3689\u001b[0m     \u001b[38;5;66;03m# Finally we need to normalize the loss for reporting\u001b[39;00m\n\u001b[1;32m   3690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.12/site-packages/accelerate/accelerator.py:2248\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2248\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MLotsawa/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"en-col-op-bert-classifier\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=100,  # Set a maximum number of epochs\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",  # Evaluate at the end of every epoch\n",
    "    save_strategy=\"epoch\",  # Save the model at the end of every epoch\n",
    "    load_best_model_at_end=True,  # Load the best model after training\n",
    "    metric_for_best_model=\"accuracy\",  # Metric to monitor\n",
    "    greater_is_better=True,  # Higher accuracy is better\n",
    "    logging_dir=\"./logs\"\n",
    ")\n",
    "\n",
    "# Add the EarlyStoppingCallback\n",
    "early_stopping = EarlyStoppingCallback(\n",
    "    early_stopping_patience=3  # Stop training if the metric does not improve for 3 evaluation steps\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stopping]  # Add the early stopping callback\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
