{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'billingsmoore/tibetan-to-english-translation-dataset' Collection\n",
    "\n",
    "The purpose of this notebook is to document the process used to scrape the dataset ['billingsmoore/tibetan-to-english-translation-dataset'](https://huggingface.co/datasets/billingsmoore/tibetan-to-english-translation-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping\n",
    "\n",
    "The code below was used to scrape the data from [Lotsawa House](www.lotsawahouse.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://www.lotsawahouse.org/topics/\"\n",
    "\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "series = soup.findAll('a', {'class':'index-entry'})\n",
    "\n",
    "for serie in series:\n",
    "    URL = 'https://www.lotsawahouse.org/'+serie['href']\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    # get titles from html\n",
    "    titles = soup.findAll('a', {'class':'title'})\n",
    "\n",
    "    for title in titles:\n",
    "        try:\n",
    "            # get html for title\n",
    "            URL = 'https://www.lotsawahouse.org/' + title['href']\n",
    "            page = requests.get(URL)\n",
    "\n",
    "            soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "            # extract text from html\n",
    "            maintext = soup.find('div', {'id': \"maintext\"})\n",
    "            tib = maintext.findAll('p', {'class': 'TibetanVerse'})\n",
    "            phon = maintext.findAll('p', {'class': 'EnglishPhonetics'})\n",
    "            en = maintext.findAll('p', {'class': 'EnglishText'})\n",
    "\n",
    "            if len(tib) == len(phon): # if pairs are valid, save them\n",
    "\n",
    "                # prep pairs from text\n",
    "                tib = [elt.contents[0].replace('\\xa0', '') for elt in tib]\n",
    "                phon = [elt.contents[0].replace(',', '') for elt in phon]\n",
    "                en = [elt.contents[0].replace(',', '') for elt in en]\n",
    "                pairs = [(tib_elt + ',' + phon_elt + ',' + en_elt + '\\n') for tib_elt, phon_elt, en_elt in zip(tib, phon, en)]\n",
    "\n",
    "                # write pairs to csv\n",
    "                with open('pairs.csv', 'a') as f:\n",
    "                    for pair in pairs:\n",
    "                        f.write(pair)\n",
    "        except:\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
