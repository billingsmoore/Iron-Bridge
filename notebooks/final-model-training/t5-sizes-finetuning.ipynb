{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "train_dataset = load_dataset('pandas', data_files='/home/j/Documents/Projects/MLotsawa/data/size-selection-data/1M-train.p')\n",
    "eval_dataset = load_dataset('pandas', data_files='/home/j/Documents/Projects/MLotsawa/data/size-selection-data/100k-eval.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 18:31:06.327574: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-14 18:31:06.327623: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-14 18:31:06.327667: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-14 18:31:06.337679: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq\n",
    "\n",
    "checkpoint = \"/home/j/Documents/Projects/MLotsawa/models/size-selection/large/epoch-3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lang = 'bo'\n",
    "target_lang = 'en'\n",
    "prefix = \"translate Tibetan to English: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "\n",
    "    inputs = [prefix + example[source_lang] for example in examples['translation']]\n",
    "    targets = [example[target_lang] for example in examples['translation']]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
    "\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback, Adafactor\n",
    "\n",
    "early_stop = EarlyStoppingCallback()\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, device_map=\"auto\")\n",
    "\n",
    "optimizer = Adafactor(\n",
    "    model.parameters(), \n",
    "    scale_parameter=True, \n",
    "    relative_step=False, \n",
    "    warmup_init=False, \n",
    "    lr=3e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer = accelerator.prepare(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbillingsmoore\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/j/Documents/Projects/MLotsawa/notebooks/final-model-training/wandb/run-20240814_183129-w25rprgm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/billingsmoore/huggingface/runs/w25rprgm/workspace' target=\"_blank\">../../models/final-model/</a></strong> to <a href='https://wandb.ai/billingsmoore/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/billingsmoore/huggingface' target=\"_blank\">https://wandb.ai/billingsmoore/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/billingsmoore/huggingface/runs/w25rprgm/workspace' target=\"_blank\">https://wandb.ai/billingsmoore/huggingface/runs/w25rprgm/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd63757ec9a497db63d0bc1c38f0254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7419, 'grad_norm': 5.968578815460205, 'learning_rate': 0.00029998799999999995, 'epoch': 0.0}\n",
      "{'loss': 0.8053, 'grad_norm': 7.301441669464111, 'learning_rate': 0.000299976, 'epoch': 0.0}\n",
      "{'loss': 0.8107, 'grad_norm': 5.739782333374023, 'learning_rate': 0.00029996399999999995, 'epoch': 0.0}\n",
      "{'loss': 0.8066, 'grad_norm': 4.712608337402344, 'learning_rate': 0.000299952, 'epoch': 0.0}\n",
      "{'loss': 0.8459, 'grad_norm': 6.24125862121582, 'learning_rate': 0.00029994, 'epoch': 0.0}\n",
      "{'loss': 0.8059, 'grad_norm': 3.6026172637939453, 'learning_rate': 0.000299928, 'epoch': 0.0}\n",
      "{'loss': 0.8353, 'grad_norm': 7.338786602020264, 'learning_rate': 0.000299916, 'epoch': 0.0}\n",
      "{'loss': 0.8275, 'grad_norm': 4.893742561340332, 'learning_rate': 0.000299904, 'epoch': 0.0}\n",
      "{'loss': 0.8493, 'grad_norm': 8.208993911743164, 'learning_rate': 0.00029989199999999995, 'epoch': 0.0}\n",
      "{'loss': 0.8073, 'grad_norm': 8.872082710266113, 'learning_rate': 0.00029988, 'epoch': 0.0}\n",
      "{'loss': 0.8515, 'grad_norm': 4.985530853271484, 'learning_rate': 0.00029986799999999996, 'epoch': 0.0}\n",
      "{'loss': 0.8208, 'grad_norm': 4.758223056793213, 'learning_rate': 0.000299856, 'epoch': 0.0}\n",
      "{'loss': 0.8005, 'grad_norm': 4.917437553405762, 'learning_rate': 0.000299844, 'epoch': 0.0}\n",
      "{'loss': 0.824, 'grad_norm': 4.99088716506958, 'learning_rate': 0.000299832, 'epoch': 0.0}\n",
      "{'loss': 0.8073, 'grad_norm': 6.345301628112793, 'learning_rate': 0.00029981999999999996, 'epoch': 0.0}\n",
      "{'loss': 0.7901, 'grad_norm': 6.176414489746094, 'learning_rate': 0.000299808, 'epoch': 0.0}\n",
      "{'loss': 0.8026, 'grad_norm': 5.785472869873047, 'learning_rate': 0.00029979599999999996, 'epoch': 0.0}\n",
      "{'loss': 0.8105, 'grad_norm': 6.263362884521484, 'learning_rate': 0.00029978399999999993, 'epoch': 0.0}\n",
      "{'loss': 0.7995, 'grad_norm': 7.38709831237793, 'learning_rate': 0.00029977199999999996, 'epoch': 0.0}\n",
      "{'loss': 0.7871, 'grad_norm': 6.610780715942383, 'learning_rate': 0.00029976, 'epoch': 0.0}\n",
      "{'loss': 0.7919, 'grad_norm': 5.151288986206055, 'learning_rate': 0.00029974799999999996, 'epoch': 0.0}\n",
      "{'loss': 0.779, 'grad_norm': 6.09230899810791, 'learning_rate': 0.000299736, 'epoch': 0.0}\n",
      "{'loss': 0.7994, 'grad_norm': 6.871119022369385, 'learning_rate': 0.00029972399999999996, 'epoch': 0.0}\n",
      "{'loss': 0.7847, 'grad_norm': 7.307765483856201, 'learning_rate': 0.000299712, 'epoch': 0.0}\n",
      "{'loss': 0.7802, 'grad_norm': 8.272321701049805, 'learning_rate': 0.00029969999999999997, 'epoch': 0.0}\n",
      "{'loss': 0.753, 'grad_norm': 4.1381378173828125, 'learning_rate': 0.00029968799999999994, 'epoch': 0.0}\n",
      "{'loss': 0.7795, 'grad_norm': 6.018144607543945, 'learning_rate': 0.00029967599999999997, 'epoch': 0.0}\n",
      "{'loss': 0.75, 'grad_norm': 7.196473121643066, 'learning_rate': 0.000299664, 'epoch': 0.0}\n",
      "{'loss': 0.7498, 'grad_norm': 5.171830177307129, 'learning_rate': 0.00029965199999999997, 'epoch': 0.0}\n",
      "{'loss': 0.7659, 'grad_norm': 4.092408657073975, 'learning_rate': 0.00029964, 'epoch': 0.0}\n",
      "{'loss': 0.7496, 'grad_norm': 6.275320529937744, 'learning_rate': 0.00029962799999999997, 'epoch': 0.0}\n",
      "{'loss': 0.733, 'grad_norm': 3.804509162902832, 'learning_rate': 0.000299616, 'epoch': 0.0}\n",
      "{'loss': 0.7703, 'grad_norm': 4.017491817474365, 'learning_rate': 0.00029960399999999997, 'epoch': 0.0}\n",
      "{'loss': 0.7372, 'grad_norm': 4.65793514251709, 'learning_rate': 0.00029959199999999995, 'epoch': 0.0}\n",
      "{'loss': 0.7461, 'grad_norm': 7.12173318862915, 'learning_rate': 0.00029958, 'epoch': 0.0}\n",
      "{'loss': 0.7412, 'grad_norm': 4.517226219177246, 'learning_rate': 0.00029956799999999995, 'epoch': 0.0}\n",
      "{'loss': 0.7161, 'grad_norm': 6.016136169433594, 'learning_rate': 0.000299556, 'epoch': 0.0}\n",
      "{'loss': 0.7268, 'grad_norm': 5.311272144317627, 'learning_rate': 0.000299544, 'epoch': 0.0}\n",
      "{'loss': 0.7088, 'grad_norm': 7.207073211669922, 'learning_rate': 0.000299532, 'epoch': 0.0}\n",
      "{'loss': 0.6984, 'grad_norm': 5.157007217407227, 'learning_rate': 0.00029951999999999995, 'epoch': 0.0}\n",
      "{'loss': 0.7122, 'grad_norm': 6.2889018058776855, 'learning_rate': 0.000299508, 'epoch': 0.0}\n",
      "{'loss': 0.6898, 'grad_norm': 6.395699977874756, 'learning_rate': 0.00029949599999999995, 'epoch': 0.0}\n",
      "{'loss': 0.6988, 'grad_norm': 5.150548934936523, 'learning_rate': 0.000299484, 'epoch': 0.0}\n",
      "{'loss': 0.6954, 'grad_norm': 5.263807773590088, 'learning_rate': 0.00029947199999999995, 'epoch': 0.0}\n",
      "{'loss': 0.7131, 'grad_norm': 7.52790641784668, 'learning_rate': 0.00029946, 'epoch': 0.0}\n",
      "{'loss': 0.7135, 'grad_norm': 4.2017717361450195, 'learning_rate': 0.000299448, 'epoch': 0.0}\n",
      "{'loss': 0.6899, 'grad_norm': 6.3503737449646, 'learning_rate': 0.000299436, 'epoch': 0.0}\n",
      "{'loss': 0.6998, 'grad_norm': 7.070868015289307, 'learning_rate': 0.00029942399999999996, 'epoch': 0.0}\n",
      "{'loss': 0.6694, 'grad_norm': 5.698850154876709, 'learning_rate': 0.000299412, 'epoch': 0.0}\n",
      "{'loss': 0.6615, 'grad_norm': 8.846109390258789, 'learning_rate': 0.00029939999999999996, 'epoch': 0.0}\n",
      "{'loss': 0.6737, 'grad_norm': 5.033903121948242, 'learning_rate': 0.000299388, 'epoch': 0.0}\n",
      "{'loss': 0.6793, 'grad_norm': 6.630783557891846, 'learning_rate': 0.00029937599999999996, 'epoch': 0.0}\n",
      "{'loss': 0.6685, 'grad_norm': 3.487502098083496, 'learning_rate': 0.000299364, 'epoch': 0.0}\n",
      "{'loss': 0.6678, 'grad_norm': 6.1143951416015625, 'learning_rate': 0.00029935199999999996, 'epoch': 0.0}\n",
      "{'loss': 0.6687, 'grad_norm': 4.787235260009766, 'learning_rate': 0.00029934, 'epoch': 0.0}\n",
      "{'loss': 0.6637, 'grad_norm': 5.723255157470703, 'learning_rate': 0.00029932799999999996, 'epoch': 0.0}\n",
      "{'loss': 0.6563, 'grad_norm': 5.989710330963135, 'learning_rate': 0.000299316, 'epoch': 0.0}\n",
      "{'loss': 0.6526, 'grad_norm': 6.12830114364624, 'learning_rate': 0.00029930399999999997, 'epoch': 0.0}\n",
      "{'loss': 0.6408, 'grad_norm': 4.321720600128174, 'learning_rate': 0.00029929199999999994, 'epoch': 0.0}\n",
      "{'loss': 0.6327, 'grad_norm': 4.752015113830566, 'learning_rate': 0.00029927999999999997, 'epoch': 0.0}\n",
      "{'loss': 0.6356, 'grad_norm': 5.8396806716918945, 'learning_rate': 0.000299268, 'epoch': 0.0}\n",
      "{'loss': 0.637, 'grad_norm': 8.876317977905273, 'learning_rate': 0.00029925599999999997, 'epoch': 0.0}\n",
      "{'loss': 0.6343, 'grad_norm': 5.50262975692749, 'learning_rate': 0.000299244, 'epoch': 0.0}\n",
      "{'loss': 0.6286, 'grad_norm': 4.9795308113098145, 'learning_rate': 0.00029923199999999997, 'epoch': 0.0}\n",
      "{'loss': 0.6111, 'grad_norm': 5.3482794761657715, 'learning_rate': 0.00029921999999999994, 'epoch': 0.0}\n",
      "{'loss': 0.6137, 'grad_norm': 5.2660298347473145, 'learning_rate': 0.00029920799999999997, 'epoch': 0.0}\n",
      "{'loss': 0.611, 'grad_norm': 3.07896089553833, 'learning_rate': 0.00029919599999999995, 'epoch': 0.0}\n",
      "{'loss': 0.5928, 'grad_norm': 8.095474243164062, 'learning_rate': 0.000299184, 'epoch': 0.0}\n",
      "{'loss': 0.6139, 'grad_norm': 6.7143473625183105, 'learning_rate': 0.000299172, 'epoch': 0.0}\n",
      "{'loss': 0.6105, 'grad_norm': 7.953627586364746, 'learning_rate': 0.00029916, 'epoch': 0.0}\n",
      "{'loss': 0.6017, 'grad_norm': 4.887324333190918, 'learning_rate': 0.000299148, 'epoch': 0.0}\n",
      "{'loss': 0.6066, 'grad_norm': 5.280966758728027, 'learning_rate': 0.000299136, 'epoch': 0.0}\n",
      "{'loss': 0.5859, 'grad_norm': 7.668287754058838, 'learning_rate': 0.00029912399999999995, 'epoch': 0.0}\n",
      "{'loss': 0.5902, 'grad_norm': 5.729834079742432, 'learning_rate': 0.000299112, 'epoch': 0.0}\n",
      "{'loss': 0.5927, 'grad_norm': 5.478388786315918, 'learning_rate': 0.00029909999999999995, 'epoch': 0.0}\n",
      "{'loss': 0.5839, 'grad_norm': 3.390122890472412, 'learning_rate': 0.000299088, 'epoch': 0.0}\n",
      "{'loss': 0.6185, 'grad_norm': 7.322494029998779, 'learning_rate': 0.000299076, 'epoch': 0.0}\n",
      "{'loss': 0.5624, 'grad_norm': 6.962793827056885, 'learning_rate': 0.000299064, 'epoch': 0.0}\n",
      "{'loss': 0.5819, 'grad_norm': 5.778462886810303, 'learning_rate': 0.00029905199999999996, 'epoch': 0.0}\n",
      "{'loss': 0.5688, 'grad_norm': 9.282979011535645, 'learning_rate': 0.00029904, 'epoch': 0.0}\n",
      "{'loss': 0.5974, 'grad_norm': 4.508838653564453, 'learning_rate': 0.00029902799999999996, 'epoch': 0.0}\n",
      "{'loss': 0.5539, 'grad_norm': 5.19209098815918, 'learning_rate': 0.000299016, 'epoch': 0.0}\n",
      "{'loss': 0.5613, 'grad_norm': 4.75389289855957, 'learning_rate': 0.00029900399999999996, 'epoch': 0.0}\n",
      "{'loss': 0.583, 'grad_norm': 4.831140041351318, 'learning_rate': 0.000298992, 'epoch': 0.0}\n",
      "{'loss': 0.5671, 'grad_norm': 3.7304317951202393, 'learning_rate': 0.00029897999999999996, 'epoch': 0.0}\n",
      "{'loss': 0.5425, 'grad_norm': 5.382282733917236, 'learning_rate': 0.000298968, 'epoch': 0.0}\n",
      "{'loss': 0.5492, 'grad_norm': 6.650603771209717, 'learning_rate': 0.00029895599999999996, 'epoch': 0.0}\n",
      "{'loss': 0.5332, 'grad_norm': 5.065451622009277, 'learning_rate': 0.000298944, 'epoch': 0.0}\n",
      "{'loss': 0.5481, 'grad_norm': 7.293885707855225, 'learning_rate': 0.00029893199999999996, 'epoch': 0.0}\n",
      "{'loss': 0.561, 'grad_norm': 5.453551769256592, 'learning_rate': 0.00029891999999999994, 'epoch': 0.0}\n",
      "{'loss': 0.5695, 'grad_norm': 3.469924211502075, 'learning_rate': 0.00029890799999999996, 'epoch': 0.0}\n",
      "{'loss': 0.5361, 'grad_norm': 6.413525581359863, 'learning_rate': 0.000298896, 'epoch': 0.0}\n",
      "{'loss': 0.5244, 'grad_norm': 4.003545761108398, 'learning_rate': 0.00029888399999999997, 'epoch': 0.0}\n",
      "{'loss': 0.5324, 'grad_norm': 6.585995197296143, 'learning_rate': 0.000298872, 'epoch': 0.0}\n",
      "{'loss': 0.5221, 'grad_norm': 4.646562099456787, 'learning_rate': 0.00029885999999999997, 'epoch': 0.0}\n",
      "{'loss': 0.5329, 'grad_norm': 2.877429485321045, 'learning_rate': 0.000298848, 'epoch': 0.0}\n",
      "{'loss': 0.5254, 'grad_norm': 5.336552143096924, 'learning_rate': 0.00029883599999999997, 'epoch': 0.0}\n",
      "{'loss': 0.5025, 'grad_norm': 5.627103328704834, 'learning_rate': 0.00029882399999999994, 'epoch': 0.0}\n",
      "{'loss': 0.4996, 'grad_norm': 3.56960129737854, 'learning_rate': 0.00029881199999999997, 'epoch': 0.0}\n",
      "{'loss': 0.5127, 'grad_norm': 5.542482376098633, 'learning_rate': 0.0002988, 'epoch': 0.0}\n",
      "{'loss': 0.5156, 'grad_norm': 3.7436797618865967, 'learning_rate': 0.00029878799999999997, 'epoch': 0.0}\n",
      "{'loss': 0.5276, 'grad_norm': 4.427595138549805, 'learning_rate': 0.000298776, 'epoch': 0.0}\n",
      "{'loss': 0.499, 'grad_norm': 5.150705337524414, 'learning_rate': 0.000298764, 'epoch': 0.0}\n",
      "{'loss': 0.5128, 'grad_norm': 4.170351505279541, 'learning_rate': 0.00029875199999999995, 'epoch': 0.0}\n",
      "{'loss': 0.5038, 'grad_norm': 5.997584819793701, 'learning_rate': 0.00029874, 'epoch': 0.0}\n",
      "{'loss': 0.4935, 'grad_norm': 3.5740177631378174, 'learning_rate': 0.00029872799999999995, 'epoch': 0.0}\n",
      "{'loss': 0.5096, 'grad_norm': 6.191461563110352, 'learning_rate': 0.000298716, 'epoch': 0.0}\n",
      "{'loss': 0.4898, 'grad_norm': 3.8011608123779297, 'learning_rate': 0.00029870399999999995, 'epoch': 0.0}\n",
      "{'loss': 0.5, 'grad_norm': 4.383612632751465, 'learning_rate': 0.000298692, 'epoch': 0.0}\n",
      "{'loss': 0.4747, 'grad_norm': 6.353057384490967, 'learning_rate': 0.00029868, 'epoch': 0.0}\n",
      "{'loss': 0.501, 'grad_norm': 4.0269293785095215, 'learning_rate': 0.000298668, 'epoch': 0.0}\n",
      "{'loss': 0.4962, 'grad_norm': 5.609602451324463, 'learning_rate': 0.00029865599999999995, 'epoch': 0.0}\n",
      "{'loss': 0.4822, 'grad_norm': 2.968383550643921, 'learning_rate': 0.000298644, 'epoch': 0.0}\n",
      "{'loss': 0.4701, 'grad_norm': 3.635587215423584, 'learning_rate': 0.00029863199999999996, 'epoch': 0.0}\n",
      "{'loss': 0.4821, 'grad_norm': 3.5532569885253906, 'learning_rate': 0.00029862, 'epoch': 0.0}\n",
      "{'loss': 0.4619, 'grad_norm': 5.651016712188721, 'learning_rate': 0.00029860799999999996, 'epoch': 0.0}\n",
      "{'loss': 0.4727, 'grad_norm': 4.4948272705078125, 'learning_rate': 0.000298596, 'epoch': 0.0}\n",
      "{'loss': 0.4776, 'grad_norm': 8.601306915283203, 'learning_rate': 0.000298584, 'epoch': 0.0}\n",
      "{'loss': 0.4531, 'grad_norm': 7.100347518920898, 'learning_rate': 0.000298572, 'epoch': 0.0}\n",
      "{'loss': 0.4682, 'grad_norm': 4.4668192863464355, 'learning_rate': 0.00029855999999999996, 'epoch': 0.0}\n",
      "{'loss': 0.4852, 'grad_norm': 4.8671956062316895, 'learning_rate': 0.000298548, 'epoch': 0.0}\n",
      "{'loss': 0.4616, 'grad_norm': 5.751241683959961, 'learning_rate': 0.00029853599999999996, 'epoch': 0.0}\n",
      "{'loss': 0.4644, 'grad_norm': 4.282456874847412, 'learning_rate': 0.000298524, 'epoch': 0.0}\n",
      "{'loss': 0.4607, 'grad_norm': 3.7902145385742188, 'learning_rate': 0.00029851199999999996, 'epoch': 0.0}\n",
      "{'loss': 0.4709, 'grad_norm': 3.411968946456909, 'learning_rate': 0.0002985, 'epoch': 0.01}\n",
      "{'loss': 0.4702, 'grad_norm': 4.081420421600342, 'learning_rate': 0.00029848799999999997, 'epoch': 0.01}\n",
      "{'loss': 0.4466, 'grad_norm': 4.178391456604004, 'learning_rate': 0.000298476, 'epoch': 0.01}\n",
      "{'loss': 0.4504, 'grad_norm': 4.5048508644104, 'learning_rate': 0.00029846399999999997, 'epoch': 0.01}\n",
      "{'loss': 0.4562, 'grad_norm': 2.8357186317443848, 'learning_rate': 0.00029845199999999994, 'epoch': 0.01}\n",
      "{'loss': 0.4448, 'grad_norm': 3.7660322189331055, 'learning_rate': 0.00029843999999999997, 'epoch': 0.01}\n",
      "{'loss': 0.4615, 'grad_norm': 4.208014965057373, 'learning_rate': 0.00029842799999999994, 'epoch': 0.01}\n",
      "{'loss': 0.4428, 'grad_norm': 4.888354301452637, 'learning_rate': 0.00029841599999999997, 'epoch': 0.01}\n",
      "{'loss': 0.4363, 'grad_norm': 4.255516052246094, 'learning_rate': 0.000298404, 'epoch': 0.01}\n",
      "{'loss': 0.4456, 'grad_norm': 3.3964688777923584, 'learning_rate': 0.00029839199999999997, 'epoch': 0.01}\n",
      "{'loss': 0.4259, 'grad_norm': 2.538668632507324, 'learning_rate': 0.00029838, 'epoch': 0.01}\n",
      "{'loss': 0.4351, 'grad_norm': 7.187539577484131, 'learning_rate': 0.000298368, 'epoch': 0.01}\n",
      "{'loss': 0.4395, 'grad_norm': 5.587326526641846, 'learning_rate': 0.00029835599999999995, 'epoch': 0.01}\n",
      "{'loss': 0.4165, 'grad_norm': 5.257188320159912, 'learning_rate': 0.000298344, 'epoch': 0.01}\n",
      "{'loss': 0.4424, 'grad_norm': 6.68412446975708, 'learning_rate': 0.00029833199999999995, 'epoch': 0.01}\n",
      "{'loss': 0.4128, 'grad_norm': 4.853565692901611, 'learning_rate': 0.00029832, 'epoch': 0.01}\n",
      "{'loss': 0.4212, 'grad_norm': 4.19740104675293, 'learning_rate': 0.000298308, 'epoch': 0.01}\n",
      "{'loss': 0.4134, 'grad_norm': 4.731738567352295, 'learning_rate': 0.000298296, 'epoch': 0.01}\n",
      "{'loss': 0.4156, 'grad_norm': 3.8589611053466797, 'learning_rate': 0.000298284, 'epoch': 0.01}\n",
      "{'loss': 0.416, 'grad_norm': 3.999377489089966, 'learning_rate': 0.000298272, 'epoch': 0.01}\n",
      "{'loss': 0.4127, 'grad_norm': 4.568110466003418, 'learning_rate': 0.00029825999999999995, 'epoch': 0.01}\n",
      "{'loss': 0.4224, 'grad_norm': 3.760765790939331, 'learning_rate': 0.000298248, 'epoch': 0.01}\n",
      "{'loss': 0.4143, 'grad_norm': 3.990661144256592, 'learning_rate': 0.00029823599999999995, 'epoch': 0.01}\n",
      "{'loss': 0.4258, 'grad_norm': 5.367715358734131, 'learning_rate': 0.000298224, 'epoch': 0.01}\n",
      "{'loss': 0.424, 'grad_norm': 3.207041025161743, 'learning_rate': 0.000298212, 'epoch': 0.01}\n",
      "{'loss': 0.4065, 'grad_norm': 3.6252448558807373, 'learning_rate': 0.0002982, 'epoch': 0.01}\n",
      "{'loss': 0.4043, 'grad_norm': 4.356091022491455, 'learning_rate': 0.00029818799999999996, 'epoch': 0.01}\n",
      "{'loss': 0.3988, 'grad_norm': 4.9590911865234375, 'learning_rate': 0.000298176, 'epoch': 0.01}\n",
      "{'loss': 0.4065, 'grad_norm': 2.9521429538726807, 'learning_rate': 0.00029816399999999996, 'epoch': 0.01}\n",
      "{'loss': 0.399, 'grad_norm': 3.1666719913482666, 'learning_rate': 0.00029815199999999993, 'epoch': 0.01}\n",
      "{'loss': 0.3815, 'grad_norm': 6.945850849151611, 'learning_rate': 0.00029813999999999996, 'epoch': 0.01}\n",
      "{'loss': 0.3935, 'grad_norm': 2.718804359436035, 'learning_rate': 0.000298128, 'epoch': 0.01}\n",
      "{'loss': 0.3982, 'grad_norm': 3.4454445838928223, 'learning_rate': 0.00029811599999999996, 'epoch': 0.01}\n",
      "{'loss': 0.3783, 'grad_norm': 5.953805923461914, 'learning_rate': 0.000298104, 'epoch': 0.01}\n",
      "{'loss': 0.39, 'grad_norm': 3.0092482566833496, 'learning_rate': 0.00029809199999999996, 'epoch': 0.01}\n",
      "{'loss': 0.3871, 'grad_norm': 4.375281810760498, 'learning_rate': 0.00029808, 'epoch': 0.01}\n",
      "{'loss': 0.3862, 'grad_norm': 5.562203407287598, 'learning_rate': 0.00029806799999999997, 'epoch': 0.01}\n",
      "{'loss': 0.3758, 'grad_norm': 3.641622543334961, 'learning_rate': 0.00029805599999999994, 'epoch': 0.01}\n",
      "{'loss': 0.3817, 'grad_norm': 3.6463963985443115, 'learning_rate': 0.00029804399999999997, 'epoch': 0.01}\n",
      "{'loss': 0.3729, 'grad_norm': 6.888224124908447, 'learning_rate': 0.000298032, 'epoch': 0.01}\n",
      "{'loss': 0.381, 'grad_norm': 4.448245525360107, 'learning_rate': 0.00029801999999999997, 'epoch': 0.01}\n",
      "{'loss': 0.3858, 'grad_norm': 5.368537425994873, 'learning_rate': 0.000298008, 'epoch': 0.01}\n",
      "{'loss': 0.3807, 'grad_norm': 4.246615886688232, 'learning_rate': 0.00029799599999999997, 'epoch': 0.01}\n",
      "{'loss': 0.3784, 'grad_norm': 3.6560471057891846, 'learning_rate': 0.000297984, 'epoch': 0.01}\n",
      "{'loss': 0.3723, 'grad_norm': 3.0043115615844727, 'learning_rate': 0.00029797199999999997, 'epoch': 0.01}\n",
      "{'loss': 0.3701, 'grad_norm': 6.242751598358154, 'learning_rate': 0.00029795999999999995, 'epoch': 0.01}\n",
      "{'loss': 0.3723, 'grad_norm': 4.145946502685547, 'learning_rate': 0.000297948, 'epoch': 0.01}\n",
      "{'loss': 0.3674, 'grad_norm': 2.4963908195495605, 'learning_rate': 0.000297936, 'epoch': 0.01}\n",
      "{'loss': 0.3648, 'grad_norm': 7.813316822052002, 'learning_rate': 0.000297924, 'epoch': 0.01}\n",
      "{'loss': 0.362, 'grad_norm': 4.618705749511719, 'learning_rate': 0.000297912, 'epoch': 0.01}\n",
      "{'loss': 0.3586, 'grad_norm': 5.112116813659668, 'learning_rate': 0.0002979, 'epoch': 0.01}\n",
      "{'loss': 0.3774, 'grad_norm': 3.8887577056884766, 'learning_rate': 0.00029788799999999995, 'epoch': 0.01}\n",
      "{'loss': 0.3566, 'grad_norm': 3.8447253704071045, 'learning_rate': 0.000297876, 'epoch': 0.01}\n",
      "{'loss': 0.3572, 'grad_norm': 1.3077870607376099, 'learning_rate': 0.00029786399999999995, 'epoch': 0.01}\n",
      "{'loss': 0.3415, 'grad_norm': 4.327483177185059, 'learning_rate': 0.000297852, 'epoch': 0.01}\n",
      "{'loss': 0.3615, 'grad_norm': 6.535661220550537, 'learning_rate': 0.00029783999999999995, 'epoch': 0.01}\n",
      "{'loss': 0.3618, 'grad_norm': 4.517356872558594, 'learning_rate': 0.000297828, 'epoch': 0.01}\n",
      "{'loss': 0.3432, 'grad_norm': 3.8013393878936768, 'learning_rate': 0.000297816, 'epoch': 0.01}\n",
      "{'loss': 0.3502, 'grad_norm': 2.275855541229248, 'learning_rate': 0.000297804, 'epoch': 0.01}\n",
      "{'loss': 0.3555, 'grad_norm': 3.980956792831421, 'learning_rate': 0.00029779199999999996, 'epoch': 0.01}\n",
      "{'loss': 0.3515, 'grad_norm': 3.220689296722412, 'learning_rate': 0.00029778, 'epoch': 0.01}\n",
      "{'loss': 0.3302, 'grad_norm': 4.187653064727783, 'learning_rate': 0.00029776799999999996, 'epoch': 0.01}\n",
      "{'loss': 0.3598, 'grad_norm': 3.363800525665283, 'learning_rate': 0.000297756, 'epoch': 0.01}\n",
      "{'loss': 0.3415, 'grad_norm': 3.990802049636841, 'learning_rate': 0.00029774399999999996, 'epoch': 0.01}\n",
      "{'loss': 0.3511, 'grad_norm': 6.7539753913879395, 'learning_rate': 0.000297732, 'epoch': 0.01}\n",
      "{'loss': 0.3376, 'grad_norm': 4.215581893920898, 'learning_rate': 0.00029771999999999996, 'epoch': 0.01}\n",
      "{'loss': 0.3421, 'grad_norm': 3.7245805263519287, 'learning_rate': 0.000297708, 'epoch': 0.01}\n",
      "{'loss': 0.3387, 'grad_norm': 3.9711811542510986, 'learning_rate': 0.00029769599999999996, 'epoch': 0.01}\n",
      "{'loss': 0.3575, 'grad_norm': 5.138594627380371, 'learning_rate': 0.000297684, 'epoch': 0.01}\n",
      "{'loss': 0.3383, 'grad_norm': 4.402811050415039, 'learning_rate': 0.00029767199999999996, 'epoch': 0.01}\n",
      "{'loss': 0.3299, 'grad_norm': 4.514734745025635, 'learning_rate': 0.00029765999999999994, 'epoch': 0.01}\n",
      "{'loss': 0.3233, 'grad_norm': 3.409395456314087, 'learning_rate': 0.00029764799999999997, 'epoch': 0.01}\n",
      "{'loss': 0.3426, 'grad_norm': 3.829223394393921, 'learning_rate': 0.000297636, 'epoch': 0.01}\n",
      "{'loss': 0.3481, 'grad_norm': 4.794765472412109, 'learning_rate': 0.00029762399999999997, 'epoch': 0.01}\n",
      "{'loss': 0.3199, 'grad_norm': 3.616466760635376, 'learning_rate': 0.000297612, 'epoch': 0.01}\n",
      "{'loss': 0.3106, 'grad_norm': 2.0074334144592285, 'learning_rate': 0.00029759999999999997, 'epoch': 0.01}\n",
      "{'loss': 0.3431, 'grad_norm': 3.4904072284698486, 'learning_rate': 0.00029758799999999994, 'epoch': 0.01}\n",
      "{'loss': 0.3359, 'grad_norm': 3.2474262714385986, 'learning_rate': 0.00029757599999999997, 'epoch': 0.01}\n",
      "{'loss': 0.3171, 'grad_norm': 2.2046120166778564, 'learning_rate': 0.00029756399999999994, 'epoch': 0.01}\n",
      "{'loss': 0.3174, 'grad_norm': 3.270704507827759, 'learning_rate': 0.00029755199999999997, 'epoch': 0.01}\n",
      "{'loss': 0.3078, 'grad_norm': 6.199949264526367, 'learning_rate': 0.00029754, 'epoch': 0.01}\n",
      "{'loss': 0.3219, 'grad_norm': 3.1752798557281494, 'learning_rate': 0.000297528, 'epoch': 0.01}\n",
      "{'loss': 0.3306, 'grad_norm': 4.1181960105896, 'learning_rate': 0.000297516, 'epoch': 0.01}\n",
      "{'loss': 0.3218, 'grad_norm': 8.430895805358887, 'learning_rate': 0.000297504, 'epoch': 0.01}\n",
      "{'loss': 0.3004, 'grad_norm': 3.6327836513519287, 'learning_rate': 0.00029749199999999995, 'epoch': 0.01}\n",
      "{'loss': 0.3225, 'grad_norm': 3.9855458736419678, 'learning_rate': 0.00029748, 'epoch': 0.01}\n",
      "{'loss': 0.3081, 'grad_norm': 3.1704607009887695, 'learning_rate': 0.00029746799999999995, 'epoch': 0.01}\n",
      "{'loss': 0.3208, 'grad_norm': 4.177967071533203, 'learning_rate': 0.000297456, 'epoch': 0.01}\n",
      "{'loss': 0.3084, 'grad_norm': 5.246538162231445, 'learning_rate': 0.000297444, 'epoch': 0.01}\n",
      "{'loss': 0.3214, 'grad_norm': 3.07259464263916, 'learning_rate': 0.000297432, 'epoch': 0.01}\n",
      "{'loss': 0.3062, 'grad_norm': 6.013926029205322, 'learning_rate': 0.00029741999999999995, 'epoch': 0.01}\n",
      "{'loss': 0.3111, 'grad_norm': 4.3407793045043945, 'learning_rate': 0.000297408, 'epoch': 0.01}\n",
      "{'loss': 0.3181, 'grad_norm': 2.254818916320801, 'learning_rate': 0.00029739599999999996, 'epoch': 0.01}\n",
      "{'loss': 0.3021, 'grad_norm': 4.9073405265808105, 'learning_rate': 0.000297384, 'epoch': 0.01}\n",
      "{'loss': 0.2929, 'grad_norm': 3.252007484436035, 'learning_rate': 0.00029737199999999996, 'epoch': 0.01}\n",
      "{'loss': 0.2912, 'grad_norm': 2.1151444911956787, 'learning_rate': 0.00029736, 'epoch': 0.01}\n",
      "{'loss': 0.2965, 'grad_norm': 5.043329238891602, 'learning_rate': 0.000297348, 'epoch': 0.01}\n",
      "{'loss': 0.2871, 'grad_norm': 4.571120262145996, 'learning_rate': 0.000297336, 'epoch': 0.01}\n",
      "{'loss': 0.301, 'grad_norm': 3.900527000427246, 'learning_rate': 0.00029732399999999996, 'epoch': 0.01}\n",
      "{'loss': 0.2993, 'grad_norm': 3.046999931335449, 'learning_rate': 0.000297312, 'epoch': 0.01}\n",
      "{'loss': 0.2909, 'grad_norm': 7.3164238929748535, 'learning_rate': 0.00029729999999999996, 'epoch': 0.01}\n",
      "{'loss': 0.2925, 'grad_norm': 3.856707811355591, 'learning_rate': 0.00029728799999999994, 'epoch': 0.01}\n",
      "{'loss': 0.2979, 'grad_norm': 4.680398464202881, 'learning_rate': 0.00029727599999999996, 'epoch': 0.01}\n",
      "{'loss': 0.2936, 'grad_norm': 4.924483299255371, 'learning_rate': 0.000297264, 'epoch': 0.01}\n",
      "{'loss': 0.2956, 'grad_norm': 3.7757415771484375, 'learning_rate': 0.00029725199999999997, 'epoch': 0.01}\n",
      "{'loss': 0.2872, 'grad_norm': 4.030797481536865, 'learning_rate': 0.00029724, 'epoch': 0.01}\n",
      "{'loss': 0.3093, 'grad_norm': 6.5244927406311035, 'learning_rate': 0.00029722799999999997, 'epoch': 0.01}\n",
      "{'loss': 0.288, 'grad_norm': 2.794266939163208, 'learning_rate': 0.000297216, 'epoch': 0.01}\n",
      "{'loss': 0.2931, 'grad_norm': 5.083655834197998, 'learning_rate': 0.00029720399999999997, 'epoch': 0.01}\n",
      "{'loss': 0.2783, 'grad_norm': 3.7218425273895264, 'learning_rate': 0.00029719199999999994, 'epoch': 0.01}\n",
      "{'loss': 0.2823, 'grad_norm': 2.748614549636841, 'learning_rate': 0.00029717999999999997, 'epoch': 0.01}\n",
      "{'loss': 0.2832, 'grad_norm': 3.7635743618011475, 'learning_rate': 0.000297168, 'epoch': 0.01}\n",
      "{'loss': 0.2897, 'grad_norm': 5.542245864868164, 'learning_rate': 0.00029715599999999997, 'epoch': 0.01}\n",
      "{'loss': 0.2994, 'grad_norm': 2.242884874343872, 'learning_rate': 0.000297144, 'epoch': 0.01}\n",
      "{'loss': 0.2748, 'grad_norm': 7.526284217834473, 'learning_rate': 0.000297132, 'epoch': 0.01}\n",
      "{'loss': 0.2708, 'grad_norm': 5.532268524169922, 'learning_rate': 0.00029711999999999995, 'epoch': 0.01}\n",
      "{'loss': 0.2841, 'grad_norm': 2.815558671951294, 'learning_rate': 0.000297108, 'epoch': 0.01}\n",
      "{'loss': 0.2657, 'grad_norm': 5.024725437164307, 'learning_rate': 0.00029709599999999995, 'epoch': 0.01}\n",
      "{'loss': 0.2735, 'grad_norm': 2.7787668704986572, 'learning_rate': 0.000297084, 'epoch': 0.01}\n",
      "{'loss': 0.2837, 'grad_norm': 2.41702938079834, 'learning_rate': 0.00029707199999999995, 'epoch': 0.01}\n",
      "{'loss': 0.2613, 'grad_norm': 3.317436456680298, 'learning_rate': 0.00029706, 'epoch': 0.01}\n",
      "{'loss': 0.2791, 'grad_norm': 3.5465333461761475, 'learning_rate': 0.000297048, 'epoch': 0.01}\n",
      "{'loss': 0.2773, 'grad_norm': 3.9719297885894775, 'learning_rate': 0.000297036, 'epoch': 0.01}\n",
      "{'loss': 0.2647, 'grad_norm': 3.6171634197235107, 'learning_rate': 0.00029702399999999995, 'epoch': 0.01}\n",
      "{'loss': 0.275, 'grad_norm': 4.843073844909668, 'learning_rate': 0.000297012, 'epoch': 0.01}\n",
      "{'loss': 0.267, 'grad_norm': 2.4583070278167725, 'learning_rate': 0.00029699999999999996, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15402033925056458, 'eval_bleu': 76.2479, 'eval_gen_len': 12.9687, 'eval_runtime': 10387.1373, 'eval_samples_per_second': 9.627, 'eval_steps_per_second': 1.203, 'epoch': 0.01}\n",
      "{'loss': 0.2507, 'grad_norm': 4.469458103179932, 'learning_rate': 0.000296988, 'epoch': 1.0}\n",
      "{'loss': 0.257, 'grad_norm': 2.307915687561035, 'learning_rate': 0.00029697599999999996, 'epoch': 1.0}\n",
      "{'loss': 0.2545, 'grad_norm': 4.1516900062561035, 'learning_rate': 0.000296964, 'epoch': 1.0}\n",
      "{'loss': 0.2554, 'grad_norm': 3.5532469749450684, 'learning_rate': 0.000296952, 'epoch': 1.0}\n",
      "{'loss': 0.2547, 'grad_norm': 4.177746295928955, 'learning_rate': 0.00029694, 'epoch': 1.0}\n",
      "{'loss': 0.2514, 'grad_norm': 2.5770959854125977, 'learning_rate': 0.00029692799999999996, 'epoch': 1.0}\n",
      "{'loss': 0.2588, 'grad_norm': 3.0951461791992188, 'learning_rate': 0.000296916, 'epoch': 1.0}\n",
      "{'loss': 0.2536, 'grad_norm': 3.9138803482055664, 'learning_rate': 0.00029690399999999996, 'epoch': 1.0}\n",
      "{'loss': 0.2511, 'grad_norm': 3.7397305965423584, 'learning_rate': 0.000296892, 'epoch': 1.0}\n",
      "{'loss': 0.2392, 'grad_norm': 6.43604040145874, 'learning_rate': 0.00029687999999999996, 'epoch': 1.0}\n",
      "{'loss': 0.2647, 'grad_norm': 4.724180221557617, 'learning_rate': 0.000296868, 'epoch': 1.0}\n",
      "{'loss': 0.2402, 'grad_norm': 2.510127305984497, 'learning_rate': 0.00029685599999999996, 'epoch': 1.0}\n",
      "{'loss': 0.2434, 'grad_norm': 3.5771379470825195, 'learning_rate': 0.000296844, 'epoch': 1.0}\n",
      "{'loss': 0.2552, 'grad_norm': 3.504481077194214, 'learning_rate': 0.00029683199999999997, 'epoch': 1.0}\n",
      "{'loss': 0.2407, 'grad_norm': 2.9315757751464844, 'learning_rate': 0.00029681999999999994, 'epoch': 1.0}\n",
      "{'loss': 0.2458, 'grad_norm': 2.220478057861328, 'learning_rate': 0.00029680799999999997, 'epoch': 1.0}\n",
      "{'loss': 0.2413, 'grad_norm': 4.2761549949646, 'learning_rate': 0.00029679599999999994, 'epoch': 1.0}\n",
      "{'loss': 0.2501, 'grad_norm': 4.24411678314209, 'learning_rate': 0.00029678399999999997, 'epoch': 1.0}\n",
      "{'loss': 0.2361, 'grad_norm': 5.064977645874023, 'learning_rate': 0.000296772, 'epoch': 1.0}\n",
      "{'loss': 0.2376, 'grad_norm': 3.47209095954895, 'learning_rate': 0.00029675999999999997, 'epoch': 1.0}\n",
      "{'loss': 0.2438, 'grad_norm': 2.6467812061309814, 'learning_rate': 0.000296748, 'epoch': 1.0}\n",
      "{'loss': 0.2387, 'grad_norm': 3.1148087978363037, 'learning_rate': 0.00029673599999999997, 'epoch': 1.0}\n",
      "{'loss': 0.2489, 'grad_norm': 5.073225498199463, 'learning_rate': 0.00029672399999999995, 'epoch': 1.0}\n",
      "{'loss': 0.244, 'grad_norm': 2.9214072227478027, 'learning_rate': 0.000296712, 'epoch': 1.0}\n",
      "{'loss': 0.2446, 'grad_norm': 5.28171443939209, 'learning_rate': 0.00029669999999999995, 'epoch': 1.0}\n",
      "{'loss': 0.2376, 'grad_norm': 3.4855754375457764, 'learning_rate': 0.000296688, 'epoch': 1.0}\n",
      "{'loss': 0.2399, 'grad_norm': 3.788079023361206, 'learning_rate': 0.000296676, 'epoch': 1.0}\n",
      "{'loss': 0.2259, 'grad_norm': 4.801810264587402, 'learning_rate': 0.000296664, 'epoch': 1.0}\n",
      "{'loss': 0.231, 'grad_norm': 3.7288622856140137, 'learning_rate': 0.000296652, 'epoch': 1.0}\n",
      "{'loss': 0.242, 'grad_norm': 2.247149705886841, 'learning_rate': 0.00029664, 'epoch': 1.0}\n",
      "{'loss': 0.2322, 'grad_norm': 3.327486038208008, 'learning_rate': 0.00029662799999999995, 'epoch': 1.0}\n",
      "{'loss': 0.2303, 'grad_norm': 2.6558070182800293, 'learning_rate': 0.000296616, 'epoch': 1.0}\n",
      "{'loss': 0.2382, 'grad_norm': 2.2251293659210205, 'learning_rate': 0.00029660399999999995, 'epoch': 1.0}\n",
      "{'loss': 0.2377, 'grad_norm': 4.1783976554870605, 'learning_rate': 0.000296592, 'epoch': 1.0}\n",
      "{'loss': 0.2332, 'grad_norm': 4.905104160308838, 'learning_rate': 0.00029658, 'epoch': 1.0}\n",
      "{'loss': 0.2321, 'grad_norm': 2.5108256340026855, 'learning_rate': 0.000296568, 'epoch': 1.0}\n",
      "{'loss': 0.2273, 'grad_norm': 3.8586246967315674, 'learning_rate': 0.00029655599999999996, 'epoch': 1.0}\n",
      "{'loss': 0.2234, 'grad_norm': 2.666472911834717, 'learning_rate': 0.000296544, 'epoch': 1.0}\n",
      "{'loss': 0.2274, 'grad_norm': 5.123117446899414, 'learning_rate': 0.00029653199999999996, 'epoch': 1.0}\n",
      "{'loss': 0.2188, 'grad_norm': 4.221427917480469, 'learning_rate': 0.00029651999999999993, 'epoch': 1.0}\n",
      "{'loss': 0.2285, 'grad_norm': 5.361599922180176, 'learning_rate': 0.00029650799999999996, 'epoch': 1.0}\n",
      "{'loss': 0.2193, 'grad_norm': 4.349587440490723, 'learning_rate': 0.000296496, 'epoch': 1.0}\n",
      "{'loss': 0.2285, 'grad_norm': 3.015333652496338, 'learning_rate': 0.00029648399999999996, 'epoch': 1.0}\n",
      "{'loss': 0.2248, 'grad_norm': 4.2043280601501465, 'learning_rate': 0.000296472, 'epoch': 1.0}\n",
      "{'loss': 0.2301, 'grad_norm': 5.29231595993042, 'learning_rate': 0.00029645999999999996, 'epoch': 1.0}\n",
      "{'loss': 0.2289, 'grad_norm': 1.3294615745544434, 'learning_rate': 0.000296448, 'epoch': 1.0}\n",
      "{'loss': 0.23, 'grad_norm': 5.821530342102051, 'learning_rate': 0.00029643599999999997, 'epoch': 1.0}\n",
      "{'loss': 0.2272, 'grad_norm': 3.229858160018921, 'learning_rate': 0.00029642399999999994, 'epoch': 1.0}\n",
      "{'loss': 0.2167, 'grad_norm': 4.404061794281006, 'learning_rate': 0.00029641199999999997, 'epoch': 1.0}\n",
      "{'loss': 0.2112, 'grad_norm': 5.136993885040283, 'learning_rate': 0.0002964, 'epoch': 1.0}\n",
      "{'loss': 0.2169, 'grad_norm': 4.993639945983887, 'learning_rate': 0.00029638799999999997, 'epoch': 1.0}\n",
      "{'loss': 0.2259, 'grad_norm': 3.9006104469299316, 'learning_rate': 0.000296376, 'epoch': 1.0}\n",
      "{'loss': 0.2279, 'grad_norm': 1.51738440990448, 'learning_rate': 0.00029636399999999997, 'epoch': 1.0}\n",
      "{'loss': 0.2195, 'grad_norm': 3.663952112197876, 'learning_rate': 0.000296352, 'epoch': 1.0}\n",
      "{'loss': 0.2225, 'grad_norm': 2.539846181869507, 'learning_rate': 0.00029633999999999997, 'epoch': 1.0}\n",
      "{'loss': 0.2095, 'grad_norm': 4.835390090942383, 'learning_rate': 0.00029632799999999995, 'epoch': 1.0}\n",
      "{'loss': 0.2242, 'grad_norm': 5.1593427658081055, 'learning_rate': 0.000296316, 'epoch': 1.0}\n",
      "{'loss': 0.2106, 'grad_norm': 3.826903820037842, 'learning_rate': 0.000296304, 'epoch': 1.0}\n",
      "{'loss': 0.2261, 'grad_norm': 1.7483819723129272, 'learning_rate': 0.000296292, 'epoch': 1.0}\n",
      "{'loss': 0.2027, 'grad_norm': 3.3222715854644775, 'learning_rate': 0.00029628, 'epoch': 1.0}\n",
      "{'loss': 0.2148, 'grad_norm': 4.372520446777344, 'learning_rate': 0.000296268, 'epoch': 1.0}\n",
      "{'loss': 0.2096, 'grad_norm': 5.912413120269775, 'learning_rate': 0.00029625599999999995, 'epoch': 1.0}\n",
      "{'loss': 0.2123, 'grad_norm': 3.581550121307373, 'learning_rate': 0.000296244, 'epoch': 1.0}\n",
      "{'loss': 0.2235, 'grad_norm': 1.942481279373169, 'learning_rate': 0.00029623199999999995, 'epoch': 1.0}\n",
      "{'loss': 0.2003, 'grad_norm': 3.2576303482055664, 'learning_rate': 0.00029622, 'epoch': 1.0}\n",
      "{'loss': 0.2062, 'grad_norm': 4.622177600860596, 'learning_rate': 0.00029620799999999995, 'epoch': 1.0}\n",
      "{'loss': 0.2126, 'grad_norm': 1.6911524534225464, 'learning_rate': 0.000296196, 'epoch': 1.0}\n",
      "{'loss': 0.2014, 'grad_norm': 4.850314140319824, 'learning_rate': 0.000296184, 'epoch': 1.0}\n",
      "{'loss': 0.2079, 'grad_norm': 4.474655628204346, 'learning_rate': 0.000296172, 'epoch': 1.0}\n",
      "{'loss': 0.2123, 'grad_norm': 5.514101982116699, 'learning_rate': 0.00029615999999999996, 'epoch': 1.0}\n",
      "{'loss': 0.2065, 'grad_norm': 1.60468327999115, 'learning_rate': 0.000296148, 'epoch': 1.0}\n",
      "{'loss': 0.2123, 'grad_norm': 3.491628646850586, 'learning_rate': 0.00029613599999999996, 'epoch': 1.0}\n",
      "{'loss': 0.2117, 'grad_norm': 5.666593551635742, 'learning_rate': 0.000296124, 'epoch': 1.0}\n",
      "{'loss': 0.2091, 'grad_norm': 4.030158519744873, 'learning_rate': 0.00029611199999999996, 'epoch': 1.0}\n",
      "{'loss': 0.2071, 'grad_norm': 4.53306770324707, 'learning_rate': 0.0002961, 'epoch': 1.0}\n",
      "{'loss': 0.1954, 'grad_norm': 4.743644714355469, 'learning_rate': 0.00029608799999999996, 'epoch': 1.0}\n",
      "{'loss': 0.2232, 'grad_norm': 5.768840789794922, 'learning_rate': 0.000296076, 'epoch': 1.0}\n",
      "{'loss': 0.1939, 'grad_norm': 5.667995452880859, 'learning_rate': 0.00029606399999999996, 'epoch': 1.0}\n",
      "{'loss': 0.2035, 'grad_norm': 2.3747880458831787, 'learning_rate': 0.000296052, 'epoch': 1.0}\n",
      "{'loss': 0.2022, 'grad_norm': 3.483586549758911, 'learning_rate': 0.00029603999999999996, 'epoch': 1.0}\n",
      "{'loss': 0.2151, 'grad_norm': 3.3491456508636475, 'learning_rate': 0.000296028, 'epoch': 1.0}\n",
      "{'loss': 0.2005, 'grad_norm': 4.756645202636719, 'learning_rate': 0.00029601599999999997, 'epoch': 1.0}\n",
      "{'loss': 0.197, 'grad_norm': 2.790192127227783, 'learning_rate': 0.000296004, 'epoch': 1.0}\n",
      "{'loss': 0.2092, 'grad_norm': 4.106579780578613, 'learning_rate': 0.00029599199999999997, 'epoch': 1.0}\n",
      "{'loss': 0.1964, 'grad_norm': 4.016497611999512, 'learning_rate': 0.00029598, 'epoch': 1.0}\n",
      "{'loss': 0.1995, 'grad_norm': 4.942420482635498, 'learning_rate': 0.00029596799999999997, 'epoch': 1.0}\n",
      "{'loss': 0.1992, 'grad_norm': 2.6401617527008057, 'learning_rate': 0.00029595599999999994, 'epoch': 1.0}\n",
      "{'loss': 0.1954, 'grad_norm': 4.7758073806762695, 'learning_rate': 0.00029594399999999997, 'epoch': 1.0}\n",
      "{'loss': 0.1994, 'grad_norm': 5.731761932373047, 'learning_rate': 0.00029593199999999994, 'epoch': 1.0}\n",
      "{'loss': 0.2025, 'grad_norm': 3.1024973392486572, 'learning_rate': 0.00029591999999999997, 'epoch': 1.0}\n",
      "{'loss': 0.2115, 'grad_norm': 2.138432502746582, 'learning_rate': 0.000295908, 'epoch': 1.0}\n",
      "{'loss': 0.1965, 'grad_norm': 3.8966963291168213, 'learning_rate': 0.000295896, 'epoch': 1.0}\n",
      "{'loss': 0.1999, 'grad_norm': 1.6234917640686035, 'learning_rate': 0.000295884, 'epoch': 1.0}\n",
      "{'loss': 0.1888, 'grad_norm': 4.3059797286987305, 'learning_rate': 0.000295872, 'epoch': 1.0}\n",
      "{'loss': 0.1894, 'grad_norm': 1.8840763568878174, 'learning_rate': 0.00029585999999999995, 'epoch': 1.0}\n",
      "{'loss': 0.1906, 'grad_norm': 2.282855987548828, 'learning_rate': 0.000295848, 'epoch': 1.0}\n",
      "{'loss': 0.1941, 'grad_norm': 1.9440416097640991, 'learning_rate': 0.00029583599999999995, 'epoch': 1.0}\n",
      "{'loss': 0.1935, 'grad_norm': 4.569890975952148, 'learning_rate': 0.000295824, 'epoch': 1.0}\n",
      "{'loss': 0.1853, 'grad_norm': 1.7752164602279663, 'learning_rate': 0.000295812, 'epoch': 1.0}\n",
      "{'loss': 0.1992, 'grad_norm': 4.452846527099609, 'learning_rate': 0.0002958, 'epoch': 1.0}\n",
      "{'loss': 0.1944, 'grad_norm': 2.5970547199249268, 'learning_rate': 0.00029578799999999995, 'epoch': 1.0}\n",
      "{'loss': 0.2043, 'grad_norm': 2.5788943767547607, 'learning_rate': 0.000295776, 'epoch': 1.0}\n",
      "{'loss': 0.1901, 'grad_norm': 4.116145133972168, 'learning_rate': 0.00029576399999999996, 'epoch': 1.0}\n",
      "{'loss': 0.2011, 'grad_norm': 2.2878708839416504, 'learning_rate': 0.000295752, 'epoch': 1.0}\n",
      "{'loss': 0.1928, 'grad_norm': 4.658055305480957, 'learning_rate': 0.00029573999999999996, 'epoch': 1.0}\n",
      "{'loss': 0.1906, 'grad_norm': 1.8106087446212769, 'learning_rate': 0.000295728, 'epoch': 1.0}\n",
      "{'loss': 0.1943, 'grad_norm': 3.4216291904449463, 'learning_rate': 0.000295716, 'epoch': 1.0}\n",
      "{'loss': 0.1931, 'grad_norm': 4.85912561416626, 'learning_rate': 0.000295704, 'epoch': 1.0}\n",
      "{'loss': 0.1977, 'grad_norm': 3.615114450454712, 'learning_rate': 0.00029569199999999996, 'epoch': 1.0}\n",
      "{'loss': 0.1844, 'grad_norm': 3.8858120441436768, 'learning_rate': 0.00029568, 'epoch': 1.0}\n",
      "{'loss': 0.1898, 'grad_norm': 2.6860435009002686, 'learning_rate': 0.00029566799999999996, 'epoch': 1.0}\n",
      "{'loss': 0.1917, 'grad_norm': 3.2291619777679443, 'learning_rate': 0.00029565599999999994, 'epoch': 1.0}\n",
      "{'loss': 0.1844, 'grad_norm': 3.670548439025879, 'learning_rate': 0.00029564399999999996, 'epoch': 1.0}\n",
      "{'loss': 0.1804, 'grad_norm': 2.0008187294006348, 'learning_rate': 0.000295632, 'epoch': 1.0}\n",
      "{'loss': 0.1813, 'grad_norm': 2.4382779598236084, 'learning_rate': 0.00029561999999999996, 'epoch': 1.0}\n",
      "{'loss': 0.1762, 'grad_norm': 3.738363027572632, 'learning_rate': 0.000295608, 'epoch': 1.0}\n",
      "{'loss': 0.1854, 'grad_norm': 1.3159472942352295, 'learning_rate': 0.00029559599999999997, 'epoch': 1.0}\n",
      "{'loss': 0.1888, 'grad_norm': 6.352377891540527, 'learning_rate': 0.000295584, 'epoch': 1.0}\n",
      "{'loss': 0.1727, 'grad_norm': 4.082931995391846, 'learning_rate': 0.00029557199999999997, 'epoch': 1.0}\n",
      "{'loss': 0.1897, 'grad_norm': 2.894603967666626, 'learning_rate': 0.00029555999999999994, 'epoch': 1.0}\n",
      "{'loss': 0.1884, 'grad_norm': 1.309714913368225, 'learning_rate': 0.00029554799999999997, 'epoch': 1.0}\n",
      "{'loss': 0.1865, 'grad_norm': 5.656927108764648, 'learning_rate': 0.000295536, 'epoch': 1.0}\n",
      "{'loss': 0.1817, 'grad_norm': 3.3133885860443115, 'learning_rate': 0.00029552399999999997, 'epoch': 1.0}\n",
      "{'loss': 0.1766, 'grad_norm': 1.636926293373108, 'learning_rate': 0.000295512, 'epoch': 1.0}\n",
      "{'loss': 0.1864, 'grad_norm': 1.7907216548919678, 'learning_rate': 0.00029549999999999997, 'epoch': 1.0}\n",
      "{'loss': 0.1938, 'grad_norm': 3.0987331867218018, 'learning_rate': 0.00029548799999999995, 'epoch': 1.01}\n",
      "{'loss': 0.1814, 'grad_norm': 2.4971959590911865, 'learning_rate': 0.000295476, 'epoch': 1.01}\n",
      "{'loss': 0.184, 'grad_norm': 3.5239028930664062, 'learning_rate': 0.00029546399999999995, 'epoch': 1.01}\n",
      "{'loss': 0.1841, 'grad_norm': 1.508712649345398, 'learning_rate': 0.000295452, 'epoch': 1.01}\n",
      "{'loss': 0.1778, 'grad_norm': 1.4140379428863525, 'learning_rate': 0.00029544, 'epoch': 1.01}\n",
      "{'loss': 0.1895, 'grad_norm': 3.222633123397827, 'learning_rate': 0.000295428, 'epoch': 1.01}\n",
      "{'loss': 0.1743, 'grad_norm': 4.336769104003906, 'learning_rate': 0.000295416, 'epoch': 1.01}\n",
      "{'loss': 0.1814, 'grad_norm': 2.9856433868408203, 'learning_rate': 0.000295404, 'epoch': 1.01}\n",
      "{'loss': 0.1891, 'grad_norm': 2.1437435150146484, 'learning_rate': 0.00029539199999999995, 'epoch': 1.01}\n",
      "{'loss': 0.1687, 'grad_norm': 4.279220104217529, 'learning_rate': 0.00029538, 'epoch': 1.01}\n",
      "{'loss': 0.1864, 'grad_norm': 3.118710517883301, 'learning_rate': 0.00029536799999999995, 'epoch': 1.01}\n",
      "{'loss': 0.1887, 'grad_norm': 5.606659412384033, 'learning_rate': 0.000295356, 'epoch': 1.01}\n",
      "{'loss': 0.1727, 'grad_norm': 1.3431044816970825, 'learning_rate': 0.00029534399999999996, 'epoch': 1.01}\n",
      "{'loss': 0.1817, 'grad_norm': 2.495474100112915, 'learning_rate': 0.000295332, 'epoch': 1.01}\n",
      "{'loss': 0.1754, 'grad_norm': 3.278956890106201, 'learning_rate': 0.00029532, 'epoch': 1.01}\n",
      "{'loss': 0.1772, 'grad_norm': 3.8303720951080322, 'learning_rate': 0.000295308, 'epoch': 1.01}\n",
      "{'loss': 0.1703, 'grad_norm': 3.2991204261779785, 'learning_rate': 0.00029529599999999996, 'epoch': 1.01}\n",
      "{'loss': 0.1738, 'grad_norm': 3.109499454498291, 'learning_rate': 0.000295284, 'epoch': 1.01}\n",
      "{'loss': 0.1734, 'grad_norm': 3.422159194946289, 'learning_rate': 0.00029527199999999996, 'epoch': 1.01}\n",
      "{'loss': 0.1733, 'grad_norm': 4.584260940551758, 'learning_rate': 0.00029526, 'epoch': 1.01}\n",
      "{'loss': 0.1816, 'grad_norm': 3.148480176925659, 'learning_rate': 0.00029524799999999996, 'epoch': 1.01}\n",
      "{'loss': 0.1759, 'grad_norm': 1.876806378364563, 'learning_rate': 0.000295236, 'epoch': 1.01}\n",
      "{'loss': 0.1782, 'grad_norm': 4.697540283203125, 'learning_rate': 0.00029522399999999996, 'epoch': 1.01}\n",
      "{'loss': 0.1797, 'grad_norm': 2.575448751449585, 'learning_rate': 0.000295212, 'epoch': 1.01}\n",
      "{'loss': 0.1727, 'grad_norm': 3.0312538146972656, 'learning_rate': 0.00029519999999999997, 'epoch': 1.01}\n",
      "{'loss': 0.1748, 'grad_norm': 1.283278465270996, 'learning_rate': 0.00029518799999999994, 'epoch': 1.01}\n",
      "{'loss': 0.1714, 'grad_norm': 2.6384167671203613, 'learning_rate': 0.00029517599999999997, 'epoch': 1.01}\n",
      "{'loss': 0.1857, 'grad_norm': 4.004120826721191, 'learning_rate': 0.00029516399999999994, 'epoch': 1.01}\n",
      "{'loss': 0.1736, 'grad_norm': 2.5248236656188965, 'learning_rate': 0.00029515199999999997, 'epoch': 1.01}\n",
      "{'loss': 0.1636, 'grad_norm': 4.7431721687316895, 'learning_rate': 0.00029514, 'epoch': 1.01}\n",
      "{'loss': 0.175, 'grad_norm': 1.6553211212158203, 'learning_rate': 0.00029512799999999997, 'epoch': 1.01}\n",
      "{'loss': 0.1759, 'grad_norm': 0.8168877959251404, 'learning_rate': 0.000295116, 'epoch': 1.01}\n",
      "{'loss': 0.1695, 'grad_norm': 3.7031171321868896, 'learning_rate': 0.00029510399999999997, 'epoch': 1.01}\n",
      "{'loss': 0.1737, 'grad_norm': 2.45340895652771, 'learning_rate': 0.00029509199999999995, 'epoch': 1.01}\n",
      "{'loss': 0.1734, 'grad_norm': 1.3922107219696045, 'learning_rate': 0.00029508, 'epoch': 1.01}\n",
      "{'loss': 0.171, 'grad_norm': 1.9949575662612915, 'learning_rate': 0.00029506799999999995, 'epoch': 1.01}\n",
      "{'loss': 0.1656, 'grad_norm': 1.7302788496017456, 'learning_rate': 0.000295056, 'epoch': 1.01}\n",
      "{'loss': 0.1694, 'grad_norm': 0.9072257876396179, 'learning_rate': 0.000295044, 'epoch': 1.01}\n",
      "{'loss': 0.1688, 'grad_norm': 6.879487037658691, 'learning_rate': 0.000295032, 'epoch': 1.01}\n",
      "{'loss': 0.1701, 'grad_norm': 2.109572172164917, 'learning_rate': 0.00029502, 'epoch': 1.01}\n",
      "{'loss': 0.1768, 'grad_norm': 3.3364908695220947, 'learning_rate': 0.000295008, 'epoch': 1.01}\n",
      "{'loss': 0.181, 'grad_norm': 1.6328279972076416, 'learning_rate': 0.00029499599999999995, 'epoch': 1.01}\n",
      "{'loss': 0.1686, 'grad_norm': 1.6397472620010376, 'learning_rate': 0.000294984, 'epoch': 1.01}\n",
      "{'loss': 0.173, 'grad_norm': 1.407339096069336, 'learning_rate': 0.00029497199999999995, 'epoch': 1.01}\n",
      "{'loss': 0.1626, 'grad_norm': 3.1313230991363525, 'learning_rate': 0.00029496, 'epoch': 1.01}\n",
      "{'loss': 0.1634, 'grad_norm': 2.7047464847564697, 'learning_rate': 0.000294948, 'epoch': 1.01}\n",
      "{'loss': 0.163, 'grad_norm': 3.6101698875427246, 'learning_rate': 0.000294936, 'epoch': 1.01}\n",
      "{'loss': 0.1653, 'grad_norm': 7.064635276794434, 'learning_rate': 0.00029492399999999996, 'epoch': 1.01}\n",
      "{'loss': 0.166, 'grad_norm': 2.154524564743042, 'learning_rate': 0.000294912, 'epoch': 1.01}\n",
      "{'loss': 0.1664, 'grad_norm': 6.830127716064453, 'learning_rate': 0.00029489999999999996, 'epoch': 1.01}\n",
      "{'loss': 0.1779, 'grad_norm': 3.025782346725464, 'learning_rate': 0.00029488799999999993, 'epoch': 1.01}\n",
      "{'loss': 0.1638, 'grad_norm': 4.104227542877197, 'learning_rate': 0.00029487599999999996, 'epoch': 1.01}\n",
      "{'loss': 0.1676, 'grad_norm': 2.3682444095611572, 'learning_rate': 0.000294864, 'epoch': 1.01}\n",
      "{'loss': 0.1558, 'grad_norm': 1.5448088645935059, 'learning_rate': 0.00029485199999999996, 'epoch': 1.01}\n",
      "{'loss': 0.167, 'grad_norm': 3.966925621032715, 'learning_rate': 0.00029484, 'epoch': 1.01}\n",
      "{'loss': 0.1652, 'grad_norm': 2.9435529708862305, 'learning_rate': 0.00029482799999999996, 'epoch': 1.01}\n",
      "{'loss': 0.1627, 'grad_norm': 1.8825560808181763, 'learning_rate': 0.000294816, 'epoch': 1.01}\n",
      "{'loss': 0.1599, 'grad_norm': 4.014323711395264, 'learning_rate': 0.00029480399999999996, 'epoch': 1.01}\n",
      "{'loss': 0.1631, 'grad_norm': 1.992781162261963, 'learning_rate': 0.00029479199999999994, 'epoch': 1.01}\n",
      "{'loss': 0.1665, 'grad_norm': 10.371916770935059, 'learning_rate': 0.00029477999999999997, 'epoch': 1.01}\n",
      "{'loss': 0.1544, 'grad_norm': 3.292194128036499, 'learning_rate': 0.000294768, 'epoch': 1.01}\n",
      "{'loss': 0.1708, 'grad_norm': 3.5936741828918457, 'learning_rate': 0.00029475599999999997, 'epoch': 1.01}\n",
      "{'loss': 0.1633, 'grad_norm': 1.2943150997161865, 'learning_rate': 0.000294744, 'epoch': 1.01}\n",
      "{'loss': 0.1656, 'grad_norm': 4.971903324127197, 'learning_rate': 0.00029473199999999997, 'epoch': 1.01}\n",
      "{'loss': 0.1548, 'grad_norm': 3.66414737701416, 'learning_rate': 0.00029472, 'epoch': 1.01}\n",
      "{'loss': 0.1642, 'grad_norm': 1.809024453163147, 'learning_rate': 0.00029470799999999997, 'epoch': 1.01}\n",
      "{'loss': 0.1601, 'grad_norm': 2.0508861541748047, 'learning_rate': 0.00029469599999999994, 'epoch': 1.01}\n",
      "{'loss': 0.1677, 'grad_norm': 3.039597749710083, 'learning_rate': 0.00029468399999999997, 'epoch': 1.01}\n",
      "{'loss': 0.164, 'grad_norm': 2.2919676303863525, 'learning_rate': 0.000294672, 'epoch': 1.01}\n",
      "{'loss': 0.1611, 'grad_norm': 2.1096205711364746, 'learning_rate': 0.00029466, 'epoch': 1.01}\n",
      "{'loss': 0.1534, 'grad_norm': 5.604648113250732, 'learning_rate': 0.000294648, 'epoch': 1.01}\n",
      "{'loss': 0.1647, 'grad_norm': 1.9683454036712646, 'learning_rate': 0.000294636, 'epoch': 1.01}\n",
      "{'loss': 0.1703, 'grad_norm': 4.577098369598389, 'learning_rate': 0.00029462399999999995, 'epoch': 1.01}\n",
      "{'loss': 0.1575, 'grad_norm': 3.5364537239074707, 'learning_rate': 0.000294612, 'epoch': 1.01}\n",
      "{'loss': 0.1529, 'grad_norm': 3.562342882156372, 'learning_rate': 0.00029459999999999995, 'epoch': 1.01}\n",
      "{'loss': 0.168, 'grad_norm': 2.6538608074188232, 'learning_rate': 0.000294588, 'epoch': 1.01}\n",
      "{'loss': 0.1644, 'grad_norm': 2.097865343093872, 'learning_rate': 0.00029457599999999995, 'epoch': 1.01}\n",
      "{'loss': 0.1559, 'grad_norm': 2.883103609085083, 'learning_rate': 0.000294564, 'epoch': 1.01}\n",
      "{'loss': 0.16, 'grad_norm': 1.384385585784912, 'learning_rate': 0.000294552, 'epoch': 1.01}\n",
      "{'loss': 0.1515, 'grad_norm': 2.7600696086883545, 'learning_rate': 0.00029454, 'epoch': 1.01}\n",
      "{'loss': 0.1559, 'grad_norm': 1.9043347835540771, 'learning_rate': 0.00029452799999999996, 'epoch': 1.01}\n",
      "{'loss': 0.1613, 'grad_norm': 3.441181182861328, 'learning_rate': 0.000294516, 'epoch': 1.01}\n",
      "{'loss': 0.1595, 'grad_norm': 4.974977970123291, 'learning_rate': 0.00029450399999999996, 'epoch': 1.01}\n",
      "{'loss': 0.1472, 'grad_norm': 2.1234965324401855, 'learning_rate': 0.000294492, 'epoch': 1.01}\n",
      "{'loss': 0.1592, 'grad_norm': 1.2265558242797852, 'learning_rate': 0.00029447999999999996, 'epoch': 1.01}\n",
      "{'loss': 0.1516, 'grad_norm': 1.54194176197052, 'learning_rate': 0.000294468, 'epoch': 1.01}\n",
      "{'loss': 0.1576, 'grad_norm': 2.335618019104004, 'learning_rate': 0.00029445599999999996, 'epoch': 1.01}\n",
      "{'loss': 0.1549, 'grad_norm': 2.6020679473876953, 'learning_rate': 0.000294444, 'epoch': 1.01}\n",
      "{'loss': 0.1614, 'grad_norm': 1.6905816793441772, 'learning_rate': 0.00029443199999999996, 'epoch': 1.01}\n",
      "{'loss': 0.1498, 'grad_norm': 2.5219502449035645, 'learning_rate': 0.00029442, 'epoch': 1.01}\n",
      "{'loss': 0.1589, 'grad_norm': 3.62176513671875, 'learning_rate': 0.00029440799999999996, 'epoch': 1.01}\n",
      "{'loss': 0.163, 'grad_norm': 3.1216723918914795, 'learning_rate': 0.000294396, 'epoch': 1.01}\n",
      "{'loss': 0.1544, 'grad_norm': 2.696190118789673, 'learning_rate': 0.00029438399999999997, 'epoch': 1.01}\n",
      "{'loss': 0.1468, 'grad_norm': 1.7650787830352783, 'learning_rate': 0.000294372, 'epoch': 1.01}\n",
      "{'loss': 0.1454, 'grad_norm': 0.7740412354469299, 'learning_rate': 0.00029435999999999997, 'epoch': 1.01}\n",
      "{'loss': 0.1491, 'grad_norm': 1.9464247226715088, 'learning_rate': 0.000294348, 'epoch': 1.01}\n",
      "{'loss': 0.1506, 'grad_norm': 1.915330410003662, 'learning_rate': 0.00029433599999999997, 'epoch': 1.01}\n",
      "{'loss': 0.153, 'grad_norm': 1.9740687608718872, 'learning_rate': 0.00029432399999999994, 'epoch': 1.01}\n",
      "{'loss': 0.1571, 'grad_norm': 3.3373074531555176, 'learning_rate': 0.00029431199999999997, 'epoch': 1.01}\n",
      "{'loss': 0.149, 'grad_norm': 8.242945671081543, 'learning_rate': 0.00029429999999999994, 'epoch': 1.01}\n",
      "{'loss': 0.1532, 'grad_norm': 2.3551762104034424, 'learning_rate': 0.00029428799999999997, 'epoch': 1.01}\n",
      "{'loss': 0.1524, 'grad_norm': 6.130211353302002, 'learning_rate': 0.000294276, 'epoch': 1.01}\n",
      "{'loss': 0.1486, 'grad_norm': 1.363691806793213, 'learning_rate': 0.000294264, 'epoch': 1.01}\n",
      "{'loss': 0.1483, 'grad_norm': 1.6028647422790527, 'learning_rate': 0.000294252, 'epoch': 1.01}\n",
      "{'loss': 0.1473, 'grad_norm': 2.104785442352295, 'learning_rate': 0.00029424, 'epoch': 1.01}\n",
      "{'loss': 0.1593, 'grad_norm': 5.470669746398926, 'learning_rate': 0.00029422799999999995, 'epoch': 1.01}\n",
      "{'loss': 0.153, 'grad_norm': 0.3786894679069519, 'learning_rate': 0.000294216, 'epoch': 1.01}\n",
      "{'loss': 0.1553, 'grad_norm': 4.778529167175293, 'learning_rate': 0.00029420399999999995, 'epoch': 1.01}\n",
      "{'loss': 0.1498, 'grad_norm': 2.119534969329834, 'learning_rate': 0.000294192, 'epoch': 1.01}\n",
      "{'loss': 0.1569, 'grad_norm': 3.541841506958008, 'learning_rate': 0.00029418, 'epoch': 1.01}\n",
      "{'loss': 0.1492, 'grad_norm': 2.011268138885498, 'learning_rate': 0.000294168, 'epoch': 1.01}\n",
      "{'loss': 0.1548, 'grad_norm': 4.374622821807861, 'learning_rate': 0.00029415599999999995, 'epoch': 1.01}\n",
      "{'loss': 0.1591, 'grad_norm': 1.9713211059570312, 'learning_rate': 0.000294144, 'epoch': 1.01}\n",
      "{'loss': 0.1471, 'grad_norm': 4.10123348236084, 'learning_rate': 0.00029413199999999995, 'epoch': 1.01}\n",
      "{'loss': 0.1475, 'grad_norm': 2.934357166290283, 'learning_rate': 0.00029412, 'epoch': 1.01}\n",
      "{'loss': 0.1495, 'grad_norm': 2.8916146755218506, 'learning_rate': 0.00029410799999999996, 'epoch': 1.01}\n",
      "{'loss': 0.139, 'grad_norm': 4.570589542388916, 'learning_rate': 0.000294096, 'epoch': 1.01}\n",
      "{'loss': 0.1455, 'grad_norm': 4.507101058959961, 'learning_rate': 0.000294084, 'epoch': 1.01}\n",
      "{'loss': 0.154, 'grad_norm': 2.3714559078216553, 'learning_rate': 0.000294072, 'epoch': 1.01}\n",
      "{'loss': 0.1374, 'grad_norm': 2.637251615524292, 'learning_rate': 0.00029405999999999996, 'epoch': 1.01}\n",
      "{'loss': 0.1479, 'grad_norm': 2.348846912384033, 'learning_rate': 0.000294048, 'epoch': 1.01}\n",
      "{'loss': 0.1433, 'grad_norm': 2.6496942043304443, 'learning_rate': 0.00029403599999999996, 'epoch': 1.01}\n",
      "{'loss': 0.1417, 'grad_norm': 1.024275541305542, 'learning_rate': 0.00029402399999999993, 'epoch': 1.01}\n",
      "{'loss': 0.1459, 'grad_norm': 1.7120909690856934, 'learning_rate': 0.00029401199999999996, 'epoch': 1.01}\n",
      "{'loss': 0.1432, 'grad_norm': 2.1595065593719482, 'learning_rate': 0.000294, 'epoch': 1.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09588701277971268, 'eval_bleu': 82.0651, 'eval_gen_len': 13.0374, 'eval_runtime': 10281.1998, 'eval_samples_per_second': 9.726, 'eval_steps_per_second': 1.216, 'epoch': 1.01}\n",
      "{'loss': 0.1376, 'grad_norm': 2.2709035873413086, 'learning_rate': 0.00029398799999999996, 'epoch': 2.0}\n",
      "{'loss': 0.1442, 'grad_norm': 4.277287006378174, 'learning_rate': 0.000293976, 'epoch': 2.0}\n",
      "{'loss': 0.1386, 'grad_norm': 2.5494027137756348, 'learning_rate': 0.00029396399999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1445, 'grad_norm': 6.307223320007324, 'learning_rate': 0.000293952, 'epoch': 2.0}\n",
      "{'loss': 0.1372, 'grad_norm': 2.8489413261413574, 'learning_rate': 0.00029393999999999997, 'epoch': 2.0}\n",
      "{'loss': 0.141, 'grad_norm': 1.927731990814209, 'learning_rate': 0.00029392799999999994, 'epoch': 2.0}\n",
      "{'loss': 0.1424, 'grad_norm': 3.4384982585906982, 'learning_rate': 0.00029391599999999997, 'epoch': 2.0}\n",
      "{'loss': 0.138, 'grad_norm': 3.9315600395202637, 'learning_rate': 0.000293904, 'epoch': 2.0}\n",
      "{'loss': 0.1405, 'grad_norm': 2.142336368560791, 'learning_rate': 0.00029389199999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1353, 'grad_norm': 3.2081847190856934, 'learning_rate': 0.00029388, 'epoch': 2.0}\n",
      "{'loss': 0.1555, 'grad_norm': 3.0725629329681396, 'learning_rate': 0.00029386799999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1317, 'grad_norm': 1.739355444908142, 'learning_rate': 0.00029385599999999995, 'epoch': 2.0}\n",
      "{'loss': 0.1383, 'grad_norm': 1.131321668624878, 'learning_rate': 0.000293844, 'epoch': 2.0}\n",
      "{'loss': 0.1444, 'grad_norm': 2.362388849258423, 'learning_rate': 0.00029383199999999995, 'epoch': 2.0}\n",
      "{'loss': 0.132, 'grad_norm': 3.03063702583313, 'learning_rate': 0.00029382, 'epoch': 2.0}\n",
      "{'loss': 0.1364, 'grad_norm': 0.431235134601593, 'learning_rate': 0.000293808, 'epoch': 2.0}\n",
      "{'loss': 0.1324, 'grad_norm': 2.32902193069458, 'learning_rate': 0.000293796, 'epoch': 2.0}\n",
      "{'loss': 0.1418, 'grad_norm': 3.750286102294922, 'learning_rate': 0.000293784, 'epoch': 2.0}\n",
      "{'loss': 0.1315, 'grad_norm': 8.789199829101562, 'learning_rate': 0.000293772, 'epoch': 2.0}\n",
      "{'loss': 0.1353, 'grad_norm': 2.9331321716308594, 'learning_rate': 0.00029375999999999995, 'epoch': 2.0}\n",
      "{'loss': 0.137, 'grad_norm': 2.6493983268737793, 'learning_rate': 0.000293748, 'epoch': 2.0}\n",
      "{'loss': 0.1446, 'grad_norm': 4.424702167510986, 'learning_rate': 0.00029373599999999995, 'epoch': 2.0}\n",
      "{'loss': 0.1493, 'grad_norm': 3.7845425605773926, 'learning_rate': 0.000293724, 'epoch': 2.0}\n",
      "{'loss': 0.1378, 'grad_norm': 1.781535267829895, 'learning_rate': 0.00029371199999999996, 'epoch': 2.0}\n",
      "{'loss': 0.142, 'grad_norm': 2.9932804107666016, 'learning_rate': 0.0002937, 'epoch': 2.0}\n",
      "{'loss': 0.1328, 'grad_norm': 0.8702292442321777, 'learning_rate': 0.000293688, 'epoch': 2.0}\n",
      "{'loss': 0.139, 'grad_norm': 3.113612651824951, 'learning_rate': 0.000293676, 'epoch': 2.0}\n",
      "{'loss': 0.1338, 'grad_norm': 3.0813252925872803, 'learning_rate': 0.00029366399999999996, 'epoch': 2.0}\n",
      "{'loss': 0.1359, 'grad_norm': 3.338951826095581, 'learning_rate': 0.000293652, 'epoch': 2.0}\n",
      "{'loss': 0.136, 'grad_norm': 2.9664957523345947, 'learning_rate': 0.00029363999999999996, 'epoch': 2.0}\n",
      "{'loss': 0.1289, 'grad_norm': 1.0048376321792603, 'learning_rate': 0.000293628, 'epoch': 2.0}\n",
      "{'loss': 0.1255, 'grad_norm': 2.707369089126587, 'learning_rate': 0.00029361599999999996, 'epoch': 2.0}\n",
      "{'loss': 0.1358, 'grad_norm': 2.7925937175750732, 'learning_rate': 0.000293604, 'epoch': 2.0}\n",
      "{'loss': 0.1384, 'grad_norm': 3.2758543491363525, 'learning_rate': 0.00029359199999999996, 'epoch': 2.0}\n",
      "{'loss': 0.1315, 'grad_norm': 2.1986522674560547, 'learning_rate': 0.00029358, 'epoch': 2.0}\n",
      "{'loss': 0.1353, 'grad_norm': 1.8748422861099243, 'learning_rate': 0.00029356799999999996, 'epoch': 2.0}\n",
      "{'loss': 0.1276, 'grad_norm': 2.5773167610168457, 'learning_rate': 0.00029355599999999994, 'epoch': 2.0}\n",
      "{'loss': 0.1335, 'grad_norm': 1.8565456867218018, 'learning_rate': 0.00029354399999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1332, 'grad_norm': 4.530105113983154, 'learning_rate': 0.000293532, 'epoch': 2.0}\n",
      "{'loss': 0.1282, 'grad_norm': 3.8440396785736084, 'learning_rate': 0.00029351999999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1383, 'grad_norm': 2.955807685852051, 'learning_rate': 0.000293508, 'epoch': 2.0}\n",
      "{'loss': 0.125, 'grad_norm': 5.13429069519043, 'learning_rate': 0.00029349599999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1278, 'grad_norm': 3.286369562149048, 'learning_rate': 0.000293484, 'epoch': 2.0}\n",
      "{'loss': 0.1326, 'grad_norm': 3.3534038066864014, 'learning_rate': 0.00029347199999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1331, 'grad_norm': 2.0764176845550537, 'learning_rate': 0.00029345999999999994, 'epoch': 2.0}\n",
      "{'loss': 0.1334, 'grad_norm': 0.5238533616065979, 'learning_rate': 0.00029344799999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1321, 'grad_norm': 3.3318631649017334, 'learning_rate': 0.00029343599999999995, 'epoch': 2.0}\n",
      "{'loss': 0.1303, 'grad_norm': 1.6384979486465454, 'learning_rate': 0.000293424, 'epoch': 2.0}\n",
      "{'loss': 0.1284, 'grad_norm': 3.7384300231933594, 'learning_rate': 0.000293412, 'epoch': 2.0}\n",
      "{'loss': 0.1258, 'grad_norm': 3.2738399505615234, 'learning_rate': 0.0002934, 'epoch': 2.0}\n",
      "{'loss': 0.1286, 'grad_norm': 2.0293521881103516, 'learning_rate': 0.000293388, 'epoch': 2.0}\n",
      "{'loss': 0.1328, 'grad_norm': 2.9309005737304688, 'learning_rate': 0.000293376, 'epoch': 2.0}\n",
      "{'loss': 0.1343, 'grad_norm': 2.2000954151153564, 'learning_rate': 0.00029336399999999995, 'epoch': 2.0}\n",
      "{'loss': 0.1306, 'grad_norm': 2.6773478984832764, 'learning_rate': 0.000293352, 'epoch': 2.0}\n",
      "{'loss': 0.1347, 'grad_norm': 0.7172983884811401, 'learning_rate': 0.00029333999999999995, 'epoch': 2.0}\n",
      "{'loss': 0.1265, 'grad_norm': 3.458069086074829, 'learning_rate': 0.000293328, 'epoch': 2.0}\n",
      "{'loss': 0.1325, 'grad_norm': 3.935786008834839, 'learning_rate': 0.000293316, 'epoch': 2.0}\n",
      "{'loss': 0.1239, 'grad_norm': 3.8543701171875, 'learning_rate': 0.000293304, 'epoch': 2.0}\n",
      "{'loss': 0.1355, 'grad_norm': 4.473086357116699, 'learning_rate': 0.00029329199999999996, 'epoch': 2.0}\n",
      "{'loss': 0.1211, 'grad_norm': 4.033792495727539, 'learning_rate': 0.00029328, 'epoch': 2.0}\n",
      "{'loss': 0.1282, 'grad_norm': 4.11038064956665, 'learning_rate': 0.00029326799999999996, 'epoch': 2.0}\n",
      "{'loss': 0.1254, 'grad_norm': 6.386830806732178, 'learning_rate': 0.00029325599999999993, 'epoch': 2.0}\n",
      "{'loss': 0.1275, 'grad_norm': 2.0828099250793457, 'learning_rate': 0.00029324399999999996, 'epoch': 2.0}\n",
      "{'loss': 0.134, 'grad_norm': 1.8084986209869385, 'learning_rate': 0.000293232, 'epoch': 2.0}\n",
      "{'loss': 0.1209, 'grad_norm': 0.423042893409729, 'learning_rate': 0.00029322, 'epoch': 2.0}\n",
      "{'loss': 0.1267, 'grad_norm': 3.563321828842163, 'learning_rate': 0.000293208, 'epoch': 2.0}\n",
      "{'loss': 0.1285, 'grad_norm': 2.841665267944336, 'learning_rate': 0.00029319599999999996, 'epoch': 2.0}\n",
      "{'loss': 0.1243, 'grad_norm': 1.8566856384277344, 'learning_rate': 0.000293184, 'epoch': 2.0}\n",
      "{'loss': 0.1344, 'grad_norm': 4.3799028396606445, 'learning_rate': 0.00029317199999999996, 'epoch': 2.0}\n",
      "{'loss': 0.127, 'grad_norm': 4.769808769226074, 'learning_rate': 0.00029315999999999994, 'epoch': 2.0}\n",
      "{'loss': 0.1222, 'grad_norm': 0.5095666646957397, 'learning_rate': 0.00029314799999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1303, 'grad_norm': 2.8522884845733643, 'learning_rate': 0.000293136, 'epoch': 2.0}\n",
      "{'loss': 0.1292, 'grad_norm': 3.9617726802825928, 'learning_rate': 0.00029312399999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1293, 'grad_norm': 1.737900972366333, 'learning_rate': 0.000293112, 'epoch': 2.0}\n",
      "{'loss': 0.1274, 'grad_norm': 2.6229465007781982, 'learning_rate': 0.00029309999999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1195, 'grad_norm': 2.206629991531372, 'learning_rate': 0.000293088, 'epoch': 2.0}\n",
      "{'loss': 0.135, 'grad_norm': 5.507608413696289, 'learning_rate': 0.00029307599999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1186, 'grad_norm': 1.5188572406768799, 'learning_rate': 0.00029306399999999994, 'epoch': 2.0}\n",
      "{'loss': 0.1277, 'grad_norm': 2.7951951026916504, 'learning_rate': 0.00029305199999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1238, 'grad_norm': 2.387110710144043, 'learning_rate': 0.00029304, 'epoch': 2.0}\n",
      "{'loss': 0.129, 'grad_norm': 2.447939395904541, 'learning_rate': 0.000293028, 'epoch': 2.0}\n",
      "{'loss': 0.123, 'grad_norm': 0.9044855237007141, 'learning_rate': 0.000293016, 'epoch': 2.0}\n",
      "{'loss': 0.1228, 'grad_norm': 1.1171132326126099, 'learning_rate': 0.000293004, 'epoch': 2.0}\n",
      "{'loss': 0.1301, 'grad_norm': 3.639570713043213, 'learning_rate': 0.00029299199999999995, 'epoch': 2.0}\n",
      "{'loss': 0.1221, 'grad_norm': 3.1657662391662598, 'learning_rate': 0.00029298, 'epoch': 2.0}\n",
      "{'loss': 0.1251, 'grad_norm': 5.7147626876831055, 'learning_rate': 0.00029296799999999995, 'epoch': 2.0}\n",
      "{'loss': 0.1278, 'grad_norm': 3.4511513710021973, 'learning_rate': 0.000292956, 'epoch': 2.0}\n",
      "{'loss': 0.1218, 'grad_norm': 3.377957582473755, 'learning_rate': 0.00029294399999999995, 'epoch': 2.0}\n",
      "{'loss': 0.1278, 'grad_norm': 7.976517677307129, 'learning_rate': 0.000292932, 'epoch': 2.0}\n",
      "{'loss': 0.1247, 'grad_norm': 2.02519154548645, 'learning_rate': 0.00029292, 'epoch': 2.0}\n",
      "{'loss': 0.1376, 'grad_norm': 2.7919113636016846, 'learning_rate': 0.000292908, 'epoch': 2.0}\n",
      "{'loss': 0.1197, 'grad_norm': 2.419034242630005, 'learning_rate': 0.00029289599999999995, 'epoch': 2.0}\n",
      "{'loss': 0.1212, 'grad_norm': 3.7754876613616943, 'learning_rate': 0.000292884, 'epoch': 2.0}\n",
      "{'loss': 0.1148, 'grad_norm': 0.8889287710189819, 'learning_rate': 0.00029287199999999996, 'epoch': 2.0}\n",
      "{'loss': 0.1186, 'grad_norm': 1.004289150238037, 'learning_rate': 0.00029286, 'epoch': 2.0}\n",
      "{'loss': 0.1139, 'grad_norm': 1.5944300889968872, 'learning_rate': 0.00029284799999999996, 'epoch': 2.0}\n",
      "{'loss': 0.1215, 'grad_norm': 1.5856274366378784, 'learning_rate': 0.000292836, 'epoch': 2.0}\n",
      "{'loss': 0.1198, 'grad_norm': 5.564332962036133, 'learning_rate': 0.00029282399999999996, 'epoch': 2.0}\n",
      "{'loss': 0.1168, 'grad_norm': 2.1302220821380615, 'learning_rate': 0.000292812, 'epoch': 2.0}\n",
      "{'loss': 0.1247, 'grad_norm': 4.0562310218811035, 'learning_rate': 0.00029279999999999996, 'epoch': 2.0}\n",
      "{'loss': 0.1239, 'grad_norm': 2.4869186878204346, 'learning_rate': 0.000292788, 'epoch': 2.0}\n",
      "{'loss': 0.1307, 'grad_norm': 1.9940553903579712, 'learning_rate': 0.00029277599999999996, 'epoch': 2.0}\n",
      "{'loss': 0.1204, 'grad_norm': 1.2960954904556274, 'learning_rate': 0.000292764, 'epoch': 2.0}\n",
      "{'loss': 0.1296, 'grad_norm': 0.5060068368911743, 'learning_rate': 0.00029275199999999996, 'epoch': 2.0}\n",
      "{'loss': 0.1178, 'grad_norm': 2.3480186462402344, 'learning_rate': 0.00029274, 'epoch': 2.0}\n",
      "{'loss': 0.121, 'grad_norm': 2.540792226791382, 'learning_rate': 0.00029272799999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1235, 'grad_norm': 3.043269395828247, 'learning_rate': 0.000292716, 'epoch': 2.0}\n",
      "{'loss': 0.125, 'grad_norm': 2.3583412170410156, 'learning_rate': 0.00029270399999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1231, 'grad_norm': 0.8401320576667786, 'learning_rate': 0.00029269199999999994, 'epoch': 2.0}\n",
      "{'loss': 0.1141, 'grad_norm': 0.9102119207382202, 'learning_rate': 0.00029267999999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1231, 'grad_norm': 3.575181722640991, 'learning_rate': 0.00029266799999999994, 'epoch': 2.0}\n",
      "{'loss': 0.1224, 'grad_norm': 2.64037823677063, 'learning_rate': 0.00029265599999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1201, 'grad_norm': 3.303713321685791, 'learning_rate': 0.000292644, 'epoch': 2.0}\n",
      "{'loss': 0.1144, 'grad_norm': 1.6128613948822021, 'learning_rate': 0.00029263199999999997, 'epoch': 2.0}\n",
      "{'loss': 0.1175, 'grad_norm': 3.4190754890441895, 'learning_rate': 0.00029262, 'epoch': 2.0}\n",
      "{'loss': 0.1105, 'grad_norm': 3.250152349472046, 'learning_rate': 0.000292608, 'epoch': 2.0}\n",
      "{'loss': 0.1172, 'grad_norm': 0.7306925058364868, 'learning_rate': 0.00029259599999999995, 'epoch': 2.0}\n",
      "{'loss': 0.1228, 'grad_norm': 7.052609920501709, 'learning_rate': 0.000292584, 'epoch': 2.0}\n",
      "{'loss': 0.112, 'grad_norm': 2.7094674110412598, 'learning_rate': 0.00029257199999999995, 'epoch': 2.0}\n",
      "{'loss': 0.1241, 'grad_norm': 2.9605116844177246, 'learning_rate': 0.00029256, 'epoch': 2.0}\n",
      "{'loss': 0.1195, 'grad_norm': 1.5654844045639038, 'learning_rate': 0.000292548, 'epoch': 2.0}\n",
      "{'loss': 0.1197, 'grad_norm': 1.8896777629852295, 'learning_rate': 0.000292536, 'epoch': 2.0}\n",
      "{'loss': 0.1199, 'grad_norm': 4.192567348480225, 'learning_rate': 0.00029252399999999995, 'epoch': 2.0}\n",
      "{'loss': 0.1143, 'grad_norm': 2.19905424118042, 'learning_rate': 0.000292512, 'epoch': 2.0}\n",
      "{'loss': 0.1191, 'grad_norm': 4.060257434844971, 'learning_rate': 0.00029249999999999995, 'epoch': 2.0}\n",
      "{'loss': 0.1289, 'grad_norm': 3.5720231533050537, 'learning_rate': 0.000292488, 'epoch': 2.01}\n",
      "{'loss': 0.1194, 'grad_norm': 2.740933656692505, 'learning_rate': 0.00029247599999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1266, 'grad_norm': 3.1621556282043457, 'learning_rate': 0.000292464, 'epoch': 2.01}\n",
      "{'loss': 0.1204, 'grad_norm': 0.8545740842819214, 'learning_rate': 0.000292452, 'epoch': 2.01}\n",
      "{'loss': 0.1182, 'grad_norm': 2.388923168182373, 'learning_rate': 0.00029244, 'epoch': 2.01}\n",
      "{'loss': 0.1268, 'grad_norm': 2.8463668823242188, 'learning_rate': 0.00029242799999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1127, 'grad_norm': 1.3737515211105347, 'learning_rate': 0.000292416, 'epoch': 2.01}\n",
      "{'loss': 0.1222, 'grad_norm': 3.860771417617798, 'learning_rate': 0.00029240399999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1233, 'grad_norm': 1.3590078353881836, 'learning_rate': 0.00029239199999999993, 'epoch': 2.01}\n",
      "{'loss': 0.1094, 'grad_norm': 1.6744765043258667, 'learning_rate': 0.00029237999999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1236, 'grad_norm': 1.1201251745224, 'learning_rate': 0.000292368, 'epoch': 2.01}\n",
      "{'loss': 0.1253, 'grad_norm': 3.147468328475952, 'learning_rate': 0.00029235599999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1113, 'grad_norm': 0.8654192090034485, 'learning_rate': 0.000292344, 'epoch': 2.01}\n",
      "{'loss': 0.1265, 'grad_norm': 2.3188912868499756, 'learning_rate': 0.00029233199999999997, 'epoch': 2.01}\n",
      "{'loss': 0.1137, 'grad_norm': 1.5067181587219238, 'learning_rate': 0.00029232, 'epoch': 2.01}\n",
      "{'loss': 0.1184, 'grad_norm': 1.4770702123641968, 'learning_rate': 0.00029230799999999997, 'epoch': 2.01}\n",
      "{'loss': 0.11, 'grad_norm': 5.3268561363220215, 'learning_rate': 0.00029229599999999994, 'epoch': 2.01}\n",
      "{'loss': 0.1145, 'grad_norm': 3.205221176147461, 'learning_rate': 0.00029228399999999997, 'epoch': 2.01}\n",
      "{'loss': 0.1186, 'grad_norm': 1.641491174697876, 'learning_rate': 0.000292272, 'epoch': 2.01}\n",
      "{'loss': 0.1148, 'grad_norm': 1.2563878297805786, 'learning_rate': 0.00029225999999999997, 'epoch': 2.01}\n",
      "{'loss': 0.1215, 'grad_norm': 1.4177504777908325, 'learning_rate': 0.000292248, 'epoch': 2.01}\n",
      "{'loss': 0.1168, 'grad_norm': 1.9973009824752808, 'learning_rate': 0.00029223599999999997, 'epoch': 2.01}\n",
      "{'loss': 0.1209, 'grad_norm': 2.1990246772766113, 'learning_rate': 0.00029222399999999995, 'epoch': 2.01}\n",
      "{'loss': 0.1213, 'grad_norm': 1.9918477535247803, 'learning_rate': 0.000292212, 'epoch': 2.01}\n",
      "{'loss': 0.1137, 'grad_norm': 0.5774727463722229, 'learning_rate': 0.00029219999999999995, 'epoch': 2.01}\n",
      "{'loss': 0.1161, 'grad_norm': 3.2665913105010986, 'learning_rate': 0.000292188, 'epoch': 2.01}\n",
      "{'loss': 0.1083, 'grad_norm': 0.9700117707252502, 'learning_rate': 0.000292176, 'epoch': 2.01}\n",
      "{'loss': 0.1247, 'grad_norm': 2.9342832565307617, 'learning_rate': 0.000292164, 'epoch': 2.01}\n",
      "{'loss': 0.1172, 'grad_norm': 2.783564805984497, 'learning_rate': 0.000292152, 'epoch': 2.01}\n",
      "{'loss': 0.1099, 'grad_norm': 3.161661386489868, 'learning_rate': 0.00029214, 'epoch': 2.01}\n",
      "{'loss': 0.1197, 'grad_norm': 3.8382480144500732, 'learning_rate': 0.00029212799999999995, 'epoch': 2.01}\n",
      "{'loss': 0.1237, 'grad_norm': 0.47026482224464417, 'learning_rate': 0.000292116, 'epoch': 2.01}\n",
      "{'loss': 0.1087, 'grad_norm': 0.45630645751953125, 'learning_rate': 0.00029210399999999995, 'epoch': 2.01}\n",
      "{'loss': 0.1133, 'grad_norm': 2.7439465522766113, 'learning_rate': 0.000292092, 'epoch': 2.01}\n",
      "{'loss': 0.1183, 'grad_norm': 0.6043952703475952, 'learning_rate': 0.00029207999999999995, 'epoch': 2.01}\n",
      "{'loss': 0.1088, 'grad_norm': 0.47853580117225647, 'learning_rate': 0.000292068, 'epoch': 2.01}\n",
      "{'loss': 0.1128, 'grad_norm': 5.921606540679932, 'learning_rate': 0.000292056, 'epoch': 2.01}\n",
      "{'loss': 0.114, 'grad_norm': 0.4956236481666565, 'learning_rate': 0.000292044, 'epoch': 2.01}\n",
      "{'loss': 0.1137, 'grad_norm': 5.103168964385986, 'learning_rate': 0.00029203199999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1098, 'grad_norm': 2.6282458305358887, 'learning_rate': 0.00029202, 'epoch': 2.01}\n",
      "{'loss': 0.1223, 'grad_norm': 3.2450222969055176, 'learning_rate': 0.00029200799999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1237, 'grad_norm': 2.7570393085479736, 'learning_rate': 0.000291996, 'epoch': 2.01}\n",
      "{'loss': 0.1137, 'grad_norm': 1.091401219367981, 'learning_rate': 0.00029198399999999996, 'epoch': 2.01}\n",
      "{'loss': 0.113, 'grad_norm': 4.036409854888916, 'learning_rate': 0.000291972, 'epoch': 2.01}\n",
      "{'loss': 0.1126, 'grad_norm': 1.836958885192871, 'learning_rate': 0.00029195999999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1099, 'grad_norm': 3.6118693351745605, 'learning_rate': 0.000291948, 'epoch': 2.01}\n",
      "{'loss': 0.1113, 'grad_norm': 3.8493504524230957, 'learning_rate': 0.00029193599999999996, 'epoch': 2.01}\n",
      "{'loss': 0.113, 'grad_norm': 5.580748558044434, 'learning_rate': 0.00029192399999999994, 'epoch': 2.01}\n",
      "{'loss': 0.1121, 'grad_norm': 0.7934975624084473, 'learning_rate': 0.00029191199999999997, 'epoch': 2.01}\n",
      "{'loss': 0.1175, 'grad_norm': 3.619835615158081, 'learning_rate': 0.0002919, 'epoch': 2.01}\n",
      "{'loss': 0.1217, 'grad_norm': 1.5620776414871216, 'learning_rate': 0.00029188799999999997, 'epoch': 2.01}\n",
      "{'loss': 0.1142, 'grad_norm': 1.4396110773086548, 'learning_rate': 0.000291876, 'epoch': 2.01}\n",
      "{'loss': 0.1099, 'grad_norm': 0.4743040204048157, 'learning_rate': 0.00029186399999999997, 'epoch': 2.01}\n",
      "{'loss': 0.1087, 'grad_norm': 2.1959404945373535, 'learning_rate': 0.000291852, 'epoch': 2.01}\n",
      "{'loss': 0.1129, 'grad_norm': 3.5588090419769287, 'learning_rate': 0.00029183999999999997, 'epoch': 2.01}\n",
      "{'loss': 0.1166, 'grad_norm': 5.0135979652404785, 'learning_rate': 0.00029182799999999994, 'epoch': 2.01}\n",
      "{'loss': 0.11, 'grad_norm': 3.159623622894287, 'learning_rate': 0.00029181599999999997, 'epoch': 2.01}\n",
      "{'loss': 0.1092, 'grad_norm': 0.7589007019996643, 'learning_rate': 0.00029180399999999995, 'epoch': 2.01}\n",
      "{'loss': 0.1139, 'grad_norm': 2.533414125442505, 'learning_rate': 0.000291792, 'epoch': 2.01}\n",
      "{'loss': 0.1124, 'grad_norm': 1.4575071334838867, 'learning_rate': 0.00029178, 'epoch': 2.01}\n",
      "{'loss': 0.1014, 'grad_norm': 3.153585910797119, 'learning_rate': 0.000291768, 'epoch': 2.01}\n",
      "{'loss': 0.1107, 'grad_norm': 0.8423141241073608, 'learning_rate': 0.000291756, 'epoch': 2.01}\n",
      "{'loss': 0.1084, 'grad_norm': 2.1738460063934326, 'learning_rate': 0.000291744, 'epoch': 2.01}\n",
      "{'loss': 0.1111, 'grad_norm': 5.609316825866699, 'learning_rate': 0.00029173199999999995, 'epoch': 2.01}\n",
      "{'loss': 0.1081, 'grad_norm': 2.1674554347991943, 'learning_rate': 0.00029172, 'epoch': 2.01}\n",
      "{'loss': 0.116, 'grad_norm': 2.916914224624634, 'learning_rate': 0.00029170799999999995, 'epoch': 2.01}\n",
      "{'loss': 0.1073, 'grad_norm': 0.4129124581813812, 'learning_rate': 0.000291696, 'epoch': 2.01}\n",
      "{'loss': 0.1141, 'grad_norm': 3.408672571182251, 'learning_rate': 0.000291684, 'epoch': 2.01}\n",
      "{'loss': 0.1161, 'grad_norm': 3.1447489261627197, 'learning_rate': 0.000291672, 'epoch': 2.01}\n",
      "{'loss': 0.1117, 'grad_norm': 2.6587162017822266, 'learning_rate': 0.00029165999999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1082, 'grad_norm': 0.46870800852775574, 'learning_rate': 0.000291648, 'epoch': 2.01}\n",
      "{'loss': 0.11, 'grad_norm': 2.367058277130127, 'learning_rate': 0.00029163599999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1183, 'grad_norm': 4.445566177368164, 'learning_rate': 0.000291624, 'epoch': 2.01}\n",
      "{'loss': 0.1122, 'grad_norm': 1.593863844871521, 'learning_rate': 0.00029161199999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1063, 'grad_norm': 0.12959879636764526, 'learning_rate': 0.0002916, 'epoch': 2.01}\n",
      "{'loss': 0.1145, 'grad_norm': 1.8720011711120605, 'learning_rate': 0.000291588, 'epoch': 2.01}\n",
      "{'loss': 0.109, 'grad_norm': 2.2766153812408447, 'learning_rate': 0.000291576, 'epoch': 2.01}\n",
      "{'loss': 0.1062, 'grad_norm': 1.2660677433013916, 'learning_rate': 0.00029156399999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1069, 'grad_norm': 0.929209291934967, 'learning_rate': 0.000291552, 'epoch': 2.01}\n",
      "{'loss': 0.1055, 'grad_norm': 1.5919702053070068, 'learning_rate': 0.00029153999999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1112, 'grad_norm': 1.7186473608016968, 'learning_rate': 0.00029152799999999994, 'epoch': 2.01}\n",
      "{'loss': 0.1074, 'grad_norm': 1.6441524028778076, 'learning_rate': 0.00029151599999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1114, 'grad_norm': 5.618305206298828, 'learning_rate': 0.000291504, 'epoch': 2.01}\n",
      "{'loss': 0.1022, 'grad_norm': 1.4468591213226318, 'learning_rate': 0.00029149199999999997, 'epoch': 2.01}\n",
      "{'loss': 0.1102, 'grad_norm': 1.945196509361267, 'learning_rate': 0.00029148, 'epoch': 2.01}\n",
      "{'loss': 0.1074, 'grad_norm': 1.157016634941101, 'learning_rate': 0.00029146799999999997, 'epoch': 2.01}\n",
      "{'loss': 0.1123, 'grad_norm': 1.892235517501831, 'learning_rate': 0.000291456, 'epoch': 2.01}\n",
      "{'loss': 0.1107, 'grad_norm': 4.153439998626709, 'learning_rate': 0.00029144399999999997, 'epoch': 2.01}\n",
      "{'loss': 0.1126, 'grad_norm': 4.634562969207764, 'learning_rate': 0.00029143199999999994, 'epoch': 2.01}\n",
      "{'loss': 0.1072, 'grad_norm': 2.47878098487854, 'learning_rate': 0.00029141999999999997, 'epoch': 2.01}\n",
      "{'loss': 0.1139, 'grad_norm': 3.472118854522705, 'learning_rate': 0.000291408, 'epoch': 2.01}\n",
      "{'loss': 0.1138, 'grad_norm': 0.39303699135780334, 'learning_rate': 0.00029139599999999997, 'epoch': 2.01}\n",
      "{'loss': 0.11, 'grad_norm': 2.575265884399414, 'learning_rate': 0.000291384, 'epoch': 2.01}\n",
      "{'loss': 0.1043, 'grad_norm': 4.471051216125488, 'learning_rate': 0.000291372, 'epoch': 2.01}\n",
      "{'loss': 0.1049, 'grad_norm': 0.7849469780921936, 'learning_rate': 0.00029135999999999995, 'epoch': 2.01}\n",
      "{'loss': 0.1016, 'grad_norm': 1.960547924041748, 'learning_rate': 0.000291348, 'epoch': 2.01}\n",
      "{'loss': 0.104, 'grad_norm': 3.90724515914917, 'learning_rate': 0.00029133599999999995, 'epoch': 2.01}\n",
      "{'loss': 0.1083, 'grad_norm': 0.6677924990653992, 'learning_rate': 0.000291324, 'epoch': 2.01}\n",
      "{'loss': 0.1146, 'grad_norm': 1.9418089389801025, 'learning_rate': 0.000291312, 'epoch': 2.01}\n",
      "{'loss': 0.1025, 'grad_norm': 5.922062397003174, 'learning_rate': 0.0002913, 'epoch': 2.01}\n",
      "{'loss': 0.1075, 'grad_norm': 2.2685582637786865, 'learning_rate': 0.000291288, 'epoch': 2.01}\n",
      "{'loss': 0.1067, 'grad_norm': 1.3905583620071411, 'learning_rate': 0.000291276, 'epoch': 2.01}\n",
      "{'loss': 0.1065, 'grad_norm': 1.4377933740615845, 'learning_rate': 0.00029126399999999995, 'epoch': 2.01}\n",
      "{'loss': 0.1065, 'grad_norm': 3.5916378498077393, 'learning_rate': 0.000291252, 'epoch': 2.01}\n",
      "{'loss': 0.1038, 'grad_norm': 0.3926748037338257, 'learning_rate': 0.00029123999999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1139, 'grad_norm': 6.69644832611084, 'learning_rate': 0.000291228, 'epoch': 2.01}\n",
      "{'loss': 0.1054, 'grad_norm': 1.6826541423797607, 'learning_rate': 0.00029121599999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1089, 'grad_norm': 4.097982883453369, 'learning_rate': 0.000291204, 'epoch': 2.01}\n",
      "{'loss': 0.1076, 'grad_norm': 1.4968926906585693, 'learning_rate': 0.00029119199999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1127, 'grad_norm': 0.48118120431900024, 'learning_rate': 0.00029118, 'epoch': 2.01}\n",
      "{'loss': 0.1064, 'grad_norm': 1.3405027389526367, 'learning_rate': 0.00029116799999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1097, 'grad_norm': 3.5770325660705566, 'learning_rate': 0.000291156, 'epoch': 2.01}\n",
      "{'loss': 0.111, 'grad_norm': 3.378302574157715, 'learning_rate': 0.00029114399999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1021, 'grad_norm': 3.3440518379211426, 'learning_rate': 0.000291132, 'epoch': 2.01}\n",
      "{'loss': 0.1051, 'grad_norm': 3.1609373092651367, 'learning_rate': 0.00029111999999999996, 'epoch': 2.01}\n",
      "{'loss': 0.1058, 'grad_norm': 0.8198079466819763, 'learning_rate': 0.000291108, 'epoch': 2.01}\n",
      "{'loss': 0.105, 'grad_norm': 3.6088531017303467, 'learning_rate': 0.00029109599999999997, 'epoch': 2.01}\n",
      "{'loss': 0.1049, 'grad_norm': 1.593658685684204, 'learning_rate': 0.000291084, 'epoch': 2.01}\n",
      "{'loss': 0.1122, 'grad_norm': 4.447879791259766, 'learning_rate': 0.00029107199999999997, 'epoch': 2.01}\n",
      "{'loss': 0.0989, 'grad_norm': 0.7262019515037537, 'learning_rate': 0.00029105999999999994, 'epoch': 2.01}\n",
      "{'loss': 0.1059, 'grad_norm': 1.696982502937317, 'learning_rate': 0.00029104799999999997, 'epoch': 2.01}\n",
      "{'loss': 0.1089, 'grad_norm': 4.02099084854126, 'learning_rate': 0.00029103599999999994, 'epoch': 2.01}\n",
      "{'loss': 0.1002, 'grad_norm': 0.18269699811935425, 'learning_rate': 0.00029102399999999997, 'epoch': 2.01}\n",
      "{'loss': 0.1049, 'grad_norm': 1.1577106714248657, 'learning_rate': 0.000291012, 'epoch': 2.01}\n",
      "{'loss': 0.1049, 'grad_norm': 0.8291025757789612, 'learning_rate': 0.00029099999999999997, 'epoch': 2.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0802435427904129, 'eval_bleu': 83.4374, 'eval_gen_len': 13.0407, 'eval_runtime': 10299.0274, 'eval_samples_per_second': 9.71, 'eval_steps_per_second': 1.214, 'epoch': 2.01}\n",
      "{'loss': 0.0978, 'grad_norm': 0.8594223856925964, 'learning_rate': 0.000290988, 'epoch': 3.0}\n",
      "{'loss': 0.1034, 'grad_norm': 2.8545756340026855, 'learning_rate': 0.000290976, 'epoch': 3.0}\n",
      "{'loss': 0.1012, 'grad_norm': 0.9948955774307251, 'learning_rate': 0.00029096399999999995, 'epoch': 3.0}\n",
      "{'loss': 0.1063, 'grad_norm': 2.501620292663574, 'learning_rate': 0.000290952, 'epoch': 3.0}\n",
      "{'loss': 0.1053, 'grad_norm': 2.350952386856079, 'learning_rate': 0.00029093999999999995, 'epoch': 3.0}\n",
      "{'loss': 0.1026, 'grad_norm': 0.4806984066963196, 'learning_rate': 0.000290928, 'epoch': 3.0}\n",
      "{'loss': 0.1075, 'grad_norm': 2.849700450897217, 'learning_rate': 0.000290916, 'epoch': 3.0}\n",
      "{'loss': 0.1005, 'grad_norm': 0.37258675694465637, 'learning_rate': 0.000290904, 'epoch': 3.0}\n",
      "{'loss': 0.0989, 'grad_norm': 1.8506498336791992, 'learning_rate': 0.00029089199999999995, 'epoch': 3.0}\n",
      "{'loss': 0.0985, 'grad_norm': 2.229323625564575, 'learning_rate': 0.00029088, 'epoch': 3.0}\n",
      "{'loss': 0.116, 'grad_norm': 3.0412075519561768, 'learning_rate': 0.00029086799999999995, 'epoch': 3.0}\n",
      "{'loss': 0.0981, 'grad_norm': 1.722491979598999, 'learning_rate': 0.000290856, 'epoch': 3.0}\n",
      "{'loss': 0.1011, 'grad_norm': 0.7677403092384338, 'learning_rate': 0.00029084399999999995, 'epoch': 3.0}\n",
      "{'loss': 0.1049, 'grad_norm': 1.429568886756897, 'learning_rate': 0.000290832, 'epoch': 3.0}\n",
      "{'loss': 0.0972, 'grad_norm': 4.273577690124512, 'learning_rate': 0.00029082, 'epoch': 3.0}\n",
      "{'loss': 0.1043, 'grad_norm': 2.644643783569336, 'learning_rate': 0.000290808, 'epoch': 3.0}\n",
      "{'loss': 0.0971, 'grad_norm': 1.1898268461227417, 'learning_rate': 0.00029079599999999996, 'epoch': 3.0}\n",
      "{'loss': 0.1036, 'grad_norm': 3.0068631172180176, 'learning_rate': 0.000290784, 'epoch': 3.0}\n",
      "{'loss': 0.0952, 'grad_norm': 4.602987766265869, 'learning_rate': 0.00029077199999999996, 'epoch': 3.0}\n",
      "{'loss': 0.0971, 'grad_norm': 2.5085561275482178, 'learning_rate': 0.00029075999999999993, 'epoch': 3.0}\n",
      "{'loss': 0.1005, 'grad_norm': 0.9797974228858948, 'learning_rate': 0.00029074799999999996, 'epoch': 3.0}\n",
      "{'loss': 0.1037, 'grad_norm': 2.1844072341918945, 'learning_rate': 0.000290736, 'epoch': 3.0}\n",
      "{'loss': 0.1117, 'grad_norm': 1.585594654083252, 'learning_rate': 0.000290724, 'epoch': 3.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 25\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m Seq2SeqTrainingArguments(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../models/final-model/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     auto_find_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     max_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12500000\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     15\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stop]\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/utils/memory.py:146\u001b[0m, in \u001b[0;36mfind_executable_batch_size.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo executable batch size found, reached zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_reduce_batch_size(e):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2330\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2327\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2328\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\n\u001b[0;32m-> 2330\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2334\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/optimizer.py:170\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator_state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mXLA:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/optimization.py:882\u001b[0m, in \u001b[0;36mAdafactor.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    879\u001b[0m exp_avg_sq_row \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_avg_sq_row\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    880\u001b[0m exp_avg_sq_col \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_avg_sq_col\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 882\u001b[0m exp_avg_sq_row\u001b[38;5;241m.\u001b[39mmul_(beta2t)\u001b[38;5;241m.\u001b[39madd_(\u001b[43mupdate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, alpha\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta2t))\n\u001b[1;32m    883\u001b[0m exp_avg_sq_col\u001b[38;5;241m.\u001b[39mmul_(beta2t)\u001b[38;5;241m.\u001b[39madd_(update\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m), alpha\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta2t))\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Approximation of exponential moving average of square of gradient\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"../../models/final-model/\",\n",
    "    auto_find_batch_size=True,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False, #check this\n",
    "    push_to_hub=False,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    num_train_epochs=5\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset['train'],\n",
    "    eval_dataset=tokenized_eval_dataset['train'],\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer, None),\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
