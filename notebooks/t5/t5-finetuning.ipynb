{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning T5\n",
    "\n",
    "The purpose of this notebook is to document the process of finetuning Google's T5 model for translating from Literary Tibetan to English. This notebook relies on a dataset in the form of a pickled pandas dataframe which consists of a single column, 'translation'. Entries in that column should be a python dictionary of the structure: {'bo':'Tibetan text', 'en': 'English text'}.\n",
    "\n",
    "In creating this notebook I drew on the following tutorial from HuggingFace: https://huggingface.co/learn/nlp-course/chapter7/4?fw=pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('pandas', data_files='/home/j/Documents/Projects/MLotsawa/notebooks/t5/100k-sample-dataframe.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset['train'].train_test_split(test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"google-t5/t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lang = 'bo'\n",
    "target_lang = 'en'\n",
    "prefix = \"translate Tibetan to English: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "\n",
    "    inputs = [prefix + example[source_lang] for example in examples['translation']]\n",
    "    targets = [example[target_lang] for example in examples['translation']]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
    "\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32675050a32e4a67878d6681bcc61e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee46944275449a4a74fdda388d96c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-06 16:20:14.808938: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-06 16:20:14.808988: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-06 16:20:14.809035: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-06 16:20:14.819160: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65f3b809b3d403b8ccec088305fdbd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5089, 'learning_rate': 1.9866666666666667e-05, 'epoch': 0.2}\n",
      "{'loss': 3.5687, 'learning_rate': 1.97336e-05, 'epoch': 0.4}\n",
      "{'loss': 3.5619, 'learning_rate': 1.9600266666666666e-05, 'epoch': 0.6}\n",
      "{'loss': 3.5236, 'learning_rate': 1.9466933333333335e-05, 'epoch': 0.8}\n",
      "{'loss': 3.5155, 'learning_rate': 1.93336e-05, 'epoch': 1.0}\n",
      "{'loss': 3.5051, 'learning_rate': 1.9200533333333337e-05, 'epoch': 1.2}\n",
      "{'loss': 3.4719, 'learning_rate': 1.9067200000000003e-05, 'epoch': 1.4}\n",
      "{'loss': 3.478, 'learning_rate': 1.893386666666667e-05, 'epoch': 1.6}\n",
      "{'loss': 3.4501, 'learning_rate': 1.8800533333333334e-05, 'epoch': 1.8}\n",
      "{'loss': 3.4425, 'learning_rate': 1.86672e-05, 'epoch': 2.0}\n",
      "{'loss': 3.4254, 'learning_rate': 1.8534133333333336e-05, 'epoch': 2.2}\n",
      "{'loss': 3.3976, 'learning_rate': 1.8400800000000002e-05, 'epoch': 2.4}\n",
      "{'loss': 3.4021, 'learning_rate': 1.8267466666666667e-05, 'epoch': 2.6}\n",
      "{'loss': 3.4068, 'learning_rate': 1.8134133333333333e-05, 'epoch': 2.8}\n",
      "{'loss': 3.3961, 'learning_rate': 1.800106666666667e-05, 'epoch': 3.0}\n",
      "{'loss': 3.3651, 'learning_rate': 1.7867733333333335e-05, 'epoch': 3.2}\n",
      "{'loss': 3.3565, 'learning_rate': 1.77344e-05, 'epoch': 3.4}\n",
      "{'loss': 3.3505, 'learning_rate': 1.760106666666667e-05, 'epoch': 3.6}\n",
      "{'loss': 3.3442, 'learning_rate': 1.7467733333333336e-05, 'epoch': 3.8}\n",
      "{'loss': 3.3369, 'learning_rate': 1.733466666666667e-05, 'epoch': 4.0}\n",
      "{'loss': 3.3207, 'learning_rate': 1.7201333333333334e-05, 'epoch': 4.2}\n",
      "{'loss': 3.3168, 'learning_rate': 1.7068000000000003e-05, 'epoch': 4.4}\n",
      "{'loss': 3.3179, 'learning_rate': 1.693466666666667e-05, 'epoch': 4.6}\n",
      "{'loss': 3.2881, 'learning_rate': 1.6801600000000002e-05, 'epoch': 4.8}\n",
      "{'loss': 3.281, 'learning_rate': 1.6668266666666668e-05, 'epoch': 5.0}\n",
      "{'loss': 3.2797, 'learning_rate': 1.6534933333333333e-05, 'epoch': 5.2}\n",
      "{'loss': 3.2678, 'learning_rate': 1.6401600000000002e-05, 'epoch': 5.4}\n",
      "{'loss': 3.2691, 'learning_rate': 1.6268533333333335e-05, 'epoch': 5.6}\n",
      "{'loss': 3.2451, 'learning_rate': 1.61352e-05, 'epoch': 5.8}\n",
      "{'loss': 3.242, 'learning_rate': 1.6001866666666667e-05, 'epoch': 6.0}\n",
      "{'loss': 3.2289, 'learning_rate': 1.5868533333333332e-05, 'epoch': 6.2}\n",
      "{'loss': 3.2279, 'learning_rate': 1.57352e-05, 'epoch': 6.4}\n",
      "{'loss': 3.24, 'learning_rate': 1.5601866666666667e-05, 'epoch': 6.6}\n",
      "{'loss': 3.2071, 'learning_rate': 1.54688e-05, 'epoch': 6.8}\n",
      "{'loss': 3.1977, 'learning_rate': 1.5335466666666666e-05, 'epoch': 7.0}\n",
      "{'loss': 3.188, 'learning_rate': 1.5202133333333335e-05, 'epoch': 7.2}\n",
      "{'loss': 3.1848, 'learning_rate': 1.50688e-05, 'epoch': 7.4}\n",
      "{'loss': 3.1691, 'learning_rate': 1.4935733333333335e-05, 'epoch': 7.6}\n",
      "{'loss': 3.1906, 'learning_rate': 1.48024e-05, 'epoch': 7.8}\n",
      "{'loss': 3.1915, 'learning_rate': 1.4669066666666666e-05, 'epoch': 8.0}\n",
      "{'loss': 3.1636, 'learning_rate': 1.4535733333333336e-05, 'epoch': 8.2}\n",
      "{'loss': 3.1702, 'learning_rate': 1.4402666666666667e-05, 'epoch': 8.4}\n",
      "{'loss': 3.1564, 'learning_rate': 1.4269333333333336e-05, 'epoch': 8.6}\n",
      "{'loss': 3.1402, 'learning_rate': 1.4136000000000002e-05, 'epoch': 8.8}\n",
      "{'loss': 3.1336, 'learning_rate': 1.4002666666666669e-05, 'epoch': 9.0}\n",
      "{'loss': 3.1295, 'learning_rate': 1.3869333333333335e-05, 'epoch': 9.2}\n",
      "{'loss': 3.128, 'learning_rate': 1.373626666666667e-05, 'epoch': 9.4}\n",
      "{'loss': 3.128, 'learning_rate': 1.3602933333333335e-05, 'epoch': 9.6}\n",
      "{'loss': 3.102, 'learning_rate': 1.34696e-05, 'epoch': 9.8}\n",
      "{'loss': 3.121, 'learning_rate': 1.3336266666666668e-05, 'epoch': 10.0}\n",
      "{'loss': 3.099, 'learning_rate': 1.3203200000000001e-05, 'epoch': 10.2}\n",
      "{'loss': 3.0972, 'learning_rate': 1.3069866666666668e-05, 'epoch': 10.4}\n",
      "{'loss': 3.083, 'learning_rate': 1.2936533333333334e-05, 'epoch': 10.6}\n",
      "{'loss': 3.1069, 'learning_rate': 1.28032e-05, 'epoch': 10.8}\n",
      "{'loss': 3.0805, 'learning_rate': 1.2669866666666669e-05, 'epoch': 11.0}\n",
      "{'loss': 3.0846, 'learning_rate': 1.25368e-05, 'epoch': 11.2}\n",
      "{'loss': 3.0728, 'learning_rate': 1.2403466666666667e-05, 'epoch': 11.4}\n",
      "{'loss': 3.0672, 'learning_rate': 1.2270133333333335e-05, 'epoch': 11.6}\n",
      "{'loss': 3.0546, 'learning_rate': 1.2136800000000002e-05, 'epoch': 11.8}\n",
      "{'loss': 3.0696, 'learning_rate': 1.2003733333333333e-05, 'epoch': 12.0}\n",
      "{'loss': 3.0479, 'learning_rate': 1.1870400000000002e-05, 'epoch': 12.2}\n",
      "{'loss': 3.0511, 'learning_rate': 1.1737066666666668e-05, 'epoch': 12.4}\n",
      "{'loss': 3.049, 'learning_rate': 1.1603733333333334e-05, 'epoch': 12.6}\n",
      "{'loss': 3.0318, 'learning_rate': 1.1470400000000001e-05, 'epoch': 12.8}\n",
      "{'loss': 3.0558, 'learning_rate': 1.1337333333333334e-05, 'epoch': 13.0}\n",
      "{'loss': 3.0294, 'learning_rate': 1.1204000000000001e-05, 'epoch': 13.2}\n",
      "{'loss': 3.0171, 'learning_rate': 1.1070666666666667e-05, 'epoch': 13.4}\n",
      "{'loss': 3.0208, 'learning_rate': 1.0937333333333333e-05, 'epoch': 13.6}\n",
      "{'loss': 3.0329, 'learning_rate': 1.0804266666666667e-05, 'epoch': 13.8}\n",
      "{'loss': 3.0347, 'learning_rate': 1.0670933333333333e-05, 'epoch': 14.0}\n",
      "{'loss': 3.0133, 'learning_rate': 1.05376e-05, 'epoch': 14.2}\n",
      "{'loss': 3.0204, 'learning_rate': 1.0404266666666666e-05, 'epoch': 14.4}\n",
      "{'loss': 3.0004, 'learning_rate': 1.0270933333333335e-05, 'epoch': 14.6}\n",
      "{'loss': 3.015, 'learning_rate': 1.0137866666666667e-05, 'epoch': 14.8}\n",
      "{'loss': 2.9867, 'learning_rate': 1.0004533333333336e-05, 'epoch': 15.0}\n",
      "{'loss': 2.997, 'learning_rate': 9.871200000000001e-06, 'epoch': 15.2}\n",
      "{'loss': 2.9862, 'learning_rate': 9.737866666666667e-06, 'epoch': 15.4}\n",
      "{'loss': 2.9909, 'learning_rate': 9.604533333333334e-06, 'epoch': 15.6}\n",
      "{'loss': 2.9859, 'learning_rate': 9.471733333333335e-06, 'epoch': 15.8}\n",
      "{'loss': 2.978, 'learning_rate': 9.3384e-06, 'epoch': 16.0}\n",
      "{'loss': 2.9844, 'learning_rate': 9.205066666666668e-06, 'epoch': 16.2}\n",
      "{'loss': 2.9515, 'learning_rate': 9.071733333333335e-06, 'epoch': 16.4}\n",
      "{'loss': 2.9866, 'learning_rate': 8.9384e-06, 'epoch': 16.6}\n",
      "{'loss': 2.968, 'learning_rate': 8.805066666666668e-06, 'epoch': 16.8}\n",
      "{'loss': 2.9721, 'learning_rate': 8.671733333333334e-06, 'epoch': 17.0}\n",
      "{'loss': 2.9683, 'learning_rate': 8.538400000000001e-06, 'epoch': 17.2}\n",
      "{'loss': 2.9509, 'learning_rate': 8.405333333333334e-06, 'epoch': 17.4}\n",
      "{'loss': 2.9637, 'learning_rate': 8.272000000000001e-06, 'epoch': 17.6}\n",
      "{'loss': 2.9484, 'learning_rate': 8.138666666666667e-06, 'epoch': 17.8}\n",
      "{'loss': 2.957, 'learning_rate': 8.005333333333335e-06, 'epoch': 18.0}\n",
      "{'loss': 2.9497, 'learning_rate': 7.872e-06, 'epoch': 18.2}\n",
      "{'loss': 2.9423, 'learning_rate': 7.738666666666668e-06, 'epoch': 18.4}\n",
      "{'loss': 2.9422, 'learning_rate': 7.605333333333333e-06, 'epoch': 18.6}\n",
      "{'loss': 2.9312, 'learning_rate': 7.472000000000001e-06, 'epoch': 18.8}\n",
      "{'loss': 2.9535, 'learning_rate': 7.3389333333333336e-06, 'epoch': 19.0}\n",
      "{'loss': 2.9364, 'learning_rate': 7.2056e-06, 'epoch': 19.2}\n",
      "{'loss': 2.9324, 'learning_rate': 7.0722666666666675e-06, 'epoch': 19.4}\n",
      "{'loss': 2.9251, 'learning_rate': 6.938933333333334e-06, 'epoch': 19.6}\n",
      "{'loss': 2.9275, 'learning_rate': 6.805600000000001e-06, 'epoch': 19.8}\n",
      "{'loss': 2.9345, 'learning_rate': 6.672533333333334e-06, 'epoch': 20.0}\n",
      "{'loss': 2.9124, 'learning_rate': 6.5392e-06, 'epoch': 20.2}\n",
      "{'loss': 2.9316, 'learning_rate': 6.4058666666666665e-06, 'epoch': 20.4}\n",
      "{'loss': 2.9265, 'learning_rate': 6.272533333333334e-06, 'epoch': 20.6}\n",
      "{'loss': 2.9195, 'learning_rate': 6.139466666666667e-06, 'epoch': 20.8}\n",
      "{'loss': 2.9201, 'learning_rate': 6.006133333333334e-06, 'epoch': 21.0}\n",
      "{'loss': 2.9148, 'learning_rate': 5.872800000000001e-06, 'epoch': 21.2}\n",
      "{'loss': 2.9052, 'learning_rate': 5.739466666666667e-06, 'epoch': 21.4}\n",
      "{'loss': 2.9161, 'learning_rate': 5.606133333333334e-06, 'epoch': 21.6}\n",
      "{'loss': 2.9116, 'learning_rate': 5.473066666666668e-06, 'epoch': 21.8}\n",
      "{'loss': 2.909, 'learning_rate': 5.339733333333333e-06, 'epoch': 22.0}\n",
      "{'loss': 2.9016, 'learning_rate': 5.206400000000001e-06, 'epoch': 22.2}\n",
      "{'loss': 2.9018, 'learning_rate': 5.073066666666667e-06, 'epoch': 22.4}\n",
      "{'loss': 2.8924, 'learning_rate': 4.939733333333334e-06, 'epoch': 22.6}\n",
      "{'loss': 2.9104, 'learning_rate': 4.8066666666666675e-06, 'epoch': 22.8}\n",
      "{'loss': 2.9049, 'learning_rate': 4.673333333333333e-06, 'epoch': 23.0}\n",
      "{'loss': 2.9, 'learning_rate': 4.540000000000001e-06, 'epoch': 23.2}\n",
      "{'loss': 2.8904, 'learning_rate': 4.406666666666667e-06, 'epoch': 23.4}\n",
      "{'loss': 2.9053, 'learning_rate': 4.273600000000001e-06, 'epoch': 23.6}\n",
      "{'loss': 2.8858, 'learning_rate': 4.140266666666667e-06, 'epoch': 23.8}\n",
      "{'loss': 2.8909, 'learning_rate': 4.006933333333334e-06, 'epoch': 24.0}\n",
      "{'loss': 2.8775, 'learning_rate': 3.8736000000000005e-06, 'epoch': 24.2}\n",
      "{'loss': 2.8935, 'learning_rate': 3.740533333333334e-06, 'epoch': 24.4}\n",
      "{'loss': 2.8915, 'learning_rate': 3.6072e-06, 'epoch': 24.6}\n",
      "{'loss': 2.898, 'learning_rate': 3.473866666666667e-06, 'epoch': 24.8}\n",
      "{'loss': 2.8831, 'learning_rate': 3.3405333333333334e-06, 'epoch': 25.0}\n",
      "{'loss': 2.8836, 'learning_rate': 3.2072000000000004e-06, 'epoch': 25.2}\n",
      "{'loss': 2.8674, 'learning_rate': 3.0741333333333333e-06, 'epoch': 25.4}\n",
      "{'loss': 2.8769, 'learning_rate': 2.9408000000000003e-06, 'epoch': 25.6}\n",
      "{'loss': 2.8895, 'learning_rate': 2.807466666666667e-06, 'epoch': 25.8}\n",
      "{'loss': 2.8924, 'learning_rate': 2.6741333333333338e-06, 'epoch': 26.0}\n",
      "{'loss': 2.8709, 'learning_rate': 2.5408e-06, 'epoch': 26.2}\n",
      "{'loss': 2.8816, 'learning_rate': 2.4077333333333337e-06, 'epoch': 26.4}\n",
      "{'loss': 2.8852, 'learning_rate': 2.2744e-06, 'epoch': 26.6}\n",
      "{'loss': 2.8769, 'learning_rate': 2.1410666666666667e-06, 'epoch': 26.8}\n",
      "{'loss': 2.8878, 'learning_rate': 2.0077333333333337e-06, 'epoch': 27.0}\n",
      "{'loss': 2.8666, 'learning_rate': 1.8746666666666668e-06, 'epoch': 27.2}\n",
      "{'loss': 2.8782, 'learning_rate': 1.7413333333333336e-06, 'epoch': 27.4}\n",
      "{'loss': 2.8732, 'learning_rate': 1.608e-06, 'epoch': 27.6}\n",
      "{'loss': 2.885, 'learning_rate': 1.4746666666666668e-06, 'epoch': 27.8}\n",
      "{'loss': 2.8761, 'learning_rate': 1.3416000000000002e-06, 'epoch': 28.0}\n",
      "{'loss': 2.8617, 'learning_rate': 1.2082666666666667e-06, 'epoch': 28.2}\n",
      "{'loss': 2.8641, 'learning_rate': 1.0749333333333335e-06, 'epoch': 28.4}\n",
      "{'loss': 2.8768, 'learning_rate': 9.416e-07, 'epoch': 28.6}\n",
      "{'loss': 2.8732, 'learning_rate': 8.085333333333334e-07, 'epoch': 28.8}\n",
      "{'loss': 2.8941, 'learning_rate': 6.752e-07, 'epoch': 29.0}\n",
      "{'loss': 2.8857, 'learning_rate': 5.418666666666668e-07, 'epoch': 29.2}\n",
      "{'loss': 2.8798, 'learning_rate': 4.0853333333333334e-07, 'epoch': 29.4}\n",
      "{'loss': 2.859, 'learning_rate': 2.7520000000000003e-07, 'epoch': 29.6}\n",
      "{'loss': 2.8726, 'learning_rate': 1.418666666666667e-07, 'epoch': 29.8}\n",
      "{'loss': 2.8644, 'learning_rate': 8.533333333333334e-09, 'epoch': 30.0}\n",
      "{'train_runtime': 7935.4616, 'train_samples_per_second': 302.44, 'train_steps_per_second': 9.451, 'train_loss': 3.064906062825521, 'epoch': 30.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=75000, training_loss=3.064906062825521, metrics={'train_runtime': 7935.4616, 'train_samples_per_second': 302.44, 'train_steps_per_second': 9.451, 'train_loss': 3.064906062825521, 'epoch': 30.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\".\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=30,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    "    save_steps=25000\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
