{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('csv', data_files='/home/j/Documents/MLotsawa/transliteration/data/pairs.csv', column_names=['bo', 'phon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset['train'].train_test_split(.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Checkpoint Tokenizer, Model, and Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 20:55:41.756715: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-08 20:55:41.857676: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-08 20:55:41.900066: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-08 20:55:41.911502: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-08 20:55:41.985407: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-08 20:55:42.829413: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM\n",
    "\n",
    "checkpoint = \"google-t5/t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, device_map=\"auto\")\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Tibetan to Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32245, 512)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tibetan characters to add\n",
    "tibetan_chars = [\n",
    "    # Consonants\n",
    "    \"ཀ\", \"ཁ\", \"ག\", \"ང\", \"ཅ\", \"ཆ\", \"ཇ\", \"ཉ\", \"ཏ\", \"ཐ\", \"ད\", \"ན\", \"པ\", \"པ\", \"ཕ\", \"བ\", \"མ\",\n",
    "    \"ཙ\", \"ཚ\", \"ཛ\", \"ཝ\", \"ཞ\", \"ཟ\", \"འ\", \"ཡ\", \"ར\", \"ལ\", \"ཤ\", \"ཥ\", \"ས\", \"ཧ\", \"ཨ\",\n",
    "\n",
    "    # Subjoined Consonants\n",
    "    \"ྐ\", \"ྑ\", \"ྒ\", \"ྒྷ\", \"ྔ\", \"ྕ\", \"ྖ\", \"ྗ\", \"྘\", \"ྙ\", \"ྚ\", \"ྛ\", \"ྜ\", \"ྜྷ\", \"ྞ\", \"ྟ\",\n",
    "    \"ྠ\", \"ྡ\", \"ྡྷ\", \"ྣ\", \"ྤ\", \"ྥ\", \"ྦ\", \"ྦྷ\", \"ྨ\", \"ྩ\", \"ྪ\", \"ྫ\", \"ྫྷ\", \"ྭ\", \"ྮ\", \"ྯ\",\n",
    "    \"ྰ\", \"ྱ\", \"ྲ\", \"ླ\", \"ྴ\", \"ྵ\", \"ྶ\", \"ྷ\", \"ྸ\", \"ྐྵ\", \"ྺ\", \"ྻ\", \"ྼ\", \"྽\", \"྾\", \"྿\",\n",
    "\n",
    "    # Vowels\n",
    "    \"ི\", \"ཱི\", \"ུ\", \"ཱུ\", \"ྲྀ\", \"ཷ\", \"ླྀ\", \"ཹ\", \"ེ\", \"ཻ\", \"ོ\", \"ཽ\", \"ཾ\", \"ཿ\",\n",
    "\n",
    "    # Other Marks and Symbols\n",
    "    \"འ\", \"ཡ\", \"ར\", \"ལ\", \"ཤ\", \"ཥ\", \"ས\", \"ཧ\", \"ཨ\",\n",
    "\n",
    "    # Additional Tibetan Characters\n",
    "    \"ཀྵ\", \"ཁྵ\", \"གྵ\", \"ངྵ\", \"ཅྵ\", \"ཆྵ\", \"ཇྵ\", \"ཉྵ\", \"ཏྵ\", \"ཐྵ\", \"དྵ\", \"ནྵ\", \"པྵ\", \n",
    "    \"པྵ\", \"ཕྵ\", \"བྵ\", \"མྵ\", \"ཙྵ\", \"ཚྵ\", \"ཛྵ\", \"ཝྵ\", \"ཞྵ\", \"ཟྵ\", \"འྵ\", \"ཡྵ\", \"རྵ\", \n",
    "    \"ལྵ\", \"ཤྵ\", \"ཥྵ\", \"སྵ\", \"ཧྵ\", \"ཨྵ\", \"པྪ\", \"པྫ\", \"པྫྷ\", \"པྭ\", \"པྮ\", \"པྯ\", \"པྰ\", \n",
    "    \"པྱ\", \"པྲ\", \"པླ\", \"པྴ\", \"པྵ\", \"པྶ\", \"པྷ\", \"པྸ\", \"པྐྵ\", \"པྺ\", \"པྻ\", \"པྼ\", \"པ྽\", \n",
    "    \"པ྾\", \"པ྿\"\n",
    "]\n",
    "\n",
    "\n",
    "#'ཀཁགངཅཆཇཉཏཐདནཔཕབམཙཚཛཝཞཟའཡརལཤཥསཧཨ'\n",
    "\n",
    "# Add the Tibetan characters to the tokenizer's vocabulary\n",
    "new_tokens = [char for char in tibetan_chars if char not in tokenizer.get_vocab()]\n",
    "\n",
    "# Add new tokens to the tokenizer\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "\n",
    "# Resize model embeddings to accommodate the new vocabulary size\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lang = 'bo'\n",
    "target_lang = 'phon'\n",
    "\n",
    "def preprocess_function(examples):\n",
    "\n",
    "    inputs = [example for example in examples[source_lang]]\n",
    "    targets = [example for example in examples[target_lang]]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=256, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696830accbfd45e3afa86b5f677c84b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/88737 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054553fae38a46a495adfba6fb37b273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9860 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbillingsmoore\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99dcda896f0549ee9fb87a5819110f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112109133333329, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/j/Documents/MLotsawa/transliteration/notebooks/wandb/run-20240908_205558-vscpny2p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/billingsmoore/huggingface/runs/vscpny2p' target=\"_blank\">../../models/tib-tokenized</a></strong> to <a href='https://wandb.ai/billingsmoore/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/billingsmoore/huggingface' target=\"_blank\">https://wandb.ai/billingsmoore/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/billingsmoore/huggingface/runs/vscpny2p' target=\"_blank\">https://wandb.ai/billingsmoore/huggingface/runs/vscpny2p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac3382910704e3a83de21e0b1c095ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55465 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4358, 'grad_norm': 0.4028961658477783, 'learning_rate': 0.0002972955918146579, 'epoch': 0.05}\n",
      "{'loss': 0.2264, 'grad_norm': 0.1836295872926712, 'learning_rate': 0.00029459118362931577, 'epoch': 0.09}\n",
      "{'loss': 0.2168, 'grad_norm': 0.21932683885097504, 'learning_rate': 0.0002918867754439736, 'epoch': 0.14}\n",
      "{'loss': 0.1795, 'grad_norm': 0.3370167315006256, 'learning_rate': 0.00028918236725863157, 'epoch': 0.18}\n",
      "{'loss': 0.1289, 'grad_norm': 0.6756218671798706, 'learning_rate': 0.0002864779590732894, 'epoch': 0.23}\n",
      "{'loss': 0.0865, 'grad_norm': 0.4279094636440277, 'learning_rate': 0.00028377355088794737, 'epoch': 0.27}\n",
      "{'loss': 0.0738, 'grad_norm': 0.26090720295906067, 'learning_rate': 0.0002810691427026052, 'epoch': 0.32}\n",
      "{'loss': 0.0627, 'grad_norm': 0.3491724133491516, 'learning_rate': 0.0002783647345172631, 'epoch': 0.36}\n",
      "{'loss': 0.0565, 'grad_norm': 0.2388933300971985, 'learning_rate': 0.000275660326331921, 'epoch': 0.41}\n",
      "{'loss': 0.0462, 'grad_norm': 0.22108301520347595, 'learning_rate': 0.0002729559181465789, 'epoch': 0.45}\n",
      "{'loss': 0.043, 'grad_norm': 0.14911215007305145, 'learning_rate': 0.0002702515099612368, 'epoch': 0.5}\n",
      "{'loss': 0.0391, 'grad_norm': 0.13672654330730438, 'learning_rate': 0.00026754710177589466, 'epoch': 0.54}\n",
      "{'loss': 0.0377, 'grad_norm': 0.14306075870990753, 'learning_rate': 0.0002648426935905526, 'epoch': 0.59}\n",
      "{'loss': 0.037, 'grad_norm': 0.17113980650901794, 'learning_rate': 0.00026213828540521045, 'epoch': 0.63}\n",
      "{'loss': 0.036, 'grad_norm': 0.11543264985084534, 'learning_rate': 0.00025943387721986835, 'epoch': 0.68}\n",
      "{'loss': 0.0326, 'grad_norm': 0.1850987672805786, 'learning_rate': 0.00025672946903452625, 'epoch': 0.72}\n",
      "{'loss': 0.0318, 'grad_norm': 0.1554003357887268, 'learning_rate': 0.00025402506084918415, 'epoch': 0.77}\n",
      "{'loss': 0.0288, 'grad_norm': 0.420725554227829, 'learning_rate': 0.00025132065266384205, 'epoch': 0.81}\n",
      "{'loss': 0.0267, 'grad_norm': 0.13982628285884857, 'learning_rate': 0.00024861624447849995, 'epoch': 0.86}\n",
      "{'loss': 0.0267, 'grad_norm': 0.12511587142944336, 'learning_rate': 0.00024591183629315785, 'epoch': 0.9}\n",
      "{'loss': 0.0249, 'grad_norm': 0.11449749767780304, 'learning_rate': 0.00024320742810781572, 'epoch': 0.95}\n",
      "{'loss': 0.0272, 'grad_norm': 0.09630384296178818, 'learning_rate': 0.0002405030199224736, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65d0139bb4c43578d7130be0618f8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01764485239982605, 'eval_runtime': 115.2813, 'eval_samples_per_second': 85.53, 'eval_steps_per_second': 10.696, 'epoch': 1.0}\n",
      "{'loss': 0.0244, 'grad_norm': 0.07438911497592926, 'learning_rate': 0.0002377986117371315, 'epoch': 1.04}\n",
      "{'loss': 0.026, 'grad_norm': 0.10485607385635376, 'learning_rate': 0.0002350942035517894, 'epoch': 1.08}\n",
      "{'loss': 0.0225, 'grad_norm': 0.14731422066688538, 'learning_rate': 0.0002323897953664473, 'epoch': 1.13}\n",
      "{'loss': 0.0214, 'grad_norm': 0.29146984219551086, 'learning_rate': 0.00022968538718110516, 'epoch': 1.17}\n",
      "{'loss': 0.0221, 'grad_norm': 0.2635507881641388, 'learning_rate': 0.0002269809789957631, 'epoch': 1.22}\n",
      "{'loss': 0.0212, 'grad_norm': 0.27857252955436707, 'learning_rate': 0.00022427657081042096, 'epoch': 1.26}\n",
      "{'loss': 0.0214, 'grad_norm': 0.08655886352062225, 'learning_rate': 0.00022157216262507886, 'epoch': 1.31}\n",
      "{'loss': 0.0215, 'grad_norm': 0.0826745331287384, 'learning_rate': 0.00021886775443973676, 'epoch': 1.35}\n",
      "{'loss': 0.0197, 'grad_norm': 0.12163805961608887, 'learning_rate': 0.00021616334625439463, 'epoch': 1.4}\n",
      "{'loss': 0.0212, 'grad_norm': 0.14449363946914673, 'learning_rate': 0.00021345893806905253, 'epoch': 1.44}\n",
      "{'loss': 0.0222, 'grad_norm': 0.1316869705915451, 'learning_rate': 0.00021075452988371043, 'epoch': 1.49}\n",
      "{'loss': 0.0217, 'grad_norm': 0.09315773844718933, 'learning_rate': 0.00020805012169836833, 'epoch': 1.53}\n",
      "{'loss': 0.017, 'grad_norm': 0.19446703791618347, 'learning_rate': 0.0002053457135130262, 'epoch': 1.58}\n",
      "{'loss': 0.0182, 'grad_norm': 0.15097972750663757, 'learning_rate': 0.00020264130532768413, 'epoch': 1.62}\n",
      "{'loss': 0.0193, 'grad_norm': 0.09391807019710541, 'learning_rate': 0.000199936897142342, 'epoch': 1.67}\n",
      "{'loss': 0.0174, 'grad_norm': 0.12129989266395569, 'learning_rate': 0.00019723248895699987, 'epoch': 1.71}\n",
      "{'loss': 0.0176, 'grad_norm': 0.11448131501674652, 'learning_rate': 0.0001945280807716578, 'epoch': 1.76}\n",
      "{'loss': 0.0164, 'grad_norm': 0.06253563612699509, 'learning_rate': 0.00019182367258631567, 'epoch': 1.8}\n",
      "{'loss': 0.0201, 'grad_norm': 0.12417913973331451, 'learning_rate': 0.00018911926440097357, 'epoch': 1.85}\n",
      "{'loss': 0.0168, 'grad_norm': 0.0733504667878151, 'learning_rate': 0.00018641485621563147, 'epoch': 1.89}\n",
      "{'loss': 0.0167, 'grad_norm': 0.06154681369662285, 'learning_rate': 0.00018371044803028937, 'epoch': 1.94}\n",
      "{'loss': 0.0164, 'grad_norm': 0.08478809893131256, 'learning_rate': 0.00018100603984494724, 'epoch': 1.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bc0087eb1b44d0a50fdcf97bda5b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.012265005148947239, 'eval_runtime': 115.2732, 'eval_samples_per_second': 85.536, 'eval_steps_per_second': 10.696, 'epoch': 2.0}\n",
      "{'loss': 0.016, 'grad_norm': 0.1283872425556183, 'learning_rate': 0.00017830163165960511, 'epoch': 2.03}\n",
      "{'loss': 0.0152, 'grad_norm': 0.12045174837112427, 'learning_rate': 0.00017559722347426304, 'epoch': 2.07}\n",
      "{'loss': 0.0153, 'grad_norm': 0.06561446934938431, 'learning_rate': 0.0001728928152889209, 'epoch': 2.12}\n",
      "{'loss': 0.0156, 'grad_norm': 0.11308375000953674, 'learning_rate': 0.00017018840710357884, 'epoch': 2.16}\n",
      "{'loss': 0.0136, 'grad_norm': 0.12685871124267578, 'learning_rate': 0.0001674839989182367, 'epoch': 2.21}\n",
      "{'loss': 0.0153, 'grad_norm': 0.10953421890735626, 'learning_rate': 0.0001647795907328946, 'epoch': 2.25}\n",
      "{'loss': 0.0144, 'grad_norm': 0.06467598676681519, 'learning_rate': 0.00016207518254755248, 'epoch': 2.3}\n",
      "{'loss': 0.0145, 'grad_norm': 0.07096302509307861, 'learning_rate': 0.00015937077436221038, 'epoch': 2.34}\n",
      "{'loss': 0.0162, 'grad_norm': 0.05120640620589256, 'learning_rate': 0.00015666636617686828, 'epoch': 2.39}\n",
      "{'loss': 0.015, 'grad_norm': 0.05398621782660484, 'learning_rate': 0.00015396195799152615, 'epoch': 2.43}\n",
      "{'loss': 0.0149, 'grad_norm': 0.055251091718673706, 'learning_rate': 0.00015125754980618408, 'epoch': 2.48}\n",
      "{'loss': 0.0163, 'grad_norm': 0.12607191503047943, 'learning_rate': 0.00014855314162084195, 'epoch': 2.52}\n",
      "{'loss': 0.0143, 'grad_norm': 0.07224543392658234, 'learning_rate': 0.00014584873343549985, 'epoch': 2.57}\n",
      "{'loss': 0.0142, 'grad_norm': 0.10685030370950699, 'learning_rate': 0.00014314432525015775, 'epoch': 2.61}\n",
      "{'loss': 0.0143, 'grad_norm': 0.24669644236564636, 'learning_rate': 0.00014043991706481565, 'epoch': 2.66}\n",
      "{'loss': 0.0149, 'grad_norm': 0.06379155069589615, 'learning_rate': 0.00013773550887947352, 'epoch': 2.7}\n",
      "{'loss': 0.014, 'grad_norm': 0.09284410625696182, 'learning_rate': 0.00013503110069413142, 'epoch': 2.75}\n",
      "{'loss': 0.0154, 'grad_norm': 0.3810117244720459, 'learning_rate': 0.00013232669250878932, 'epoch': 2.79}\n",
      "{'loss': 0.0142, 'grad_norm': 0.2289378046989441, 'learning_rate': 0.0001296222843234472, 'epoch': 2.84}\n",
      "{'loss': 0.0135, 'grad_norm': 0.10621816664934158, 'learning_rate': 0.0001269178761381051, 'epoch': 2.88}\n",
      "{'loss': 0.0131, 'grad_norm': 0.07948880642652512, 'learning_rate': 0.000124213467952763, 'epoch': 2.93}\n",
      "{'loss': 0.0124, 'grad_norm': 0.0774512067437172, 'learning_rate': 0.00012150905976742089, 'epoch': 2.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580c3968a2a14c549b8496569615f831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01027483120560646, 'eval_runtime': 115.4463, 'eval_samples_per_second': 85.408, 'eval_steps_per_second': 10.68, 'epoch': 3.0}\n",
      "{'loss': 0.0142, 'grad_norm': 0.06376458704471588, 'learning_rate': 0.00011880465158207878, 'epoch': 3.02}\n",
      "{'loss': 0.0131, 'grad_norm': 0.10283981263637543, 'learning_rate': 0.00011610024339673667, 'epoch': 3.06}\n",
      "{'loss': 0.013, 'grad_norm': 0.08032650500535965, 'learning_rate': 0.00011339583521139457, 'epoch': 3.11}\n",
      "{'loss': 0.0113, 'grad_norm': 0.09435302764177322, 'learning_rate': 0.00011069142702605245, 'epoch': 3.16}\n",
      "{'loss': 0.012, 'grad_norm': 0.0506606251001358, 'learning_rate': 0.00010798701884071034, 'epoch': 3.2}\n",
      "{'loss': 0.0127, 'grad_norm': 0.08407637476921082, 'learning_rate': 0.00010528261065536824, 'epoch': 3.25}\n",
      "{'loss': 0.0122, 'grad_norm': 0.09842335432767868, 'learning_rate': 0.00010257820247002613, 'epoch': 3.29}\n",
      "{'loss': 0.0132, 'grad_norm': 0.12308220565319061, 'learning_rate': 9.987379428468403e-05, 'epoch': 3.34}\n",
      "{'loss': 0.0116, 'grad_norm': 0.15583236515522003, 'learning_rate': 9.716938609934193e-05, 'epoch': 3.38}\n",
      "{'loss': 0.0137, 'grad_norm': 0.0789790004491806, 'learning_rate': 9.446497791399981e-05, 'epoch': 3.43}\n",
      "{'loss': 0.0135, 'grad_norm': 0.1526218056678772, 'learning_rate': 9.17605697286577e-05, 'epoch': 3.47}\n",
      "{'loss': 0.0131, 'grad_norm': 0.13043181598186493, 'learning_rate': 8.905616154331559e-05, 'epoch': 3.52}\n",
      "{'loss': 0.0125, 'grad_norm': 0.06901654601097107, 'learning_rate': 8.635175335797348e-05, 'epoch': 3.56}\n",
      "{'loss': 0.0154, 'grad_norm': 0.04935240373015404, 'learning_rate': 8.364734517263138e-05, 'epoch': 3.61}\n",
      "{'loss': 0.0126, 'grad_norm': 0.1453959345817566, 'learning_rate': 8.094293698728927e-05, 'epoch': 3.65}\n",
      "{'loss': 0.0118, 'grad_norm': 0.0901835635304451, 'learning_rate': 7.823852880194717e-05, 'epoch': 3.7}\n",
      "{'loss': 0.0112, 'grad_norm': 0.047621775418519974, 'learning_rate': 7.553412061660507e-05, 'epoch': 3.74}\n",
      "{'loss': 0.0113, 'grad_norm': 0.05411149188876152, 'learning_rate': 7.282971243126295e-05, 'epoch': 3.79}\n",
      "{'loss': 0.011, 'grad_norm': 0.09512954205274582, 'learning_rate': 7.012530424592085e-05, 'epoch': 3.83}\n",
      "{'loss': 0.014, 'grad_norm': 0.07539895921945572, 'learning_rate': 6.742089606057874e-05, 'epoch': 3.88}\n",
      "{'loss': 0.0118, 'grad_norm': 0.0663108229637146, 'learning_rate': 6.471648787523662e-05, 'epoch': 3.92}\n",
      "{'loss': 0.012, 'grad_norm': 0.03932526335120201, 'learning_rate': 6.201207968989452e-05, 'epoch': 3.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef31d20c993428c8d8d1a8808c7bceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00918691698461771, 'eval_runtime': 115.2962, 'eval_samples_per_second': 85.519, 'eval_steps_per_second': 10.694, 'epoch': 4.0}\n",
      "{'loss': 0.011, 'grad_norm': 0.06079893186688423, 'learning_rate': 5.9307671504552416e-05, 'epoch': 4.01}\n",
      "{'loss': 0.0125, 'grad_norm': 0.07640495151281357, 'learning_rate': 5.66032633192103e-05, 'epoch': 4.06}\n",
      "{'loss': 0.0123, 'grad_norm': 0.09477221220731735, 'learning_rate': 5.38988551338682e-05, 'epoch': 4.1}\n",
      "{'loss': 0.0101, 'grad_norm': 0.31089723110198975, 'learning_rate': 5.119444694852609e-05, 'epoch': 4.15}\n",
      "{'loss': 0.0101, 'grad_norm': 0.07270392030477524, 'learning_rate': 4.8490038763183986e-05, 'epoch': 4.19}\n",
      "{'loss': 0.0108, 'grad_norm': 0.09101097285747528, 'learning_rate': 4.578563057784188e-05, 'epoch': 4.24}\n",
      "{'loss': 0.0119, 'grad_norm': 0.13944658637046814, 'learning_rate': 4.308122239249977e-05, 'epoch': 4.28}\n",
      "{'loss': 0.012, 'grad_norm': 0.068307064473629, 'learning_rate': 4.037681420715766e-05, 'epoch': 4.33}\n",
      "{'loss': 0.0122, 'grad_norm': 0.07947788387537003, 'learning_rate': 3.767240602181556e-05, 'epoch': 4.37}\n",
      "{'loss': 0.011, 'grad_norm': 0.055460698902606964, 'learning_rate': 3.496799783647345e-05, 'epoch': 4.42}\n",
      "{'loss': 0.0102, 'grad_norm': 0.3655239939689636, 'learning_rate': 3.226358965113134e-05, 'epoch': 4.46}\n",
      "{'loss': 0.0121, 'grad_norm': 0.08433965593576431, 'learning_rate': 2.9559181465789233e-05, 'epoch': 4.51}\n",
      "{'loss': 0.0131, 'grad_norm': 0.05374601110816002, 'learning_rate': 2.6854773280447125e-05, 'epoch': 4.55}\n",
      "{'loss': 0.0103, 'grad_norm': 0.049055732786655426, 'learning_rate': 2.4150365095105018e-05, 'epoch': 4.6}\n",
      "{'loss': 0.0101, 'grad_norm': 0.039602067321538925, 'learning_rate': 2.1445956909762914e-05, 'epoch': 4.64}\n",
      "{'loss': 0.0137, 'grad_norm': 0.041634224355220795, 'learning_rate': 1.8741548724420806e-05, 'epoch': 4.69}\n",
      "{'loss': 0.0108, 'grad_norm': 0.07823880016803741, 'learning_rate': 1.6037140539078695e-05, 'epoch': 4.73}\n",
      "{'loss': 0.011, 'grad_norm': 0.08715623617172241, 'learning_rate': 1.333273235373659e-05, 'epoch': 4.78}\n",
      "{'loss': 0.011, 'grad_norm': 0.08802922815084457, 'learning_rate': 1.0628324168394482e-05, 'epoch': 4.82}\n",
      "{'loss': 0.0118, 'grad_norm': 0.05375844985246658, 'learning_rate': 7.923915983052374e-06, 'epoch': 4.87}\n",
      "{'loss': 0.012, 'grad_norm': 0.035169024020433426, 'learning_rate': 5.219507797710267e-06, 'epoch': 4.91}\n",
      "{'loss': 0.012, 'grad_norm': 0.050023213028907776, 'learning_rate': 2.51509961236816e-06, 'epoch': 4.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094fcf0720b047178baf8306a4199c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.008867141790688038, 'eval_runtime': 115.2943, 'eval_samples_per_second': 85.52, 'eval_steps_per_second': 10.694, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 18058.2619, 'train_samples_per_second': 24.57, 'train_steps_per_second': 3.071, 'train_loss': 0.028914398460556687, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=55465, training_loss=0.028914398460556687, metrics={'train_runtime': 18058.2619, 'train_samples_per_second': 24.57, 'train_steps_per_second': 3.071, 'total_flos': 3.002456359305216e+16, 'train_loss': 0.028914398460556687, 'epoch': 5.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, Adafactor\n",
    "\n",
    "optimizer = Adafactor(\n",
    "    model.parameters(), \n",
    "    scale_parameter=True, \n",
    "    relative_step=False, \n",
    "    warmup_init=False, \n",
    "    lr=3e-4\n",
    ")\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer = accelerator.prepare(model, optimizer)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"../../models/tib-tokenized\",\n",
    "    auto_find_batch_size=True,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    push_to_hub=False,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    num_train_epochs=5\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer, None),\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
