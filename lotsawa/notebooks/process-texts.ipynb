{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data\n",
    "\n",
    "The data for this project comes from Lotsawa House. I'm beginning by using their \"Words of the Buddha\" collection. The translations come in bilingual pdfs which need to be converted to a usable .txt file format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We want to be able to use and reuse this code so first I'll set up some variables that can be easily changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_name is the name of the text to be processed without the file type suffix\n",
    "\n",
    "text_name = 'jamyang'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting PDFs to txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "path = 'data/' + text_name + '/'\n",
    "\n",
    "reader = PdfReader(path + text_name + '.pdf')\n",
    "\n",
    "num_pages = len(reader.pages)\n",
    "\n",
    "text = []\n",
    "\n",
    "for page in reader.pages:\n",
    "    text.append(page.extract_text())\n",
    "\n",
    "with open(path + 'phase1.txt', 'w') as f:\n",
    "    f.writelines('\\n'.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that a txt file has been created. We need to remove lines from the file that are not useful to us. This includes pages numbers, Tibetan script lines, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = []\n",
    "\n",
    "with open(path + 'phase1.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        new_line = re.sub(r'[^a-zA-Z ]', '', line)\n",
    "        if new_line.replace(' ', '') != '':\n",
    "            text.append(new_line)\n",
    "\n",
    "with open(path + 'phase2.txt', 'w') as f:\n",
    "    f.writelines('\\n'.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've wittled the text down we can set the text into Tibetan and English sentence pairs. Lotsawa House translations are conveniently provided in multiple lines. First Tibetan and then the English translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy_langdetect import LanguageDetector\n",
    "import spacy\n",
    "\n",
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "nlp_model = spacy.load(\"en_core_web_md\")\n",
    "spacy.language.Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "nlp_model.add_pipe('language_detector', last=True)\n",
    "\n",
    "pairs = []\n",
    "\n",
    "def detect(text):\n",
    "    doc = nlp_model(text)\n",
    "    detect_language = doc._.language\n",
    "    lang = detect_language['language']\n",
    "    return lang\n",
    "\n",
    "with open(path + 'phase2.txt', 'r') as f:\n",
    "    text = f.readlines()\n",
    "    \n",
    "    for i in range(len(text) - 1):\n",
    "        lang = detect(text[i])\n",
    "        if lang != \"en\":\n",
    "            next_lang = detect(text[i+1])\n",
    "            if next_lang == \"en\":\n",
    "                pair = (text[i].replace('\\n', '') + ',' + text[i+1])\n",
    "                pairs.append(pair)\n",
    "\n",
    "with open(path + 'pairs.txt', 'w') as f:\n",
    "    f.writelines(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below concatenates all of the pairs.txt results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for folder in os.listdir('data/pre-processed/'):\n",
    "    path = 'data/pre-processed/' + folder\n",
    "\n",
    "    with open(path + '/pairs.txt', 'r') as f:\n",
    "        text = f.readlines()\n",
    "\n",
    "        with open('data/all-pairs.txt', 'a') as g:\n",
    "            g.writelines(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
